{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import f90nml\n",
    "import numpy as np\n",
    "from pint import UnitRegistry; AssignQuantity = UnitRegistry().Quantity\n",
    "from QLCstuff2 import getNQLL\n",
    "import os\n",
    "import reference_solution as refsol\n",
    "from scipy.fft import rfft\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import icepinn as ip\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "device = ip.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in GI parameters\n",
    "inputfile = \"GI parameters - Reference limit cycle (for testing).nml\"\n",
    "GI=f90nml.read(inputfile)['GI']\n",
    "nx_crystal = GI['nx_crystal']\n",
    "L = GI['L']\n",
    "NBAR = GI['Nbar']\n",
    "NSTAR = GI['Nstar']\n",
    "\n",
    "# Define t range\n",
    "RUNTIME = 5\n",
    "NUM_T_STEPS = RUNTIME + 1\n",
    "\n",
    "# Define initial conditions\n",
    "Ntot_init_1D = np.ones(nx_crystal)\n",
    "Nqll_init_1D = getNQLL(Ntot_init_1D,NSTAR,NBAR)\n",
    "\n",
    "# Define x, t pairs for training\n",
    "X_QLC = np.linspace(-L,L,nx_crystal)\n",
    "t_points = np.linspace(0, RUNTIME, NUM_T_STEPS)\n",
    "x, t = np.meshgrid(X_QLC, t_points)\n",
    "training_set = torch.tensor(np.column_stack((x.flatten(), t.flatten()))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model dimensions; instantiate model\n",
    "model_dimensions = torch.tensor([8, 80]).to(device)\n",
    "model = ip.IcePINN(num_hidden_layers=model_dimensions[0], hidden_layer_size=model_dimensions[0]).to(device)\n",
    "\n",
    "# Attach model dimensions so they can be saved and loaded\n",
    "model.register_buffer('dimensions', model_dimensions)\n",
    "\n",
    "# Initialize model weights with HE initialization\n",
    "def init_HE(m):\n",
    "\t\tif type(m) == nn.Linear:\n",
    "\t\t\tnn.init.kaiming_normal_(m.weight)\n",
    "model.apply(init_HE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing PINN training for 50000 epochs.\n",
      "Loss at epoch [1000/50000]: Ntot = 13.757093462720707, Nqll = 8.27980181594701.\n",
      "Loss at epoch [2000/50000]: Ntot = 5.603213241141843, Nqll = 2.683554053345563.\n",
      "Loss at epoch [3000/50000]: Ntot = 10.168766458773534, Nqll = 6.1842247754923925.\n",
      "Loss at epoch [4000/50000]: Ntot = 91.34929496192608, Nqll = 23.066536656874767.\n",
      "Loss at epoch [5000/50000]: Ntot = 34.520173343113655, Nqll = 8.443160287299674.\n",
      "Loss at epoch [6000/50000]: Ntot = 18.608560311543265, Nqll = 4.4535291684149545.\n",
      "Loss at epoch [7000/50000]: Ntot = 3.850059813321768, Nqll = 0.8536307604814424.\n",
      "Loss at epoch [8000/50000]: Ntot = 28.712023556722283, Nqll = 7.214190461881078.\n",
      "Loss at epoch [9000/50000]: Ntot = 21.47437801302649, Nqll = 4.953943879977403.\n",
      "Loss at epoch [10000/50000]: Ntot = 19.614871288081186, Nqll = 4.512732414437673.\n",
      "Loss at epoch [11000/50000]: Ntot = 8.673752031317893, Nqll = 2.0023617263322873.\n",
      "Loss at epoch [12000/50000]: Ntot = 7.016224635958822, Nqll = 1.6145407128921092.\n",
      "Loss at epoch [13000/50000]: Ntot = 5.685703259364156, Nqll = 1.3174367771578126.\n",
      "Loss at epoch [14000/50000]: Ntot = 5.251857426255737, Nqll = 1.1964537269240887.\n",
      "Loss at epoch [15000/50000]: Ntot = 5.392719989038237, Nqll = 1.2229564184499457.\n",
      "Loss at epoch [16000/50000]: Ntot = 5.339202311063929, Nqll = 1.2066325840907541.\n",
      "Loss at epoch [17000/50000]: Ntot = 5.4841359807033125, Nqll = 1.2462783943068405.\n",
      "Loss at epoch [18000/50000]: Ntot = 5.148666058402813, Nqll = 1.1598125208744143.\n",
      "Loss at epoch [19000/50000]: Ntot = 4.07857509631423, Nqll = 0.9275128453243418.\n",
      "Loss at epoch [20000/50000]: Ntot = 3.4780814054862534, Nqll = 0.7859087557789978.\n",
      "Loss at epoch [21000/50000]: Ntot = 3.518942784841696, Nqll = 0.789492001846192.\n",
      "Loss at epoch [22000/50000]: Ntot = 3.3555745326466924, Nqll = 0.7546242199917554.\n",
      "Loss at epoch [23000/50000]: Ntot = 2.6104233548704094, Nqll = 0.5828487006902543.\n",
      "Loss at epoch [24000/50000]: Ntot = 2.717194636925013, Nqll = 0.6131181449670329.\n",
      "Loss at epoch [25000/50000]: Ntot = 2.3401791985606404, Nqll = 0.5328208110550877.\n",
      "Loss at epoch [26000/50000]: Ntot = 1.7973165583099808, Nqll = 0.398854223001563.\n",
      "Loss at epoch [27000/50000]: Ntot = 1.167375753329377, Nqll = 0.26006831867192004.\n",
      "Loss at epoch [28000/50000]: Ntot = 0.06746242854313703, Nqll = 0.015625528800392793.\n",
      "Loss at epoch [29000/50000]: Ntot = 0.313367690947161, Nqll = 0.0738754268383092.\n",
      "Loss at epoch [30000/50000]: Ntot = 0.10116670609742526, Nqll = 0.02316009942723307.\n",
      "Loss at epoch [31000/50000]: Ntot = 0.07132419789235048, Nqll = 0.016242652210851295.\n",
      "Loss at epoch [32000/50000]: Ntot = 0.06646595110744759, Nqll = 0.015084988352982909.\n",
      "Loss at epoch [33000/50000]: Ntot = 0.05928894566762298, Nqll = 0.013451267148637019.\n",
      "Loss at epoch [34000/50000]: Ntot = 0.05048352837585149, Nqll = 0.011442168465917283.\n",
      "Loss at epoch [35000/50000]: Ntot = 0.050504747378751505, Nqll = 0.011440141445306348.\n",
      "Loss at epoch [36000/50000]: Ntot = 0.06523539323817472, Nqll = 0.014799473453847729.\n",
      "Loss at epoch [37000/50000]: Ntot = 0.049234861928293655, Nqll = 0.01114504672501327.\n",
      "Loss at epoch [38000/50000]: Ntot = 0.053008136904980296, Nqll = 0.011910645699317046.\n",
      "Loss at epoch [39000/50000]: Ntot = 0.0776258197913487, Nqll = 0.014235516187762831.\n",
      "Loss at epoch [40000/50000]: Ntot = 0.04103380673618877, Nqll = 0.009280708869955249.\n",
      "Loss at epoch [41000/50000]: Ntot = 0.06406013933844351, Nqll = 0.01438241825190768.\n",
      "Loss at epoch [42000/50000]: Ntot = 0.04783064017990305, Nqll = 0.010815257609671145.\n",
      "Loss at epoch [43000/50000]: Ntot = 0.043139843889757216, Nqll = 0.009721105057072896.\n",
      "Loss at epoch [44000/50000]: Ntot = 0.04016072536029265, Nqll = 0.009039969943702432.\n",
      "Loss at epoch [45000/50000]: Ntot = 0.03578513039511508, Nqll = 0.007119791845288385.\n",
      "Loss at epoch [46000/50000]: Ntot = 0.0342178555856013, Nqll = 0.007701416932986401.\n",
      "Loss at epoch [47000/50000]: Ntot = 0.06568801779472724, Nqll = 0.009383332798802303.\n",
      "Loss at epoch [48000/50000]: Ntot = 0.03143089160130183, Nqll = 0.0034341704129735853.\n",
      "Loss at epoch [49000/50000]: Ntot = 0.029656728772778362, Nqll = 0.0064607047366609435.\n",
      "Loss at epoch [50000/50000]: Ntot = 0.02954158418758147, Nqll = 0.006634245647594124.\n",
      "Training complete! Model from epoch 49999 has been saved.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"TestPINN\"\n",
    "PATH = './models/'+MODEL_NAME\n",
    "\n",
    "ip.train_IcePINN(model, optimizer, training_set, epochs=50_000, save_path=PATH, print_every=1_000, print_gradients=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# torch.save(model.state_dict(), PATH'/'+MODEL_NAME+'.pth')\n",
    "# torch.save(optimizer.state_dict(), PATH'/'+MODEL_NAME+'.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model (visually?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = IcePINN()\n",
    "# loaded_model.load_state_dict(torch.load(PATH)) # it takes the loaded dictionary, not the path file itself\n",
    "# loaded_model.to(device)\n",
    "# loaded_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
