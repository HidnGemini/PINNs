{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "0\n",
      "mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gem/Documents/GitHub/PINNs/icepinn.py:187: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(NBAR - NSTAR*torch.sin(2*np.pi*Ntot)).to(device)\n"
     ]
    }
   ],
   "source": [
    "import f90nml\n",
    "import numpy as np\n",
    "from pint import UnitRegistry; AssignQuantity = UnitRegistry().Quantity\n",
    "import os\n",
    "import reference_solution as refsol\n",
    "from scipy.fft import rfft\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import icepinn as ip\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "device = ip.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in GI parameters\n",
    "inputfile = \"GI parameters - Reference limit cycle (for testing).nml\"\n",
    "GI=f90nml.read(inputfile)['GI']\n",
    "nx_crystal = GI['nx_crystal']\n",
    "L = GI['L']\n",
    "NBAR = GI['Nbar']\n",
    "NSTAR = GI['Nstar']\n",
    "\n",
    "# Define t range in MS (needs to be same as training file)\n",
    "RUNTIME = 2\n",
    "NUM_T_STEPS = 100*RUNTIME + 1\n",
    "#NUM_T_STEPS = RUNTIME*5 + 1\n",
    "\n",
    "# Define initial conditions\n",
    "Ntot_init = torch.ones(nx_crystal).to(device)\n",
    "Nqll_init = ip.get_Nqll(Ntot_init)\n",
    "\n",
    "# Define x, t pairs for training\n",
    "X_QLC = np.linspace(-L,L,nx_crystal)\n",
    "t_points = np.linspace(0, RUNTIME, NUM_T_STEPS)\n",
    "x, t = np.meshgrid(X_QLC, t_points)\n",
    "training_set = torch.tensor(np.column_stack((x.flatten(), t.flatten()))).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming Legend\n",
    "\n",
    "(This is just how I was notating my saved models, you can do whatever works for you. Just make sure you remember the hyperparameters & architecture somehow)\n",
    "\n",
    "CL = curriculum learning  \n",
    "SF = SF_Pinn architecture  \n",
    "HE = hard-enforced initial condition    \n",
    "SE = soft-enforced initial condition \n",
    "{n}wide = nodes per FC-layer  \n",
    "nodiff = diffusion term is excluded  \n",
    "LBFGS = LBFGS was used  \n",
    "SGD = SGD with standard momentum  \n",
    "Nesterov = SGD with Nesterov momentum   \n",
    "AdamW was used if optimizer is unspecified  \n",
    "{n}rt = trained on RUNTIME of {n}   \n",
    "{n}x = {n}*RUNTIME + 1 timesteps in training set    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"HE_128wide_nodiff_2rt_100x\"\n",
    "\n",
    "# Hard enforce IC? (soft-enforced otherwise)\n",
    "hard_enforce_IC = True\n",
    "# Curriculum learning? (Only relevant for HE IC)\n",
    "curriculum_learning = False\n",
    "# Pre-load stage 1 model (and use it instead of stage 1 training)?\n",
    "#   - For CR, this will be the pre IC enforced model\n",
    "#   - For models fine-tuned with L-BFGS, this will be the pre L-BFGS model\n",
    "preload = False\n",
    "# Use L-BFGS after initial optimization?\n",
    "LBFGS = False\n",
    "\n",
    "# Define model attributes\n",
    "model_dimensions = torch.tensor([8, 128]).to(device) # [Num hidden layers, Nodes per layer]\n",
    "is_sf_PINN = torch.tensor(False)\n",
    "diffusion = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IcePINN(\n",
       "  (sml): SinusoidalMappingLayer()\n",
       "  (post_sml): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (sin): SinActivation()\n",
       "  (fc_in): Linear(in_features=2, out_features=128, bias=True)\n",
       "  (post_fc_in): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc_hidden): ModuleList(\n",
       "    (0-5): 6 x Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc_out): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = ip.IcePINN(\n",
    "\tnum_hidden_layers=model_dimensions[0], \n",
    "\thidden_layer_size=model_dimensions[1],\n",
    "\tis_sf_PINN=is_sf_PINN.item()).to(device)\n",
    "\n",
    "# Attach model attributes as buffers so they can be saved and loaded\n",
    "model.register_buffer('dimensions', model_dimensions)\n",
    "model.register_buffer('is_sf_PINN', is_sf_PINN)\n",
    "\n",
    "# Initialize model weights with HE initialization\n",
    "model.apply(ip.init_HE)\n",
    "\n",
    "# # Define learning rate scheduling scheme\n",
    "# scheduler_summed = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#         optimizer, mode='min', factor=0.5, patience=10000\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HE_128wide_nodiff_2rt_100x\n",
      "torch.Size([64320, 2])\n",
      "torch.Size([64320, 2])\n",
      "torch.Size([64320, 2])\n",
      "IcePINN(\n",
      "  (sml): SinusoidalMappingLayer()\n",
      "  (post_sml): Linear(in_features=384, out_features=128, bias=True)\n",
      "  (sin): SinActivation()\n",
      "  (fc_in): Linear(in_features=2, out_features=128, bias=True)\n",
      "  (post_fc_in): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc_hidden): ModuleList(\n",
      "    (0-5): 6 x Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc_out): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gem/Documents/GitHub/PINNs/icepinn.py:187: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(NBAR - NSTAR*torch.sin(2*np.pi*Ntot)).to(device)\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_NAME)\n",
    "print(training_set.shape)\n",
    "print(ip.calc_IcePINN_loss(model, training_set, hard_enforce_IC=hard_enforce_IC).shape)\n",
    "print(ip.enforced_model(training_set, model).shape)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if curriculum_learning:\n",
    "    # First, train without IC enforced (if it wasn't pre-loaded)\n",
    "    if not preload:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "        ip.train_IcePINN(\n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            training_set=training_set, \n",
    "            epochs=100_000, \n",
    "            name=MODEL_NAME, \n",
    "            print_every=1_000,\n",
    "            diffusion=diffusion,\n",
    "            LR_scheduler=None,\n",
    "            enforce_IC=False)\n",
    "    else:\n",
    "        model = ip.load_IcePINN(MODEL_NAME, pre_IC=True)\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing PINN training on 64320 points for 100000 epochs.\n",
      "IC is enforced with an adjustment period of 0.\n",
      "Epoch [0.01k/100k] at 0m 23s: Ntot = 59793.789, Nqll = 13828.994, LR = 1e-05\n",
      "Epoch [0.02k/100k] at 0m 51s: Ntot = 55388.878, Nqll = 11983.685, LR = 1e-05\n",
      "Epoch [0.03k/100k] at 1m 15s: Ntot = 50172.910, Nqll = 10876.886, LR = 1e-05\n",
      "Epoch [0.04k/100k] at 1m 44s: Ntot = 43560.279, Nqll = 9814.727, LR = 1e-05\n",
      "Epoch [0.05k/100k] at 2m 9s: Ntot = 39053.604, Nqll = 9370.179, LR = 1e-05\n",
      "Epoch [0.06k/100k] at 2m 32s: Ntot = 36756.448, Nqll = 8846.043, LR = 1e-05\n",
      "Epoch [0.07k/100k] at 2m 54s: Ntot = 32955.010, Nqll = 8440.046, LR = 1e-05\n",
      "Epoch [0.08k/100k] at 3m 15s: Ntot = 32603.463, Nqll = 8275.501, LR = 1e-05\n",
      "Epoch [0.09k/100k] at 3m 41s: Ntot = 34667.160, Nqll = 8672.254, LR = 1e-05\n",
      "Epoch [0.1k/100k] at 4m 3s: Ntot = 34698.036, Nqll = 8148.263, LR = 1e-05\n",
      "Epoch [0.11k/100k] at 4m 26s: Ntot = 35088.900, Nqll = 8101.458, LR = 1e-05\n",
      "Epoch [0.12k/100k] at 4m 46s: Ntot = 35505.406, Nqll = 8516.913, LR = 1e-05\n",
      "Epoch [0.13k/100k] at 5m 10s: Ntot = 35300.296, Nqll = 8788.981, LR = 1e-05\n",
      "Epoch [0.14k/100k] at 5m 35s: Ntot = 35561.578, Nqll = 8417.668, LR = 1e-05\n",
      "Epoch [0.15k/100k] at 5m 58s: Ntot = 35740.162, Nqll = 8502.862, LR = 1e-05\n",
      "Epoch [0.16k/100k] at 6m 20s: Ntot = 35814.803, Nqll = 8589.369, LR = 1e-05\n",
      "Epoch [0.17k/100k] at 6m 43s: Ntot = 36078.318, Nqll = 8422.157, LR = 1e-05\n",
      "Epoch [0.18k/100k] at 7m 4s: Ntot = 36061.116, Nqll = 8685.778, LR = 1e-05\n",
      "Epoch [0.19k/100k] at 7m 23s: Ntot = 36359.620, Nqll = 8426.477, LR = 1e-05\n",
      "Epoch [0.2k/100k] at 7m 48s: Ntot = 36275.360, Nqll = 8759.677, LR = 1e-05\n",
      "Epoch [0.21k/100k] at 8m 12s: Ntot = 36643.998, Nqll = 8427.892, LR = 1e-05\n",
      "Epoch [0.22k/100k] at 8m 34s: Ntot = 36599.771, Nqll = 8780.679, LR = 1e-05\n",
      "Epoch [0.23k/100k] at 8m 56s: Ntot = 37070.300, Nqll = 8477.880, LR = 1e-05\n",
      "Epoch [0.24k/100k] at 9m 20s: Ntot = 37186.352, Nqll = 8902.430, LR = 1e-05\n",
      "Epoch [0.25k/100k] at 9m 37s: Ntot = 37766.494, Nqll = 8646.297, LR = 1e-05\n",
      "Epoch [0.26k/100k] at 9m 54s: Ntot = 37774.785, Nqll = 9052.537, LR = 1e-05\n",
      "Epoch [0.27k/100k] at 10m 16s: Ntot = 38092.281, Nqll = 8726.743, LR = 1e-05\n",
      "Epoch [0.28k/100k] at 10m 36s: Ntot = 36086.048, Nqll = 8661.618, LR = 1e-05\n",
      "Epoch [0.29k/100k] at 10m 55s: Ntot = 35877.972, Nqll = 8112.457, LR = 1e-05\n",
      "Epoch [0.3k/100k] at 11m 16s: Ntot = 35334.598, Nqll = 8505.872, LR = 1e-05\n",
      "Epoch [0.31k/100k] at 11m 37s: Ntot = 35083.260, Nqll = 8085.668, LR = 1e-05\n",
      "Epoch [0.32k/100k] at 12m 0s: Ntot = 36672.539, Nqll = 8759.392, LR = 1e-05\n",
      "Epoch [0.33k/100k] at 12m 21s: Ntot = 35976.420, Nqll = 8177.490, LR = 1e-05\n",
      "Epoch [0.34k/100k] at 12m 45s: Ntot = 36419.339, Nqll = 8600.728, LR = 1e-05\n",
      "Epoch [0.35k/100k] at 13m 5s: Ntot = 36642.926, Nqll = 8272.831, LR = 1e-05\n",
      "Epoch [0.36k/100k] at 13m 26s: Ntot = 36478.324, Nqll = 8737.484, LR = 1e-05\n",
      "Epoch [0.37k/100k] at 13m 48s: Ntot = 36841.782, Nqll = 8373.599, LR = 1e-05\n",
      "Epoch [0.38k/100k] at 14m 9s: Ntot = 36519.911, Nqll = 8681.995, LR = 1e-05\n",
      "Epoch [0.39k/100k] at 14m 30s: Ntot = 36741.621, Nqll = 8328.859, LR = 1e-05\n",
      "Epoch [0.4k/100k] at 14m 50s: Ntot = 36597.996, Nqll = 8634.345, LR = 1e-05\n",
      "Epoch [0.41k/100k] at 15m 13s: Ntot = 36934.164, Nqll = 8306.666, LR = 1e-05\n",
      "Epoch [0.42k/100k] at 15m 35s: Ntot = 36821.748, Nqll = 8662.125, LR = 1e-05\n",
      "Epoch [0.43k/100k] at 15m 55s: Ntot = 37310.099, Nqll = 8363.595, LR = 1e-05\n",
      "Epoch [0.44k/100k] at 16m 18s: Ntot = 37420.206, Nqll = 8843.687, LR = 1e-05\n",
      "Epoch [0.45k/100k] at 16m 35s: Ntot = 37764.356, Nqll = 8586.527, LR = 1e-05\n",
      "Epoch [0.46k/100k] at 16m 53s: Ntot = 36003.114, Nqll = 8590.404, LR = 1e-05\n",
      "Epoch [0.47k/100k] at 17m 14s: Ntot = 35499.334, Nqll = 7947.865, LR = 1e-05\n",
      "Epoch [0.48k/100k] at 17m 35s: Ntot = 35127.049, Nqll = 8353.197, LR = 1e-05\n",
      "Epoch [0.49k/100k] at 17m 55s: Ntot = 35276.346, Nqll = 7974.613, LR = 1e-05\n",
      "Epoch [0.5k/100k] at 18m 16s: Ntot = 34971.342, Nqll = 8145.749, LR = 1e-05\n",
      "Epoch [0.51k/100k] at 18m 37s: Ntot = 37617.244, Nqll = 8758.134, LR = 1e-05\n",
      "Epoch [0.52k/100k] at 18m 59s: Ntot = 36509.451, Nqll = 8276.606, LR = 1e-05\n",
      "Epoch [0.53k/100k] at 19m 19s: Ntot = 37549.391, Nqll = 8722.202, LR = 1e-05\n",
      "Epoch [0.54k/100k] at 19m 38s: Ntot = 37162.477, Nqll = 8389.051, LR = 1e-05\n",
      "Epoch [0.55k/100k] at 20m 0s: Ntot = 37187.765, Nqll = 8641.489, LR = 1e-05\n",
      "Epoch [0.56k/100k] at 20m 21s: Ntot = 37533.460, Nqll = 8383.639, LR = 1e-05\n",
      "Epoch [0.57k/100k] at 20m 42s: Ntot = 37392.114, Nqll = 8658.599, LR = 1e-05\n",
      "Epoch [0.58k/100k] at 21m 4s: Ntot = 37869.626, Nqll = 8437.698, LR = 1e-05\n",
      "Epoch [0.59k/100k] at 21m 24s: Ntot = 38079.643, Nqll = 8896.897, LR = 1e-05\n",
      "Epoch [0.6k/100k] at 21m 47s: Ntot = 36069.302, Nqll = 8122.266, LR = 1e-05\n",
      "Epoch [0.61k/100k] at 22m 8s: Ntot = 35874.824, Nqll = 8412.282, LR = 1e-05\n",
      "Epoch [0.62k/100k] at 22m 30s: Ntot = 35758.428, Nqll = 8029.567, LR = 1e-05\n",
      "Epoch [0.63k/100k] at 22m 49s: Ntot = 35706.130, Nqll = 8322.688, LR = 1e-05\n",
      "Epoch [0.64k/100k] at 23m 10s: Ntot = 35942.063, Nqll = 8105.026, LR = 1e-05\n",
      "Epoch [0.65k/100k] at 23m 30s: Ntot = 35614.947, Nqll = 8395.200, LR = 1e-05\n",
      "Epoch [0.66k/100k] at 23m 50s: Ntot = 35785.826, Nqll = 8038.763, LR = 1e-05\n",
      "Epoch [0.67k/100k] at 24m 12s: Ntot = 39086.669, Nqll = 9132.179, LR = 1e-05\n",
      "Epoch [0.68k/100k] at 24m 34s: Ntot = 37437.842, Nqll = 8619.009, LR = 1e-05\n",
      "Epoch [0.69k/100k] at 24m 57s: Ntot = 38447.499, Nqll = 8637.992, LR = 1e-05\n",
      "Epoch [0.7k/100k] at 25m 19s: Ntot = 38272.393, Nqll = 8766.535, LR = 1e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m preload:\n\u001b[32m     21\u001b[39m         \u001b[38;5;66;03m# Train normally with IC enforced\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         \u001b[43mip\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_IcePINN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[43mLR_scheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m            \u001b[49m\u001b[43menforce_IC\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhard_enforce_IC\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhard_enforce_IC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m            \u001b[49m\u001b[43madjustment_period\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PINNs/icepinn.py:487\u001b[39m, in \u001b[36mtrain_IcePINN\u001b[39m\u001b[34m(model, optimizer, training_set, epochs, name, print_every, diffusion, LR_scheduler, enforce_IC, hard_enforce_IC, adjustment_period)\u001b[39m\n\u001b[32m    484\u001b[39m optimizer.zero_grad() \n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# evaluate training loss\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m loss = \u001b[43mip\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalc_IcePINN_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43menforce_IC\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_IC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhard_enforce_IC\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mhard_enforce_IC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43madjustment_period\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43madjustment_period\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    495\u001b[39m Ntot_loss = torch.sum(loss[:, \u001b[32m0\u001b[39m]).item()\n\u001b[32m    496\u001b[39m Nqll_loss = torch.sum(loss[:, \u001b[32m1\u001b[39m]).item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PINNs/icepinn.py:375\u001b[39m, in \u001b[36mcalc_IcePINN_loss\u001b[39m\u001b[34m(model, coords, diffusion, epoch, enforce_IC, hard_enforce_IC, adjustment_period)\u001b[39m\n\u001b[32m    372\u001b[39m     adjustment_factor = np.sqrt(epoch/adjustment_period)\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# model predicts output of training_set as batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m ys = \u001b[43menforced_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhard_enforce_IC\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhard_enforce_IC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m=\u001b[49m\u001b[43madjustment_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;66;03m# Calculate and extract gradients\u001b[39;00m\n\u001b[32m    378\u001b[39m dNtot_dt, dNqll_dt, dNqll_dxx = ip.calc_loss_gradients(coords, ys, diffusion)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PINNs/icepinn.py:156\u001b[39m, in \u001b[36menforced_model\u001b[39m\u001b[34m(coords, model, hard_enforce_IC, factor)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03mWrap IcePINN models in this function for training and evaluation to hard-enforce\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[33;03mthe initial condition using reparameterization. To gradually enforce IC during \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \u001b[33;03m  If enforce_IC=True and factor<1.0, output will partially enforce these conditions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m        \n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Get the raw outputs from the network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m nn_out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Expecting shape [batch_size, 2]\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hard_enforce_IC:\n\u001b[32m    159\u001b[39m     t = coords[:, \u001b[32m1\u001b[39m:\u001b[32m2\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PINNs/icepinn.py:80\u001b[39m, in \u001b[36mIcePINN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     77\u001b[39m     x = F.tanh(\u001b[38;5;28mself\u001b[39m.post_fc_in(x))\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc_hidden:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     x = F.tanh(\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     82\u001b[39m x = \u001b[38;5;28mself\u001b[39m.fc_out(x)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "# SGD Nesterov has exploding gradients with LR >=1e-5\n",
    "\n",
    "if curriculum_learning:\n",
    "    # Gradually enforce IC over adjustment_period and keep it enforced\n",
    "    ip.train_IcePINN(\n",
    "        model=model, \n",
    "        optimizer=optimizer, \n",
    "        training_set=training_set, \n",
    "        epochs=200_000, \n",
    "        name=MODEL_NAME, \n",
    "        print_every=1_000,\n",
    "        diffusion=diffusion,\n",
    "        LR_scheduler=None,\n",
    "        enforce_IC=True,\n",
    "        adjustment_period=100_000)\n",
    "\n",
    "else:\n",
    "    if not preload:\n",
    "        # Train normally with IC enforced\n",
    "        ip.train_IcePINN(\n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            training_set=training_set, \n",
    "            epochs=100_000, \n",
    "            name=MODEL_NAME, \n",
    "            print_every=10,\n",
    "            diffusion=diffusion,\n",
    "            LR_scheduler=None,\n",
    "            enforce_IC=True,\n",
    "            hard_enforce_IC=hard_enforce_IC,\n",
    "            adjustment_period=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for future training (LBFGS)\n",
    "model = ip.load_IcePINN(MODEL_NAME)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for L-BFGS optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbfgs_optim = torch.optim.LBFGS(\n",
    "    params=model.parameters(), \n",
    "    lr=0.1,\n",
    "    max_iter=200, \n",
    "    history_size=50\n",
    ")\n",
    "misc_params = ip.get_misc_params()\n",
    "lbfgs_iter_counter = 0\n",
    "lbfgs_print_freq = 1\n",
    "\n",
    "# closure() is called by L-BFGS when you call step() up to max_iter times\n",
    "def closure():\n",
    "    #lbfgs_iter_counter += 1\n",
    "\n",
    "    lbfgs_optim.zero_grad()\n",
    "    loss = ip.calc_IcePINN_loss(model, training_set, misc_params, diffusion, hard_enforce_IC=hard_enforce_IC)\n",
    "    loss.backward(torch.ones_like(loss))\n",
    "\n",
    "    # Gradient clipping to mitigate exploding gradients\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1, norm_type=2)\n",
    "    #nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
    "\n",
    "    #if lbfgs_iter_counter % lbfgs_print_freq == 0:\n",
    "    # sum and print loss\n",
    "    Ntot_loss = torch.sum(loss[:, 0]).item()\n",
    "    Nqll_loss = torch.sum(loss[:, 1]).item()\n",
    "    print(f\"L-BFGS iteration loss: Ntot = {Ntot_loss:.3f}, Nqll = {Nqll_loss:.3f}\")\n",
    "    # {lbfgs_iter_counter}\n",
    "    # Return as a summed scalar loss: required by L-BFGS\n",
    "    return torch.add(Ntot_loss, Nqll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L-BFGS time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LBFGS:    \n",
    "    # lbfgs_iter_counter = 0\n",
    "    # lbfgs_print_freq = 1\n",
    "    epochs = 10\n",
    "    for e in range(epochs):\n",
    "        print(f\"Epoch {e+1}\")\n",
    "        lbfgs_optim.step(closure)\n",
    "\n",
    "    \n",
    "    save_path = './models/'+MODEL_NAME\n",
    "\n",
    "    # Create folder to store model in if necessary\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Save model (not including initial condition wrapper)\n",
    "    # torch.save(model.state_dict(), save_path+'/post_LBFGS_params.pth')\n",
    "    # TODO - update (load) so that it can load LBFGS results\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(training_set[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train some more if needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip.train_IcePINN(\n",
    "#     model=model, \n",
    "#     optimizer=optimizer, \n",
    "#     training_set=training_set, \n",
    "#     epochs=100_000, \n",
    "#     name=MODEL_NAME, \n",
    "#     print_every=1_000, \n",
    "#     diffusion=diffusion,\n",
    "#     LR_scheduler=None,\n",
    "#     enforce_IC=True,\n",
    "#     adjustment_period=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
