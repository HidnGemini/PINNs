{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import f90nml\n",
    "import numpy as np\n",
    "from pint import UnitRegistry; AssignQuantity = UnitRegistry().Quantity\n",
    "from QLCstuff2 import getNQLL\n",
    "import os\n",
    "import reference_solution as refsol\n",
    "from scipy.fft import rfft\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import icepinn as ip\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "device = ip.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in GI parameters\n",
    "inputfile = \"GI parameters - Reference limit cycle (for testing).nml\"\n",
    "GI=f90nml.read(inputfile)['GI']\n",
    "nx_crystal = GI['nx_crystal']\n",
    "L = GI['L']\n",
    "NBAR = GI['Nbar']\n",
    "NSTAR = GI['Nstar']\n",
    "\n",
    "# Define t range\n",
    "RUNTIME = 5\n",
    "NUM_T_STEPS = RUNTIME + 1\n",
    "\n",
    "# Define initial conditions\n",
    "Ntot_init_1D = np.ones(nx_crystal)\n",
    "Nqll_init_1D = getNQLL(Ntot_init_1D,NSTAR,NBAR)\n",
    "\n",
    "# Define x, t pairs for training\n",
    "X_QLC = np.linspace(-L,L,nx_crystal)\n",
    "t_points = np.linspace(0, RUNTIME, NUM_T_STEPS)\n",
    "x, t = np.meshgrid(X_QLC, t_points)\n",
    "training_set = torch.tensor(np.column_stack((x.flatten(), t.flatten()))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model attributes; instantiate model\n",
    "model_dimensions = torch.tensor([8, 80]).to(device)\n",
    "is_sf_PINN = torch.tensor(True)\n",
    "model = ip.IcePINN(\n",
    "\tnum_hidden_layers=model_dimensions[0], \n",
    "\thidden_layer_size=model_dimensions[0],\n",
    "\tis_sf_PINN=is_sf_PINN.item()).to(device)\n",
    "\n",
    "# Attach model attributes as buffers so they can be saved and loaded\n",
    "model.register_buffer('dimensions', model_dimensions)\n",
    "model.register_buffer('is_sf_PINN', is_sf_PINN)\n",
    "\n",
    "# Initialize model weights with HE initialization\n",
    "def init_HE(m):\n",
    "\t\tif type(m) == nn.Linear:\n",
    "\t\t\tnn.init.kaiming_normal_(m.weight)\n",
    "model.apply(init_HE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing PINN training for 50000 epochs.\n",
      "Loss at epoch [1000/50000]: Ntot = 224950.939, Nqll = 183995.374.\n",
      "Loss at epoch [2000/50000]: Ntot = 211704.206, Nqll = 136898.588.\n",
      "Loss at epoch [3000/50000]: Ntot = 465191.361, Nqll = 413599.117.\n",
      "Loss at epoch [4000/50000]: Ntot = 867276.632, Nqll = 676487.454.\n",
      "Loss at epoch [5000/50000]: Ntot = 293638.566, Nqll = 118230.419.\n",
      "Loss at epoch [6000/50000]: Ntot = 805975.467, Nqll = 668814.447.\n",
      "Loss at epoch [7000/50000]: Ntot = 41798.692, Nqll = 14887.578.\n",
      "Loss at epoch [8000/50000]: Ntot = 4635.391, Nqll = 106.896.\n",
      "Loss at epoch [9000/50000]: Ntot = 1127.295, Nqll = 32.371.\n",
      "Loss at epoch [10000/50000]: Ntot = 1397.694, Nqll = 45.347.\n",
      "Loss at epoch [11000/50000]: Ntot = 10089.684, Nqll = 976.601.\n",
      "Loss at epoch [12000/50000]: Ntot = 32960.282, Nqll = 3813.445.\n",
      "Loss at epoch [13000/50000]: Ntot = 120984.805, Nqll = 6034.735.\n",
      "Loss at epoch [14000/50000]: Ntot = 1703738.489, Nqll = 428707.893.\n",
      "Loss at epoch [15000/50000]: Ntot = 431402.147, Nqll = 185353.118.\n",
      "Loss at epoch [16000/50000]: Ntot = 337681.888, Nqll = 2245.696.\n",
      "Loss at epoch [17000/50000]: Ntot = 436950.233, Nqll = 45150.132.\n",
      "Loss at epoch [18000/50000]: Ntot = 151765.941, Nqll = 5015.419.\n",
      "Loss at epoch [19000/50000]: Ntot = 449589.367, Nqll = 304828.766.\n",
      "Loss at epoch [20000/50000]: Ntot = 205188.857, Nqll = 2659.479.\n",
      "Loss at epoch [21000/50000]: Ntot = 175968.164, Nqll = 1408.377.\n",
      "Loss at epoch [22000/50000]: Ntot = 162760.001, Nqll = 396.576.\n",
      "Loss at epoch [23000/50000]: Ntot = 59819.237, Nqll = 98.198.\n",
      "Loss at epoch [24000/50000]: Ntot = 70429.302, Nqll = 211.448.\n",
      "Loss at epoch [25000/50000]: Ntot = 44977.118, Nqll = 514.128.\n",
      "Loss at epoch [26000/50000]: Ntot = 1589.720, Nqll = 1230.460.\n",
      "Loss at epoch [27000/50000]: Ntot = 588133.274, Nqll = 59317.798.\n",
      "Loss at epoch [28000/50000]: Ntot = 2293687.877, Nqll = 881214.153.\n",
      "Loss at epoch [29000/50000]: Ntot = 1006892.744, Nqll = 133868.712.\n",
      "Loss at epoch [30000/50000]: Ntot = 5997829.746, Nqll = 7183296.081.\n",
      "Loss at epoch [31000/50000]: Ntot = 1406705.293, Nqll = 416749.267.\n",
      "Loss at epoch [32000/50000]: Ntot = 313871.567, Nqll = 16276.689.\n",
      "Loss at epoch [33000/50000]: Ntot = 335643.174, Nqll = 17284.179.\n",
      "Loss at epoch [34000/50000]: Ntot = 444992.641, Nqll = 3221.748.\n",
      "Loss at epoch [35000/50000]: Ntot = 233509.459, Nqll = 6097.722.\n",
      "Loss at epoch [36000/50000]: Ntot = 472390.354, Nqll = 1925.458.\n",
      "Loss at epoch [37000/50000]: Ntot = 666919.322, Nqll = 76943.468.\n",
      "Loss at epoch [38000/50000]: Ntot = 685251.638, Nqll = 96487.502.\n",
      "Loss at epoch [39000/50000]: Ntot = 2038927.606, Nqll = 26569.178.\n",
      "Loss at epoch [40000/50000]: Ntot = 963659.631, Nqll = 12609.356.\n",
      "Loss at epoch [41000/50000]: Ntot = 1353897.250, Nqll = 17777.906.\n",
      "Loss at epoch [42000/50000]: Ntot = 34038.428, Nqll = 26459.891.\n",
      "Loss at epoch [43000/50000]: Ntot = 37269.325, Nqll = 12211.434.\n",
      "Loss at epoch [44000/50000]: Ntot = 448817.396, Nqll = 8999.190.\n",
      "Loss at epoch [45000/50000]: Ntot = 69126508.418, Nqll = 66936653.181.\n",
      "Loss at epoch [46000/50000]: Ntot = 2731177.570, Nqll = 2742805.711.\n",
      "Loss at epoch [47000/50000]: Ntot = 2210515.144, Nqll = 2126458.141.\n",
      "Loss at epoch [48000/50000]: Ntot = 561098.559, Nqll = 511173.580.\n",
      "Loss at epoch [49000/50000]: Ntot = 464252.985, Nqll = 197000.105.\n",
      "Loss at epoch [50000/50000]: Ntot = 386878.209, Nqll = 22451.917.\n",
      "Training complete! Model from epoch 25469 has been saved.\n",
      "Saved model Ntot loss: 265.354.\n",
      "Saved model Nqll loss: 13.854.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"TestPINN\"\n",
    "PATH = './models/'+MODEL_NAME\n",
    "\n",
    "ip.train_IcePINN(\n",
    "    model, \n",
    "    optimizer, \n",
    "    training_set, \n",
    "    epochs=50_000, \n",
    "    save_path=PATH, \n",
    "    print_every=1_000, \n",
    "    print_gradients=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
