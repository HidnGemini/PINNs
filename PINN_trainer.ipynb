{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\jonescode\\PINN-capstone\\icepinn.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(NBAR - NSTAR*torch.sin(2*np.pi*Ntot)).to(device)\n"
     ]
    }
   ],
   "source": [
    "import f90nml\n",
    "import numpy as np\n",
    "from pint import UnitRegistry; AssignQuantity = UnitRegistry().Quantity\n",
    "import os\n",
    "import reference_solution as refsol\n",
    "from scipy.fft import rfft\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import icepinn as ip\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "device = ip.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in GI parameters\n",
    "inputfile = \"GI parameters - Reference limit cycle (for testing).nml\"\n",
    "GI=f90nml.read(inputfile)['GI']\n",
    "nx_crystal = GI['nx_crystal']\n",
    "L = GI['L']\n",
    "NBAR = GI['Nbar']\n",
    "NSTAR = GI['Nstar']\n",
    "\n",
    "# Define t range (needs to be same as training file)\n",
    "RUNTIME = 5\n",
    "NUM_T_STEPS = RUNTIME + 1\n",
    "#NUM_T_STEPS = RUNTIME*5 + 1\n",
    "\n",
    "# Define initial conditions\n",
    "Ntot_init = torch.ones(nx_crystal).to(device)\n",
    "Nqll_init = ip.get_Nqll(Ntot_init)\n",
    "\n",
    "# Define x, t pairs for training\n",
    "X_QLC = np.linspace(-L,L,nx_crystal)\n",
    "t_points = np.linspace(0, RUNTIME, NUM_T_STEPS)\n",
    "x, t = np.meshgrid(X_QLC, t_points)\n",
    "training_set = torch.tensor(np.column_stack((x.flatten(), t.flatten()))).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming Legend\n",
    "\n",
    "CL = curriculum learning  \n",
    "SF = SF_Pinn architecture  \n",
    "HE = hard-enforced initial condition    \n",
    "SE = soft-enforced initial condition \n",
    "{n}wide = nodes per FC-layer  \n",
    "nodiff = diffusion term is excluded  \n",
    "LBFGS = LBFGS was used  \n",
    "SGD = SGD with standard momentum  \n",
    "Nesterov = SGD with Nesterov momentum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"SE_128wide_nodiff_Nesterov_LBFGS\"\n",
    "\n",
    "# Hard enforce IC? (soft-enforced otherwise)\n",
    "hard_enforce_IC = False\n",
    "# Curriculum learning? (Only relevant for HE IC)\n",
    "curriculum_learning = False\n",
    "# Pre-load non-IC-enforced model? (CR only)\n",
    "preload = False\n",
    "# Use L-BFGS after initial optimization?\n",
    "LBFGS = True\n",
    "\n",
    "# Define model attributes\n",
    "model_dimensions = torch.tensor([8, 128]).to(device) # [Num hidden layers, Nodes per layer]\n",
    "is_sf_PINN = torch.tensor(False)\n",
    "diffusion = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IcePINN(\n",
       "  (sml): SinusoidalMappingLayer()\n",
       "  (post_sml): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (sin): SinActivation()\n",
       "  (fc_in): Linear(in_features=2, out_features=128, bias=True)\n",
       "  (post_fc_in): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc_hidden): ModuleList(\n",
       "    (0-5): 6 x Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc_out): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = ip.IcePINN(\n",
    "\tnum_hidden_layers=model_dimensions[0], \n",
    "\thidden_layer_size=model_dimensions[1],\n",
    "\tis_sf_PINN=is_sf_PINN.item()).to(device)\n",
    "\n",
    "# Attach model attributes as buffers so they can be saved and loaded\n",
    "model.register_buffer('dimensions', model_dimensions)\n",
    "model.register_buffer('is_sf_PINN', is_sf_PINN)\n",
    "\n",
    "# Initialize model weights with HE initialization\n",
    "model.apply(ip.init_HE)\n",
    "\n",
    "# # Define learning rate scheduling scheme\n",
    "# scheduler_summed = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#         optimizer, mode='min', factor=0.5, patience=10000\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE_128wide_nodiff_Nesterov_LBFGS\n",
      "torch.Size([1920, 2])\n",
      "torch.Size([2240, 2])\n",
      "torch.Size([1920, 2])\n",
      "IcePINN(\n",
      "  (sml): SinusoidalMappingLayer()\n",
      "  (post_sml): Linear(in_features=384, out_features=128, bias=True)\n",
      "  (sin): SinActivation()\n",
      "  (fc_in): Linear(in_features=2, out_features=128, bias=True)\n",
      "  (post_fc_in): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc_hidden): ModuleList(\n",
      "    (0-5): 6 x Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc_out): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\jonescode\\PINN-capstone\\icepinn.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(NBAR - NSTAR*torch.sin(2*np.pi*Ntot)).to(device)\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_NAME)\n",
    "print(training_set.shape)\n",
    "print(ip.calc_cp_loss(model, training_set, ip.get_misc_params(), hard_enforce_IC=hard_enforce_IC).shape)\n",
    "print(ip.enforced_model(training_set, model).shape)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if curriculum_learning:\n",
    "    # First, train without IC enforced (if it wasn't pre-loaded)\n",
    "    if not preload:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "        ip.train_IcePINN(\n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            training_set=training_set, \n",
    "            epochs=100_000, \n",
    "            name=MODEL_NAME, \n",
    "            print_every=1_000,\n",
    "            diffusion=diffusion,\n",
    "            LR_scheduler=None,\n",
    "            enforce_IC=False)\n",
    "    else:\n",
    "        model = ip.load_IcePINN(MODEL_NAME, pre_IC=True)\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing PINN training on 1920 points for 100000 epochs.\n",
      "IC is enforced with an adjustment period of 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\jonescode\\PINN-capstone\\venv\\lib\\site-packages\\torch\\autograd\\graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:180.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1k/100k] at 0m 13s: Ntot = 454.456, Nqll = 109.160, LR = 0.001\n",
      "Epoch [2k/100k] at 0m 25s: Ntot = 481.400, Nqll = 117.909, LR = 0.001\n",
      "Epoch [3k/100k] at 0m 37s: Ntot = 517.216, Nqll = 126.883, LR = 0.001\n",
      "Epoch [4k/100k] at 0m 49s: Ntot = 542.154, Nqll = 131.055, LR = 0.001\n",
      "Epoch [5k/100k] at 1m 2s: Ntot = 562.760, Nqll = 133.559, LR = 0.001\n",
      "Epoch [6k/100k] at 1m 14s: Ntot = 601.441, Nqll = 141.002, LR = 0.001\n",
      "Epoch [7k/100k] at 1m 26s: Ntot = 657.666, Nqll = 153.327, LR = 0.001\n",
      "Epoch [8k/100k] at 1m 38s: Ntot = 735.410, Nqll = 171.870, LR = 0.001\n",
      "Epoch [9k/100k] at 1m 50s: Ntot = 834.408, Nqll = 195.618, LR = 0.001\n",
      "Epoch [10k/100k] at 2m 3s: Ntot = 940.872, Nqll = 219.873, LR = 0.001\n",
      "Training 1/10ths complete! Completion estimate: 20m 30s | 18m 27s remaining.\n",
      "Best model saved so far: Epoch 164; Loss: 317.091 Ntot, 89.133 Nqll\n",
      "Epoch [11k/100k] at 2m 15s: Ntot = 1025.866, Nqll = 238.694, LR = 0.001\n",
      "Epoch [12k/100k] at 2m 28s: Ntot = 1025.369, Nqll = 238.647, LR = 0.001\n",
      "Epoch [13k/100k] at 2m 40s: Ntot = 1007.822, Nqll = 236.149, LR = 0.001\n",
      "Epoch [14k/100k] at 2m 52s: Ntot = 1032.783, Nqll = 242.320, LR = 0.001\n",
      "Epoch [15k/100k] at 3m 5s: Ntot = 1066.320, Nqll = 250.102, LR = 0.001\n",
      "Epoch [16k/100k] at 3m 18s: Ntot = 1077.716, Nqll = 253.999, LR = 0.001\n",
      "Epoch [17k/100k] at 3m 30s: Ntot = 1114.402, Nqll = 268.341, LR = 0.001\n",
      "Epoch [18k/100k] at 3m 42s: Ntot = 1276.664, Nqll = 303.237, LR = 0.001\n",
      "Epoch [19k/100k] at 3m 54s: Ntot = 1576.288, Nqll = 356.586, LR = 0.001\n",
      "Epoch [20k/100k] at 4m 6s: Ntot = 1614.493, Nqll = 363.062, LR = 0.001\n",
      "Training 2/10ths complete! Completion estimate: 20m 30s | 16m 24s remaining.\n",
      "Best model saved so far: Epoch 164; Loss: 317.091 Ntot, 89.133 Nqll\n",
      "Epoch [21k/100k] at 4m 18s: Ntot = 1707.292, Nqll = 387.990, LR = 0.001\n",
      "Epoch [22k/100k] at 4m 30s: Ntot = 1663.733, Nqll = 386.270, LR = 0.001\n",
      "Epoch [23k/100k] at 4m 42s: Ntot = 1662.928, Nqll = 388.873, LR = 0.001\n",
      "Epoch [24k/100k] at 4m 54s: Ntot = 1679.888, Nqll = 392.355, LR = 0.001\n",
      "Epoch [25k/100k] at 5m 5s: Ntot = 1652.952, Nqll = 386.166, LR = 0.001\n",
      "Epoch [26k/100k] at 5m 17s: Ntot = 1403.272, Nqll = 337.115, LR = 0.001\n",
      "Epoch [27k/100k] at 5m 29s: Ntot = 1464.314, Nqll = 337.313, LR = 0.001\n",
      "Epoch [28k/100k] at 5m 40s: Ntot = 1739.008, Nqll = 331.346, LR = 0.001\n",
      "Epoch [29k/100k] at 5m 52s: Ntot = 1582.262, Nqll = 360.541, LR = 0.001\n",
      "Epoch [30k/100k] at 6m 4s: Ntot = 1574.467, Nqll = 359.041, LR = 0.001\n",
      "Training 3/10ths complete! Completion estimate: 20m 10s | 14m 7s remaining.\n",
      "Best model saved so far: Epoch 164; Loss: 317.091 Ntot, 89.133 Nqll\n",
      "Epoch [31k/100k] at 6m 16s: Ntot = 1554.840, Nqll = 354.304, LR = 0.001\n",
      "Epoch [32k/100k] at 6m 28s: Ntot = 1534.748, Nqll = 349.177, LR = 0.001\n",
      "Epoch [33k/100k] at 6m 41s: Ntot = 1505.078, Nqll = 342.160, LR = 0.001\n",
      "Epoch [34k/100k] at 6m 53s: Ntot = 1476.277, Nqll = 335.948, LR = 0.001\n",
      "Epoch [35k/100k] at 7m 5s: Ntot = 1462.166, Nqll = 333.684, LR = 0.001\n",
      "Epoch [36k/100k] at 7m 17s: Ntot = 1466.076, Nqll = 335.344, LR = 0.001\n",
      "Epoch [37k/100k] at 7m 29s: Ntot = 1475.342, Nqll = 338.384, LR = 0.001\n",
      "Epoch [38k/100k] at 7m 41s: Ntot = 1484.948, Nqll = 341.637, LR = 0.001\n",
      "Epoch [39k/100k] at 7m 53s: Ntot = 1550.550, Nqll = 358.479, LR = 0.001\n",
      "Epoch [40k/100k] at 8m 5s: Ntot = 2280.426, Nqll = 526.760, LR = 0.001\n",
      "Training 4/10ths complete! Completion estimate: 20m 10s | 12m 6s remaining.\n",
      "Best model saved so far: Epoch 164; Loss: 317.091 Ntot, 89.133 Nqll\n",
      "Epoch [41k/100k] at 8m 17s: Ntot = 2342.561, Nqll = 539.643, LR = 0.001\n",
      "Epoch [42k/100k] at 8m 29s: Ntot = 2339.013, Nqll = 544.085, LR = 0.001\n",
      "Epoch [43k/100k] at 8m 41s: Ntot = 2331.105, Nqll = 542.186, LR = 0.001\n",
      "Epoch [44k/100k] at 8m 53s: Ntot = 2213.704, Nqll = 511.179, LR = 0.001\n",
      "Epoch [45k/100k] at 9m 4s: Ntot = 1761.463, Nqll = 405.669, LR = 0.001\n",
      "Epoch [46k/100k] at 9m 16s: Ntot = 1529.589, Nqll = 349.821, LR = 0.001\n",
      "Epoch [47k/100k] at 9m 28s: Ntot = 1506.446, Nqll = 345.320, LR = 0.001\n",
      "Epoch [48k/100k] at 9m 39s: Ntot = 1613.815, Nqll = 370.913, LR = 0.001\n",
      "Epoch [49k/100k] at 9m 51s: Ntot = 1775.490, Nqll = 413.788, LR = 0.001\n",
      "Epoch [50k/100k] at 10m 4s: Ntot = 2586.744, Nqll = 596.877, LR = 0.001\n",
      "Training 5/10ths complete! Completion estimate: 20m 0s | 10m 0s remaining.\n",
      "Best model saved so far: Epoch 164; Loss: 317.091 Ntot, 89.133 Nqll\n",
      "Epoch [51k/100k] at 10m 16s: Ntot = 2433.027, Nqll = 566.740, LR = 0.001\n",
      "Epoch [52k/100k] at 10m 28s: Ntot = 2195.274, Nqll = 511.722, LR = 0.001\n",
      "Epoch [53k/100k] at 10m 40s: Ntot = 2345.791, Nqll = 554.655, LR = 0.001\n",
      "Epoch [54k/100k] at 10m 52s: Ntot = 2223.055, Nqll = 524.621, LR = 0.001\n",
      "Epoch [55k/100k] at 11m 4s: Ntot = 2136.842, Nqll = 502.140, LR = 0.001\n",
      "Epoch [56k/100k] at 11m 16s: Ntot = 2010.157, Nqll = 473.181, LR = 0.001\n",
      "Epoch [57k/100k] at 11m 28s: Ntot = 1884.968, Nqll = 442.206, LR = 0.001\n",
      "Epoch [58k/100k] at 11m 40s: Ntot = 1817.028, Nqll = 425.451, LR = 0.001\n",
      "Epoch [59k/100k] at 11m 52s: Ntot = 1769.611, Nqll = 364.483, LR = 0.001\n",
      "Epoch [60k/100k] at 12m 4s: Ntot = 1793.350, Nqll = 408.878, LR = 0.001\n",
      "Training 6/10ths complete! Completion estimate: 20m 0s | 8m 0s remaining.\n",
      "Best model saved so far: Epoch 164; Loss: 317.091 Ntot, 89.133 Nqll\n",
      "Epoch [61k/100k] at 12m 16s: Ntot = 1762.338, Nqll = 408.736, LR = 0.001\n",
      "Epoch [62k/100k] at 12m 28s: Ntot = 1745.357, Nqll = 411.775, LR = 0.001\n",
      "Epoch [63k/100k] at 12m 40s: Ntot = 1722.502, Nqll = 397.944, LR = 0.001\n",
      "Epoch [64k/100k] at 12m 52s: Ntot = 1735.960, Nqll = 401.819, LR = 0.001\n",
      "Epoch [65k/100k] at 13m 3s: Ntot = 1743.884, Nqll = 402.538, LR = 0.001\n",
      "Epoch [66k/100k] at 13m 15s: Ntot = 1733.194, Nqll = 399.733, LR = 0.001\n",
      "Epoch [67k/100k] at 13m 27s: Ntot = 1718.487, Nqll = 396.440, LR = 0.001\n",
      "Epoch [68k/100k] at 13m 39s: Ntot = 1705.108, Nqll = 392.984, LR = 0.001\n",
      "Epoch [69k/100k] at 13m 51s: Ntot = 1707.710, Nqll = 386.755, LR = 0.001\n",
      "Epoch [70k/100k] at 14m 3s: Ntot = 1807.880, Nqll = 411.044, LR = 0.001\n",
      "Training 7/10ths complete! Completion estimate: 20m 0s | 6m 0s remaining.\n",
      "Best model saved so far: Epoch 164; Loss: 317.091 Ntot, 89.133 Nqll\n",
      "Epoch [71k/100k] at 14m 15s: Ntot = 1808.567, Nqll = 416.475, LR = 0.001\n",
      "Epoch [72k/100k] at 14m 27s: Ntot = 1845.712, Nqll = 420.907, LR = 0.001\n",
      "Epoch [73k/100k] at 14m 40s: Ntot = 1794.057, Nqll = 414.416, LR = 0.001\n",
      "Epoch [74k/100k] at 14m 52s: Ntot = 1795.736, Nqll = 411.868, LR = 0.001\n",
      "Epoch [75k/100k] at 15m 4s: Ntot = 1783.906, Nqll = 406.597, LR = 0.001\n",
      "Epoch [76k/100k] at 15m 16s: Ntot = 1706.291, Nqll = 394.618, LR = 0.001\n",
      "Epoch [77k/100k] at 15m 28s: Ntot = 1669.205, Nqll = 394.295, LR = 0.001\n",
      "Epoch [78k/100k] at 15m 40s: Ntot = 1755.536, Nqll = 400.812, LR = 0.001\n",
      "Epoch [79k/100k] at 15m 52s: Ntot = 1656.171, Nqll = 380.439, LR = 0.001\n",
      "Epoch [80k/100k] at 16m 4s: Ntot = 1661.773, Nqll = 382.221, LR = 0.001\n",
      "Training 8/10ths complete! Completion estimate: 20m 0s | 4m 0s remaining.\n",
      "Best model saved so far: Epoch 164; Loss: 317.091 Ntot, 89.133 Nqll\n",
      "Epoch [81k/100k] at 16m 16s: Ntot = 1694.672, Nqll = 387.098, LR = 0.001\n",
      "Epoch [82k/100k] at 16m 28s: Ntot = 1759.016, Nqll = 399.369, LR = 0.001\n",
      "Epoch [83k/100k] at 16m 40s: Ntot = 1655.882, Nqll = 380.087, LR = 0.001\n",
      "Epoch [84k/100k] at 16m 53s: Ntot = 1715.125, Nqll = 396.646, LR = 0.001\n",
      "Epoch [85k/100k] at 17m 4s: Ntot = 2179.288, Nqll = 508.980, LR = 0.001\n",
      "Epoch [86k/100k] at 17m 16s: Ntot = 2246.246, Nqll = 513.942, LR = 0.001\n",
      "Epoch [87k/100k] at 17m 29s: Ntot = 2114.314, Nqll = 480.990, LR = 0.001\n",
      "Epoch [88k/100k] at 17m 41s: Ntot = 2255.275, Nqll = 520.005, LR = 0.001\n",
      "Epoch [89k/100k] at 17m 53s: Ntot = 2057.823, Nqll = 481.941, LR = 0.001\n",
      "Epoch [90k/100k] at 18m 5s: Ntot = 2249.508, Nqll = 519.013, LR = 0.001\n",
      "Training 9/10ths complete! Completion estimate: 20m 0s | 2m 0s remaining.\n",
      "Best model saved so far: Epoch 164; Loss: 317.091 Ntot, 89.133 Nqll\n",
      "Epoch [91k/100k] at 18m 17s: Ntot = 1844.389, Nqll = 421.116, LR = 0.001\n",
      "Epoch [92k/100k] at 18m 30s: Ntot = 1878.170, Nqll = 423.504, LR = 0.001\n",
      "Epoch [93k/100k] at 18m 42s: Ntot = 1837.963, Nqll = 422.791, LR = 0.001\n",
      "Epoch [94k/100k] at 18m 54s: Ntot = 2007.645, Nqll = 456.498, LR = 0.001\n",
      "Epoch [95k/100k] at 19m 7s: Ntot = 1787.087, Nqll = 402.371, LR = 0.001\n",
      "Epoch [96k/100k] at 19m 19s: Ntot = 1930.037, Nqll = 436.774, LR = 0.001\n",
      "Epoch [97k/100k] at 19m 31s: Ntot = 1515.843, Nqll = 346.094, LR = 0.001\n",
      "Epoch [98k/100k] at 19m 43s: Ntot = 1715.464, Nqll = 394.761, LR = 0.001\n",
      "Epoch [99k/100k] at 19m 56s: Ntot = 1598.092, Nqll = 363.435, LR = 0.001\n",
      "Epoch [100k/100k] at 20m 8s: Ntot = 1595.774, Nqll = 361.521, LR = 0.001\n",
      "Best model saved so far: Epoch 164; Loss: 317.091 Ntot, 89.133 Nqll\n",
      "Training complete after 20 minutes and 8 seconds\n",
      "Model SE_128wide_nodiff_Nesterov_LBFGS from epoch 164 has been saved.\n",
      "Saved model Ntot loss: 317.091.\n",
      "Saved model Nqll loss: 89.133.\n"
     ]
    }
   ],
   "source": [
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "# SGD Nesterov has exploding gradients with LR >=1e-5\n",
    "\n",
    "if curriculum_learning:\n",
    "    # Gradually enforce IC over adjustment_period and keep it enforced\n",
    "    ip.train_IcePINN(\n",
    "        model=model, \n",
    "        optimizer=optimizer, \n",
    "        training_set=training_set, \n",
    "        epochs=200_000, \n",
    "        name=MODEL_NAME, \n",
    "        print_every=1_000,\n",
    "        diffusion=diffusion,\n",
    "        LR_scheduler=None,\n",
    "        enforce_IC=True,\n",
    "        adjustment_period=100_000)\n",
    "\n",
    "else:\n",
    "    if not preload:\n",
    "        # Train normally with IC enforced\n",
    "        ip.train_IcePINN(\n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            training_set=training_set, \n",
    "            epochs=100_000, \n",
    "            name=MODEL_NAME, \n",
    "            print_every=1_000,\n",
    "            diffusion=diffusion,\n",
    "            LR_scheduler=None,\n",
    "            enforce_IC=True,\n",
    "            hard_enforce_IC=hard_enforce_IC,\n",
    "            adjustment_period=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IcePINN(\n",
       "  (sml): SinusoidalMappingLayer()\n",
       "  (post_sml): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (sin): SinActivation()\n",
       "  (fc_in): Linear(in_features=2, out_features=128, bias=True)\n",
       "  (post_fc_in): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc_hidden): ModuleList(\n",
       "    (0-5): 6 x Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc_out): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model for future training (LBFGS)\n",
    "model = ip.load_IcePINN(MODEL_NAME)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for L-BFGS optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbfgs_optim = torch.optim.LBFGS(\n",
    "    params=model.parameters(), \n",
    "    lr=0.1,\n",
    "    max_iter=5_000, \n",
    "    history_size=5_000\n",
    ")\n",
    "misc_params = ip.get_misc_params()\n",
    "lbfgs_iter_counter = 0\n",
    "lbfgs_print_freq = 1\n",
    "\n",
    "# closure() is called by L-BFGS when you call step() up to max_iter times\n",
    "def closure():\n",
    "    #lbfgs_iter_counter += 1\n",
    "\n",
    "    lbfgs_optim.zero_grad()\n",
    "    loss = ip.calc_cp_loss(model, training_set, misc_params, diffusion, hard_enforce_IC=hard_enforce_IC)\n",
    "    loss.backward(torch.ones_like(loss))\n",
    "\n",
    "    # Gradient clipping to mitigate exploding gradients\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5, norm_type=2)\n",
    "    #nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
    "\n",
    "    #if lbfgs_iter_counter % lbfgs_print_freq == 0:\n",
    "    # sum and print loss\n",
    "    Ntot_loss = torch.sum(loss[:, 0]).item()\n",
    "    Nqll_loss = torch.sum(loss[:, 1]).item()\n",
    "    print(f\"L-BFGS iteration loss: Ntot = {Ntot_loss:.3f}, Nqll = {Nqll_loss:.3f}\")\n",
    "    # {lbfgs_iter_counter}\n",
    "    # Return as a summed scalar loss: required by L-BFGS\n",
    "    return torch.add(Ntot_loss, Nqll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L-BFGS time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-BFGS iteration loss: Ntot = 317.091, Nqll = 89.133\n",
      "L-BFGS iteration loss: Ntot = 316.423, Nqll = 88.339\n",
      "L-BFGS iteration loss: Ntot = 351.050, Nqll = 293.601\n",
      "L-BFGS iteration loss: Ntot = 347.180, Nqll = 273.325\n",
      "L-BFGS iteration loss: Ntot = 86892.196, Nqll = 395491.398\n",
      "L-BFGS iteration loss: Ntot = 696502.010, Nqll = 3247856.370\n",
      "L-BFGS iteration loss: Ntot = 618671.796, Nqll = 2888325.903\n",
      "L-BFGS iteration loss: Ntot = 538281.713, Nqll = 2514530.020\n",
      "L-BFGS iteration loss: Ntot = 288290.665, Nqll = 1337967.064\n",
      "L-BFGS iteration loss: Ntot = 170248.123, Nqll = 797351.640\n",
      "L-BFGS iteration loss: Ntot = 9124.398, Nqll = 40669.927\n",
      "L-BFGS iteration loss: Ntot = 3442.931, Nqll = 14314.331\n",
      "L-BFGS iteration loss: Ntot = 3364.412, Nqll = 14009.489\n",
      "L-BFGS iteration loss: Ntot = 567364.331, Nqll = 2677201.801\n",
      "L-BFGS iteration loss: Ntot = 445289.066, Nqll = 2064409.547\n",
      "L-BFGS iteration loss: Ntot = 314427.312, Nqll = 1450019.925\n",
      "L-BFGS iteration loss: Ntot = 190907.483, Nqll = 1027686.378\n",
      "L-BFGS iteration loss: Ntot = 88963.433, Nqll = 407811.115\n",
      "L-BFGS iteration loss: Ntot = 10615.602, Nqll = 44687.169\n",
      "L-BFGS iteration loss: Ntot = 13721.771, Nqll = 60448.463\n",
      "L-BFGS iteration loss: Ntot = 4257.047, Nqll = 15949.638\n",
      "L-BFGS iteration loss: Ntot = 4172.328, Nqll = 15547.324\n",
      "L-BFGS iteration loss: Ntot = 4081.030, Nqll = 15133.830\n",
      "L-BFGS iteration loss: Ntot = 3988.597, Nqll = 14726.220\n",
      "L-BFGS iteration loss: Ntot = 3897.503, Nqll = 14339.533\n",
      "L-BFGS iteration loss: Ntot = 2045.419, Nqll = 6345.593\n",
      "L-BFGS iteration loss: Ntot = 1621.153, Nqll = 4540.373\n",
      "L-BFGS iteration loss: Ntot = 1571.952, Nqll = 4394.036\n",
      "L-BFGS iteration loss: Ntot = 1346.568, Nqll = 3369.663\n",
      "L-BFGS iteration loss: Ntot = 927.676, Nqll = 1702.015\n",
      "L-BFGS iteration loss: Ntot = 882.043, Nqll = 1389.674\n",
      "L-BFGS iteration loss: Ntot = 825.147, Nqll = 1256.335\n",
      "L-BFGS iteration loss: Ntot = 68546.092, Nqll = 327265.485\n",
      "L-BFGS iteration loss: Ntot = 47225.433, Nqll = 234245.287\n",
      "L-BFGS iteration loss: Ntot = 29347.301, Nqll = 152395.906\n",
      "L-BFGS iteration loss: Ntot = 15664.950, Nqll = 85197.115\n",
      "L-BFGS iteration loss: Ntot = 6528.188, Nqll = 38879.114\n",
      "L-BFGS iteration loss: Ntot = 2059.377, Nqll = 10806.221\n",
      "L-BFGS iteration loss: Ntot = 804634.058, Nqll = 3743638.339\n",
      "L-BFGS iteration loss: Ntot = 708757.442, Nqll = 3289313.848\n",
      "L-BFGS iteration loss: Ntot = 130897.474, Nqll = 592184.291\n",
      "L-BFGS iteration loss: Ntot = 31612.815, Nqll = 134181.851\n",
      "L-BFGS iteration loss: Ntot = 160274.693, Nqll = 741652.356\n",
      "L-BFGS iteration loss: Ntot = 139508.763, Nqll = 641662.729\n",
      "L-BFGS iteration loss: Ntot = 13019.943, Nqll = 36868.096\n",
      "L-BFGS iteration loss: Ntot = 3532956.433, Nqll = 16782471.674\n",
      "L-BFGS iteration loss: Ntot = 1696859.293, Nqll = 8080032.443\n",
      "L-BFGS iteration loss: Ntot = 509402.851, Nqll = 2395354.212\n",
      "L-BFGS iteration loss: Ntot = 397346.277, Nqll = 1897468.231\n",
      "L-BFGS iteration loss: Ntot = 371955.205, Nqll = 1741359.732\n",
      "L-BFGS iteration loss: Ntot = 340532.451, Nqll = 1592161.434\n",
      "L-BFGS iteration loss: Ntot = 309716.097, Nqll = 1446698.441\n",
      "L-BFGS iteration loss: Ntot = 65060.152, Nqll = 426313.575\n",
      "L-BFGS iteration loss: Ntot = 49421.044, Nqll = 347007.880\n",
      "L-BFGS iteration loss: Ntot = 37285.081, Nqll = 246932.211\n",
      "L-BFGS iteration loss: Ntot = 27692.312, Nqll = 168953.578\n",
      "L-BFGS iteration loss: Ntot = 20645.845, Nqll = 121918.433\n",
      "L-BFGS iteration loss: Ntot = 39506.096, Nqll = 190453.736\n",
      "L-BFGS iteration loss: Ntot = 36089.333, Nqll = 171949.962\n",
      "L-BFGS iteration loss: Ntot = 21787.586, Nqll = 112292.909\n",
      "L-BFGS iteration loss: Ntot = 14668.687, Nqll = 345070.474\n",
      "L-BFGS iteration loss: Ntot = 20406.713, Nqll = 2929869.382\n",
      "L-BFGS iteration loss: Ntot = 22200.739, Nqll = 801637.556\n",
      "L-BFGS iteration loss: Ntot = 67529.924, Nqll = 308542.662\n",
      "L-BFGS iteration loss: Ntot = 63358.893, Nqll = 288440.986\n",
      "L-BFGS iteration loss: Ntot = 59246.835, Nqll = 269183.046\n",
      "L-BFGS iteration loss: Ntot = 55220.656, Nqll = 250623.005\n",
      "L-BFGS iteration loss: Ntot = 51282.996, Nqll = 232593.491\n",
      "L-BFGS iteration loss: Ntot = 47425.528, Nqll = 215001.534\n",
      "L-BFGS iteration loss: Ntot = 43636.559, Nqll = 197775.916\n",
      "L-BFGS iteration loss: Ntot = 39903.537, Nqll = 180859.929\n",
      "L-BFGS iteration loss: Ntot = 36213.906, Nqll = 164210.127\n",
      "L-BFGS iteration loss: Ntot = 32556.593, Nqll = 147774.673\n",
      "L-BFGS iteration loss: Ntot = 28930.598, Nqll = 131416.481\n",
      "L-BFGS iteration loss: Ntot = 25317.671, Nqll = 115519.456\n",
      "L-BFGS iteration loss: Ntot = 21852.098, Nqll = 101361.917\n",
      "L-BFGS iteration loss: Ntot = 18293.791, Nqll = 85982.602\n",
      "L-BFGS iteration loss: Ntot = 15409.396, Nqll = 127920.458\n",
      "L-BFGS iteration loss: Ntot = 8667.516, Nqll = 37444.593\n",
      "L-BFGS iteration loss: Ntot = 5261.841, Nqll = 22584.959\n",
      "L-BFGS iteration loss: Ntot = 5091.889, Nqll = 22518.227\n",
      "L-BFGS iteration loss: Ntot = 4987.909, Nqll = 22123.776\n",
      "L-BFGS iteration loss: Ntot = 4400.530, Nqll = 51281.239\n",
      "L-BFGS iteration loss: Ntot = 3540.487, Nqll = 14467.283\n",
      "L-BFGS iteration loss: Ntot = 3406.300, Nqll = 13627.611\n",
      "L-BFGS iteration loss: Ntot = 3206.879, Nqll = 12659.433\n",
      "L-BFGS iteration loss: Ntot = 3020.166, Nqll = 11916.814\n",
      "L-BFGS iteration loss: Ntot = 2836.338, Nqll = 10982.046\n",
      "L-BFGS iteration loss: Ntot = 2646.224, Nqll = 33124.831\n",
      "L-BFGS iteration loss: Ntot = 2290.657, Nqll = 12164.339\n",
      "L-BFGS iteration loss: Ntot = 1351.695, Nqll = 3356.447\n",
      "L-BFGS iteration loss: Ntot = 1321.811, Nqll = 3198.866\n",
      "L-BFGS iteration loss: Ntot = 1292.830, Nqll = 3049.497\n",
      "L-BFGS iteration loss: Ntot = 1264.652, Nqll = 2913.680\n",
      "L-BFGS iteration loss: Ntot = 1237.221, Nqll = 2804.513\n",
      "L-BFGS iteration loss: Ntot = 1210.528, Nqll = 2749.525\n",
      "L-BFGS iteration loss: Ntot = 1184.424, Nqll = 2799.423\n",
      "L-BFGS iteration loss: Ntot = 1157.683, Nqll = 3038.981\n",
      "L-BFGS iteration loss: Ntot = 1125.418, Nqll = 3607.728\n",
      "L-BFGS iteration loss: Ntot = 1082.759, Nqll = 4593.855\n",
      "L-BFGS iteration loss: Ntot = 1064.983, Nqll = 4800.280\n",
      "L-BFGS iteration loss: Ntot = 1280.938, Nqll = 13886.635\n",
      "L-BFGS iteration loss: Ntot = 9889.229, Nqll = 828380.155\n",
      "L-BFGS iteration loss: Ntot = 3643.817, Nqll = 15273.343\n",
      "L-BFGS iteration loss: Ntot = 2532.136, Nqll = 9815.528\n",
      "L-BFGS iteration loss: Ntot = 611.397, Nqll = 679.522\n",
      "L-BFGS iteration loss: Ntot = 3674.243, Nqll = 14215.697\n",
      "L-BFGS iteration loss: Ntot = 3481.216, Nqll = 13338.296\n",
      "L-BFGS iteration loss: Ntot = 3293.358, Nqll = 12485.435\n",
      "L-BFGS iteration loss: Ntot = 3110.477, Nqll = 11656.295\n",
      "L-BFGS iteration loss: Ntot = 2932.386, Nqll = 10850.071\n",
      "L-BFGS iteration loss: Ntot = 2758.902, Nqll = 10065.985\n",
      "L-BFGS iteration loss: Ntot = 2589.852, Nqll = 9303.297\n",
      "L-BFGS iteration loss: Ntot = 2425.075, Nqll = 8561.326\n",
      "L-BFGS iteration loss: Ntot = 2264.428, Nqll = 7839.472\n",
      "L-BFGS iteration loss: Ntot = 2107.796, Nqll = 7137.247\n",
      "L-BFGS iteration loss: Ntot = 1955.098, Nqll = 6454.316\n",
      "L-BFGS iteration loss: Ntot = 1806.302, Nqll = 5790.547\n",
      "L-BFGS iteration loss: Ntot = 1661.441, Nqll = 5146.085\n",
      "L-BFGS iteration loss: Ntot = 1520.636, Nqll = 4521.443\n",
      "L-BFGS iteration loss: Ntot = 1384.126, Nqll = 3917.627\n",
      "L-BFGS iteration loss: Ntot = 1252.306, Nqll = 3336.295\n",
      "L-BFGS iteration loss: Ntot = 1125.779, Nqll = 2779.978\n",
      "L-BFGS iteration loss: Ntot = 1005.422, Nqll = 2252.370\n",
      "L-BFGS iteration loss: Ntot = 892.479, Nqll = 1758.706\n",
      "L-BFGS iteration loss: Ntot = 788.671, Nqll = 1306.274\n",
      "L-BFGS iteration loss: Ntot = 696.348, Nqll = 905.082\n",
      "L-BFGS iteration loss: Ntot = 618.675, Nqll = 568.736\n",
      "L-BFGS iteration loss: Ntot = 559.854, Nqll = 315.575\n",
      "L-BFGS iteration loss: Ntot = 525.354, Nqll = 170.096\n",
      "L-BFGS iteration loss: Ntot = 521.423, Nqll = 163.761\n",
      "L-BFGS iteration loss: Ntot = 519.570, Nqll = 160.201\n",
      "L-BFGS iteration loss: Ntot = 517.637, Nqll = 157.037\n",
      "L-BFGS iteration loss: Ntot = 515.586, Nqll = 154.261\n",
      "L-BFGS iteration loss: Ntot = 513.363, Nqll = 151.867\n",
      "L-BFGS iteration loss: Ntot = 510.896, Nqll = 149.846\n",
      "L-BFGS iteration loss: Ntot = 508.087, Nqll = 148.183\n",
      "L-BFGS iteration loss: Ntot = 504.805, Nqll = 146.861\n",
      "L-BFGS iteration loss: Ntot = 500.912, Nqll = 145.852\n",
      "L-BFGS iteration loss: Ntot = 496.348, Nqll = 145.116\n",
      "L-BFGS iteration loss: Ntot = 491.298, Nqll = 144.599\n",
      "L-BFGS iteration loss: Ntot = 486.178, Nqll = 144.228\n",
      "L-BFGS iteration loss: Ntot = 442.261, Nqll = 302.146\n",
      "L-BFGS iteration loss: Ntot = 435.553, Nqll = 265.070\n",
      "L-BFGS iteration loss: Ntot = 414.691, Nqll = 144.585\n",
      "L-BFGS iteration loss: Ntot = 413.810, Nqll = 140.825\n",
      "L-BFGS iteration loss: Ntot = 444385.927, Nqll = 2020262.284\n",
      "L-BFGS iteration loss: Ntot = 390312.241, Nqll = 1771082.224\n",
      "L-BFGS iteration loss: Ntot = 59475.967, Nqll = 248283.197\n",
      "L-BFGS iteration loss: Ntot = 13351.006, Nqll = 40062.979\n",
      "L-BFGS iteration loss: Ntot = 52156.163, Nqll = 236165.232\n",
      "L-BFGS iteration loss: Ntot = 48398.279, Nqll = 218551.595\n",
      "L-BFGS iteration loss: Ntot = 44239.392, Nqll = 199014.027\n",
      "L-BFGS iteration loss: Ntot = 39180.685, Nqll = 175152.108\n",
      "L-BFGS iteration loss: Ntot = 32625.207, Nqll = 144092.503\n",
      "L-BFGS iteration loss: Ntot = 24613.582, Nqll = 106125.525\n",
      "L-BFGS iteration loss: Ntot = 16382.620, Nqll = 67314.544\n",
      "L-BFGS iteration loss: Ntot = 9430.524, Nqll = 34708.397\n",
      "L-BFGS iteration loss: Ntot = 4674.933, Nqll = 12555.937\n",
      "L-BFGS iteration loss: Ntot = 44601.106, Nqll = 200754.074\n",
      "L-BFGS iteration loss: Ntot = 10110.903, Nqll = 44191.275\n",
      "L-BFGS iteration loss: Ntot = 10870.101, Nqll = 563660.995\n",
      "L-BFGS iteration loss: Ntot = 4490.775, Nqll = 18518.097\n",
      "L-BFGS iteration loss: Ntot = 4271.847, Nqll = 17440.014\n",
      "L-BFGS iteration loss: Ntot = 3251.065, Nqll = 14020.945\n",
      "L-BFGS iteration loss: Ntot = 2446.003, Nqll = 12152.999\n",
      "L-BFGS iteration loss: Ntot = 2351.211, Nqll = 73194.334\n",
      "L-BFGS iteration loss: Ntot = 1327.836, Nqll = 11487.696\n",
      "L-BFGS iteration loss: Ntot = 918.729, Nqll = 2114.714\n",
      "L-BFGS iteration loss: Ntot = 885.660, Nqll = 1923.526\n",
      "L-BFGS iteration loss: Ntot = 623.546, Nqll = 559.499\n",
      "L-BFGS iteration loss: Ntot = 3426.074, Nqll = 202326.356\n",
      "L-BFGS iteration loss: Ntot = 3556.482, Nqll = 14580.271\n",
      "L-BFGS iteration loss: Ntot = 3384.624, Nqll = 13767.718\n",
      "L-BFGS iteration loss: Ntot = 3214.115, Nqll = 12960.071\n",
      "L-BFGS iteration loss: Ntot = 3044.630, Nqll = 12156.023\n",
      "L-BFGS iteration loss: Ntot = 2875.823, Nqll = 11354.177\n",
      "L-BFGS iteration loss: Ntot = 2707.333, Nqll = 10553.099\n",
      "L-BFGS iteration loss: Ntot = 2538.803, Nqll = 9751.406\n",
      "L-BFGS iteration loss: Ntot = 2369.903, Nqll = 8947.910\n",
      "L-BFGS iteration loss: Ntot = 2200.380, Nqll = 8141.858\n",
      "L-BFGS iteration loss: Ntot = 2030.118, Nqll = 7333.301\n",
      "L-BFGS iteration loss: Ntot = 1859.248, Nqll = 6523.635\n",
      "L-BFGS iteration loss: Ntot = 1688.285, Nqll = 5716.378\n",
      "L-BFGS iteration loss: Ntot = 1518.328, Nqll = 4918.186\n",
      "L-BFGS iteration loss: Ntot = 1351.315, Nqll = 4140.071\n",
      "L-BFGS iteration loss: Ntot = 1190.296, Nqll = 3398.622\n",
      "L-BFGS iteration loss: Ntot = 1039.685, Nqll = 2716.775\n",
      "L-BFGS iteration loss: Ntot = 905.318, Nqll = 2123.307\n",
      "L-BFGS iteration loss: Ntot = 794.075, Nqll = 1649.698\n",
      "L-BFGS iteration loss: Ntot = 3264.858, Nqll = 12911.520\n",
      "L-BFGS iteration loss: Ntot = 2900.176, Nqll = 11320.093\n",
      "L-BFGS iteration loss: Ntot = 2554.573, Nqll = 9810.485\n",
      "L-BFGS iteration loss: Ntot = 2230.751, Nqll = 8392.619\n",
      "L-BFGS iteration loss: Ntot = 1931.501, Nqll = 7076.985\n",
      "L-BFGS iteration loss: Ntot = 1659.517, Nqll = 5874.014\n",
      "L-BFGS iteration loss: Ntot = 1417.193, Nqll = 4793.332\n",
      "L-BFGS iteration loss: Ntot = 1206.410, Nqll = 3842.894\n",
      "L-BFGS iteration loss: Ntot = 1028.335, Nqll = 3028.024\n",
      "L-BFGS iteration loss: Ntot = 883.270, Nqll = 2350.570\n",
      "L-BFGS iteration loss: Ntot = 770.594, Nqll = 1808.622\n",
      "L-BFGS iteration loss: Ntot = 688.895, Nqll = 1397.059\n",
      "L-BFGS iteration loss: Ntot = 636.268, Nqll = 1108.745\n",
      "L-BFGS iteration loss: Ntot = 610.445, Nqll = 935.372\n",
      "L-BFGS iteration loss: Ntot = 668.313, Nqll = 1031.837\n",
      "L-BFGS iteration loss: Ntot = 661.963, Nqll = 1005.442\n",
      "L-BFGS iteration loss: Ntot = 609.585, Nqll = 808.603\n",
      "L-BFGS iteration loss: Ntot = 593.112, Nqll = 752.261\n",
      "L-BFGS iteration loss: Ntot = 586.835, Nqll = 731.359\n",
      "L-BFGS iteration loss: Ntot = 581.315, Nqll = 711.559\n",
      "L-BFGS iteration loss: Ntot = 575.590, Nqll = 688.080\n",
      "L-BFGS iteration loss: Ntot = 571.862, Nqll = 673.646\n",
      "L-BFGS iteration loss: Ntot = 569.910, Nqll = 659.192\n",
      "L-BFGS iteration loss: Ntot = 567.763, Nqll = 647.042\n",
      "L-BFGS iteration loss: Ntot = 566.644, Nqll = 640.108\n",
      "L-BFGS iteration loss: Ntot = 563.975, Nqll = 623.893\n",
      "L-BFGS iteration loss: Ntot = 559.499, Nqll = 597.494\n",
      "L-BFGS iteration loss: Ntot = 553.059, Nqll = 560.908\n",
      "L-BFGS iteration loss: Ntot = 544.732, Nqll = 515.568\n",
      "L-BFGS iteration loss: Ntot = 534.965, Nqll = 464.731\n",
      "L-BFGS iteration loss: Ntot = 524.530, Nqll = 412.883\n",
      "L-BFGS iteration loss: Ntot = 514.067, Nqll = 363.319\n",
      "L-BFGS iteration loss: Ntot = 503.542, Nqll = 315.929\n",
      "L-BFGS iteration loss: Ntot = 491.556, Nqll = 265.060\n",
      "L-BFGS iteration loss: Ntot = 528.836, Nqll = 174.552\n",
      "L-BFGS iteration loss: Ntot = 524.868, Nqll = 170.777\n",
      "L-BFGS iteration loss: Ntot = 491.893, Nqll = 147.699\n",
      "L-BFGS iteration loss: Ntot = 479.373, Nqll = 151.301\n",
      "L-BFGS iteration loss: Ntot = 478.324, Nqll = 151.833\n",
      "L-BFGS iteration loss: Ntot = 478.326, Nqll = 150.139\n",
      "L-BFGS iteration loss: Ntot = 478.160, Nqll = 146.878\n",
      "L-BFGS iteration loss: Ntot = 477.236, Nqll = 138.641\n",
      "L-BFGS iteration loss: Ntot = 476.438, Nqll = 135.174\n",
      "L-BFGS iteration loss: Ntot = 475.622, Nqll = 131.605\n",
      "L-BFGS iteration loss: Ntot = 474.807, Nqll = 128.061\n",
      "L-BFGS iteration loss: Ntot = 460.179, Nqll = 75.373\n",
      "L-BFGS iteration loss: Ntot = 459.161, Nqll = 73.343\n",
      "L-BFGS iteration loss: Ntot = 542.163, Nqll = 616.642\n",
      "L-BFGS iteration loss: Ntot = 528.588, Nqll = 544.521\n",
      "L-BFGS iteration loss: Ntot = 456.506, Nqll = 87.524\n",
      "L-BFGS iteration loss: Ntot = 4021.117, Nqll = 15826.141\n",
      "L-BFGS iteration loss: Ntot = 3470.781, Nqll = 13311.511\n",
      "L-BFGS iteration loss: Ntot = 1950.467, Nqll = 6419.090\n",
      "L-BFGS iteration loss: Ntot = 682.841, Nqll = 863.792\n",
      "L-BFGS iteration loss: Ntot = 1256.356, Nqll = 4297.080\n",
      "L-BFGS iteration loss: Ntot = 1138.596, Nqll = 3714.068\n",
      "L-BFGS iteration loss: Ntot = 681.273, Nqll = 870.032\n",
      "L-BFGS iteration loss: Ntot = 622.697, Nqll = 632.213\n",
      "L-BFGS iteration loss: Ntot = 13881.231, Nqll = 61347.222\n",
      "L-BFGS iteration loss: Ntot = 11000.570, Nqll = 48772.156\n",
      "L-BFGS iteration loss: Ntot = 8064.709, Nqll = 35482.450\n",
      "L-BFGS iteration loss: Ntot = 3207.853, Nqll = 13110.498\n",
      "L-BFGS iteration loss: Ntot = 530.685, Nqll = 536.106\n",
      "L-BFGS iteration loss: Ntot = 3332.956, Nqll = 13139.450\n",
      "L-BFGS iteration loss: Ntot = 2923.156, Nqll = 11268.859\n",
      "L-BFGS iteration loss: Ntot = 1338.613, Nqll = 4045.641\n",
      "L-BFGS iteration loss: Ntot = 468.967, Nqll = 178.402\n",
      "L-BFGS iteration loss: Ntot = 14411044.918, Nqll = 120238054.672\n",
      "L-BFGS iteration loss: Ntot = 14779586.847, Nqll = 83357159.091\n",
      "L-BFGS iteration loss: Ntot = 14682315.615, Nqll = 214095206.556\n",
      "L-BFGS iteration loss: Ntot = 32754213.339, Nqll = 690544116.039\n",
      "L-BFGS iteration loss: Ntot = 12223603.979, Nqll = 62946535.797\n",
      "L-BFGS iteration loss: Ntot = 13207903.344, Nqll = 247463424.955\n",
      "L-BFGS iteration loss: Ntot = 15010935.893, Nqll = 410822295.336\n",
      "L-BFGS iteration loss: Ntot = 10100870.853, Nqll = 86056656.699\n",
      "L-BFGS iteration loss: Ntot = 9136818.262, Nqll = 42677183.226\n",
      "L-BFGS iteration loss: Ntot = 8781346.051, Nqll = 41056799.620\n",
      "L-BFGS iteration loss: Ntot = 8761829.767, Nqll = 59332413.893\n",
      "L-BFGS iteration loss: Ntot = 8098589.372, Nqll = 40540482.426\n",
      "L-BFGS iteration loss: Ntot = 7749564.104, Nqll = 40699050.197\n",
      "L-BFGS iteration loss: Ntot = 347833545802.673, Nqll = 15334220499398.602\n",
      "L-BFGS iteration loss: Ntot = 230806707767.532, Nqll = 15376299562916.729\n",
      "L-BFGS iteration loss: Ntot = 17149559305.664, Nqll = 664428715633.350\n",
      "L-BFGS iteration loss: Ntot = 51652803399.003, Nqll = 4924954641734.586\n",
      "L-BFGS iteration loss: Ntot = 48205770383.893, Nqll = 2775527709034.804\n",
      "L-BFGS iteration loss: Ntot = 149709336427.491, Nqll = 21760743169912.652\n",
      "L-BFGS iteration loss: Ntot = 205994434106.041, Nqll = 11592047796697.955\n",
      "L-BFGS iteration loss: Ntot = 258842181913.828, Nqll = 20851457178736.387\n",
      "L-BFGS iteration loss: Ntot = 6979551722.798, Nqll = 422770544930.839\n",
      "L-BFGS iteration loss: Ntot = 9120466999.934, Nqll = 631192782815.180\n",
      "L-BFGS iteration loss: Ntot = 814104299.096, Nqll = 15570403334.882\n",
      "L-BFGS iteration loss: Ntot = 725595383.553, Nqll = 9206786282.079\n",
      "L-BFGS iteration loss: Ntot = 1167247190.344, Nqll = 44886518703.768\n",
      "L-BFGS iteration loss: Ntot = 5813134507.653, Nqll = 101946634374.353\n",
      "L-BFGS iteration loss: Ntot = 2287912510.824, Nqll = 67542175214.596\n",
      "L-BFGS iteration loss: Ntot = 2463718555.944, Nqll = 27193100767.525\n",
      "L-BFGS iteration loss: Ntot = 1930751207.422, Nqll = 27995665720.563\n",
      "L-BFGS iteration loss: Ntot = 2038559466.258, Nqll = 15626687459.763\n",
      "L-BFGS iteration loss: Ntot = 1968796075.549, Nqll = 15477806910.434\n",
      "L-BFGS iteration loss: Ntot = 3736620940.281, Nqll = 31256509639.449\n",
      "L-BFGS iteration loss: Ntot = 12094379055.492, Nqll = 1531520053397.168\n",
      "L-BFGS iteration loss: Ntot = 1900941356.608, Nqll = 21735212463.032\n",
      "L-BFGS iteration loss: Ntot = 1749670596.779, Nqll = 27649206026.996\n",
      "L-BFGS iteration loss: Ntot = 10376571663.754, Nqll = 251955058764.591\n",
      "L-BFGS iteration loss: Ntot = 2964030827839.836, Nqll = 112003696943872.047\n",
      "L-BFGS iteration loss: Ntot = 160498698820.777, Nqll = 4065682068039.618\n",
      "L-BFGS iteration loss: Ntot = 364030371963.893, Nqll = 39117449682477.000\n",
      "L-BFGS iteration loss: Ntot = 543878876398147.938, Nqll = 52437745985464728.000\n",
      "L-BFGS iteration loss: Ntot = 942822761023.406, Nqll = 28874976643763.062\n",
      "L-BFGS iteration loss: Ntot = 1088304997400.873, Nqll = 51531548830909.727\n",
      "L-BFGS iteration loss: Ntot = 133817833420558.344, Nqll = 9058135413230094.000\n",
      "L-BFGS iteration loss: Ntot = 2107812191631.482, Nqll = 120758670341995.156\n",
      "L-BFGS iteration loss: Ntot = 9017980905.510, Nqll = 333924396963.460\n",
      "L-BFGS iteration loss: Ntot = 1173666154048.317, Nqll = 33188311905968.199\n",
      "L-BFGS iteration loss: Ntot = 1474107931328.593, Nqll = 18646329146898.633\n",
      "L-BFGS iteration loss: Ntot = 115347130342.922, Nqll = 12631086518009.680\n",
      "L-BFGS iteration loss: Ntot = 78390270362.093, Nqll = 1536882811627.980\n",
      "L-BFGS iteration loss: Ntot = 7283180164829.361, Nqll = 471045548289513.000\n",
      "L-BFGS iteration loss: Ntot = 1820995754542.150, Nqll = 147934076085849.781\n",
      "L-BFGS iteration loss: Ntot = 460169179331.290, Nqll = 10004501507795.150\n",
      "L-BFGS iteration loss: Ntot = 1302141972697.984, Nqll = 27668902925848.250\n",
      "L-BFGS iteration loss: Ntot = 61249096579146.828, Nqll = 6022174478188262.000\n",
      "L-BFGS iteration loss: Ntot = 8305303665.023, Nqll = 40585249587.984\n",
      "L-BFGS iteration loss: Ntot = 11071692010197.738, Nqll = 281664074932342.625\n",
      "L-BFGS iteration loss: Ntot = 3181972991897.896, Nqll = 3410030739783.924\n",
      "L-BFGS iteration loss: Ntot = 667383220090.957, Nqll = 147003946192023.656\n",
      "L-BFGS iteration loss: Ntot = 18132773874.632, Nqll = 144315390146.340\n",
      "L-BFGS iteration loss: Ntot = 53615535089.551, Nqll = 3870208232149.151\n",
      "L-BFGS iteration loss: Ntot = 24716871933.175, Nqll = 561059979699.232\n",
      "L-BFGS iteration loss: Ntot = 7426041080.949, Nqll = 82873658634.825\n",
      "L-BFGS iteration loss: Ntot = 44101846951.931, Nqll = 3744804271124.171\n",
      "L-BFGS iteration loss: Ntot = 2222064957473.859, Nqll = 325995282532818.000\n",
      "L-BFGS iteration loss: Ntot = 85859193798.177, Nqll = 1701262706995.499\n",
      "L-BFGS iteration loss: Ntot = 52083953796.987, Nqll = 3627496812470.686\n",
      "L-BFGS iteration loss: Ntot = 23665653929.330, Nqll = 650556473694.539\n",
      "L-BFGS iteration loss: Ntot = 81820396971.991, Nqll = 1340727678582.782\n",
      "L-BFGS iteration loss: Ntot = 9507858328850.650, Nqll = 233111313471467.875\n",
      "L-BFGS iteration loss: Ntot = 120919473638.406, Nqll = 107740543864819.812\n",
      "L-BFGS iteration loss: Ntot = 135000870577803.094, Nqll = 7407685498707375.000\n",
      "L-BFGS iteration loss: Ntot = 6143973209560.726, Nqll = 55875648343282.297\n",
      "L-BFGS iteration loss: Ntot = 296065288997.009, Nqll = 12453275514148.453\n",
      "L-BFGS iteration loss: Ntot = 17635424859.910, Nqll = 753552225701.300\n",
      "L-BFGS iteration loss: Ntot = 4797846057974239.000, Nqll = 44019735433767312.000\n",
      "L-BFGS iteration loss: Ntot = 9996959120.211, Nqll = 578537994244.660\n",
      "L-BFGS iteration loss: Ntot = 20909088472109.445, Nqll = 2433362166820895.500\n",
      "L-BFGS iteration loss: Ntot = 32445061461.233, Nqll = 1127410505850.224\n",
      "L-BFGS iteration loss: Ntot = 6686377493.102, Nqll = 112253378639.165\n",
      "L-BFGS iteration loss: Ntot = 170744245495.595, Nqll = 11662502756028.635\n",
      "L-BFGS iteration loss: Ntot = 10763209957.687, Nqll = 383841909574.969\n",
      "L-BFGS iteration loss: Ntot = 553622813922.058, Nqll = 4081265909874.942\n",
      "L-BFGS iteration loss: Ntot = 3863822954910.825, Nqll = 87353593434088.625\n",
      "L-BFGS iteration loss: Ntot = 546001030519.221, Nqll = 30911984312467.719\n",
      "L-BFGS iteration loss: Ntot = 1710588904173.525, Nqll = 86184348335947.922\n",
      "L-BFGS iteration loss: Ntot = 35006803080.940, Nqll = 1438989353157.457\n",
      "L-BFGS iteration loss: Ntot = 459691911392.651, Nqll = 45233148370290.477\n",
      "L-BFGS iteration loss: Ntot = 79573070343680.656, Nqll = 556617508752215.312\n",
      "L-BFGS iteration loss: Ntot = 47236682652.560, Nqll = 3043976804772.848\n",
      "L-BFGS iteration loss: Ntot = 902043407321.127, Nqll = 38672385127265.688\n",
      "L-BFGS iteration loss: Ntot = 2681742714465.057, Nqll = 22074499814120.199\n",
      "L-BFGS iteration loss: Ntot = 4016436819085.682, Nqll = 32399747897527.652\n",
      "L-BFGS iteration loss: Ntot = 37480631971.752, Nqll = 1193250144449.439\n",
      "L-BFGS iteration loss: Ntot = 783263863303.446, Nqll = 9774029930153.770\n",
      "L-BFGS iteration loss: Ntot = 7301748896116.146, Nqll = 54027340522830.023\n",
      "L-BFGS iteration loss: Ntot = 236777753157.734, Nqll = 356294812851.057\n",
      "L-BFGS iteration loss: Ntot = 9226604975.870, Nqll = 74451004306.119\n",
      "L-BFGS iteration loss: Ntot = 10248966003.420, Nqll = 45430743713.501\n",
      "L-BFGS iteration loss: Ntot = 736974773611643.250, Nqll = 14939250103871606.000\n",
      "L-BFGS iteration loss: Ntot = 173639266419.614, Nqll = 4157385864631.282\n",
      "L-BFGS iteration loss: Ntot = 1593619488611.516, Nqll = 32143704395371.617\n",
      "L-BFGS iteration loss: Ntot = 48113483046.667, Nqll = 6324949868390.517\n",
      "L-BFGS iteration loss: Ntot = 6117579181.819, Nqll = 268952696767.244\n",
      "L-BFGS iteration loss: Ntot = 5811376019.477, Nqll = 66119382943.305\n",
      "L-BFGS iteration loss: Ntot = 10413279789.132, Nqll = 556534786501.605\n",
      "L-BFGS iteration loss: Ntot = 180106865334.684, Nqll = 6353325140079.511\n",
      "L-BFGS iteration loss: Ntot = 44300202468.288, Nqll = 4742304070986.923\n",
      "L-BFGS iteration loss: Ntot = 85617486413.480, Nqll = 9012144320634.324\n",
      "L-BFGS iteration loss: Ntot = 35741032048408.414, Nqll = 1030679304085092.875\n",
      "L-BFGS iteration loss: Ntot = 8571577990.667, Nqll = 3288573837759.747\n",
      "L-BFGS iteration loss: Ntot = 7578597997.574, Nqll = 1413597693810.761\n",
      "L-BFGS iteration loss: Ntot = 6503969459.887, Nqll = 1310667581687.613\n",
      "L-BFGS iteration loss: Ntot = 822644512180.303, Nqll = 28821677656948.176\n",
      "L-BFGS iteration loss: Ntot = 78255692022.368, Nqll = 1008212376098.459\n",
      "L-BFGS iteration loss: Ntot = 61389639367.431, Nqll = 2912064430624.644\n",
      "L-BFGS iteration loss: Ntot = 12204293794.722, Nqll = 1152262575919.205\n",
      "L-BFGS iteration loss: Ntot = 200784036731.106, Nqll = 4695133968243.071\n",
      "L-BFGS iteration loss: Ntot = 851541974855.787, Nqll = 49494734499614.242\n",
      "L-BFGS iteration loss: Ntot = 263974051844.040, Nqll = 22023270462545.754\n",
      "L-BFGS iteration loss: Ntot = 118085555346.679, Nqll = 737553560448.457\n",
      "L-BFGS iteration loss: Ntot = 3834618825128.185, Nqll = 161678135070186.844\n",
      "L-BFGS iteration loss: Ntot = 113377535662.838, Nqll = 525054391119.784\n",
      "L-BFGS iteration loss: Ntot = 501216258915.179, Nqll = 39734663799761.867\n",
      "L-BFGS iteration loss: Ntot = 110423859750.571, Nqll = 563941777872.072\n",
      "L-BFGS iteration loss: Ntot = 124637635772.143, Nqll = 520570422598.293\n",
      "L-BFGS iteration loss: Ntot = 110086729119.396, Nqll = 525659237633.879\n",
      "L-BFGS iteration loss: Ntot = 108576306515.600, Nqll = 511172737266.591\n",
      "L-BFGS iteration loss: Ntot = 150634257190150.250, Nqll = 2571583377007587.000\n",
      "L-BFGS iteration loss: Ntot = 108570716617.181, Nqll = 939399829417.092\n",
      "L-BFGS iteration loss: Ntot = 41510357468555.938, Nqll = 1524252643303456.250\n",
      "L-BFGS iteration loss: Ntot = 107176022053.963, Nqll = 503367331586.356\n",
      "L-BFGS iteration loss: Ntot = 107210913339.873, Nqll = 506129031226.015\n",
      "L-BFGS iteration loss: Ntot = 12841817949379.854, Nqll = 3016374045195222.500\n",
      "L-BFGS iteration loss: Ntot = 112976177334.125, Nqll = 1225419069390.862\n",
      "L-BFGS iteration loss: Ntot = 107516417487.689, Nqll = 500511524283.526\n",
      "L-BFGS iteration loss: Ntot = 142742114809.159, Nqll = 1713261984988.272\n",
      "L-BFGS iteration loss: Ntot = 109396462932.613, Nqll = 1745457484785.548\n",
      "L-BFGS iteration loss: Ntot = 107758800638.167, Nqll = 507266681366.077\n",
      "L-BFGS iteration loss: Ntot = 134869093745.084, Nqll = 2789177978657.817\n",
      "L-BFGS iteration loss: Ntot = 318006981926.917, Nqll = 8243124107195.019\n",
      "L-BFGS iteration loss: Ntot = 1209930960752.864, Nqll = 61268728706401.516\n",
      "L-BFGS iteration loss: Ntot = 104821229149.611, Nqll = 485604115594.113\n",
      "L-BFGS iteration loss: Ntot = 168954175324.468, Nqll = 2883227825975.237\n",
      "L-BFGS iteration loss: Ntot = 7814465961466.817, Nqll = 436182934573549.375\n",
      "L-BFGS iteration loss: Ntot = 204067444804.556, Nqll = 13160284856837.488\n",
      "L-BFGS iteration loss: Ntot = 105779994694.455, Nqll = 670358699030.987\n",
      "L-BFGS iteration loss: Ntot = 106619799920.211, Nqll = 817506076510.458\n",
      "L-BFGS iteration loss: Ntot = 233418529465.552, Nqll = 29935297585050.418\n",
      "L-BFGS iteration loss: Ntot = 108896599361.535, Nqll = 508255656539.883\n",
      "L-BFGS iteration loss: Ntot = 41653615110894.641, Nqll = 8248094547846176.000\n",
      "L-BFGS iteration loss: Ntot = 111870769591.913, Nqll = 672913464634.761\n",
      "L-BFGS iteration loss: Ntot = 7697774227116.836, Nqll = 324984197198753.000\n",
      "L-BFGS iteration loss: Ntot = 119740362162.877, Nqll = 1058589614188.605\n",
      "L-BFGS iteration loss: Ntot = 109775380002.389, Nqll = 507844166207.322\n",
      "L-BFGS iteration loss: Ntot = 762298715528.328, Nqll = 68116092503093.219\n",
      "L-BFGS iteration loss: Ntot = 213571950106615712.000, Nqll = 918270279436118912.000\n",
      "L-BFGS iteration loss: Ntot = 109564930225.335, Nqll = 506562514205.815\n",
      "L-BFGS iteration loss: Ntot = 159109332888.460, Nqll = 9327818106493.143\n",
      "L-BFGS iteration loss: Ntot = 3159195513285.064, Nqll = 145821545381846.875\n",
      "L-BFGS iteration loss: Ntot = 49508655105144.039, Nqll = 2793986037218426.500\n",
      "L-BFGS iteration loss: Ntot = 110965444395.228, Nqll = 652371889830.901\n",
      "L-BFGS iteration loss: Ntot = 149838482954.880, Nqll = 527148408715.003\n",
      "L-BFGS iteration loss: Ntot = 1766173645781.788, Nqll = 22412900085937.102\n",
      "L-BFGS iteration loss: Ntot = 127526609908.267, Nqll = 6844154504028.414\n",
      "L-BFGS iteration loss: Ntot = 109523661950.027, Nqll = 508579247216.824\n",
      "L-BFGS iteration loss: Ntot = 108588300528.456, Nqll = 509857465845.321\n",
      "L-BFGS iteration loss: Ntot = 108586097501.093, Nqll = 504207835319.426\n",
      "L-BFGS iteration loss: Ntot = 108551512641.698, Nqll = 503958096148.627\n",
      "L-BFGS iteration loss: Ntot = 3685118366606.597, Nqll = 22068864763808.203\n",
      "L-BFGS iteration loss: Ntot = 300166231777.417, Nqll = 5540586745527.243\n",
      "L-BFGS iteration loss: Ntot = 197271618671.660, Nqll = 4613241267322.520\n",
      "L-BFGS iteration loss: Ntot = 131619215683.037, Nqll = 1354335359426.941\n",
      "L-BFGS iteration loss: Ntot = 121605796047.723, Nqll = 1157484697288.794\n",
      "L-BFGS iteration loss: Ntot = 118854391967.680, Nqll = 561829457934.366\n",
      "L-BFGS iteration loss: Ntot = 225800195205268.219, Nqll = 7809835571859310.000\n",
      "L-BFGS iteration loss: Ntot = 120062143154.538, Nqll = 651109651975.025\n",
      "L-BFGS iteration loss: Ntot = 198140067961.283, Nqll = 5989379135453.170\n",
      "L-BFGS iteration loss: Ntot = 295833154694.642, Nqll = 32282674822931.672\n",
      "L-BFGS iteration loss: Ntot = 150074729641.218, Nqll = 4894885455534.705\n",
      "L-BFGS iteration loss: Ntot = 2294129973426.540, Nqll = 84109522719554.641\n",
      "L-BFGS iteration loss: Ntot = 55302714462616.633, Nqll = 4118436647741291.000\n",
      "L-BFGS iteration loss: Ntot = 772909852208.548, Nqll = 45568527900871.727\n",
      "L-BFGS iteration loss: Ntot = 523336574936.532, Nqll = 84575815024702.344\n",
      "L-BFGS iteration loss: Ntot = 507595985554.871, Nqll = 71769236570025.281\n",
      "L-BFGS iteration loss: Ntot = 117812645624.986, Nqll = 555900959001.879\n",
      "L-BFGS iteration loss: Ntot = 1700617571695.164, Nqll = 3878161766657863.000\n",
      "L-BFGS iteration loss: Ntot = 117671920881.059, Nqll = 552283468380.017\n",
      "L-BFGS iteration loss: Ntot = 117681146233.813, Nqll = 554973240987.973\n",
      "L-BFGS iteration loss: Ntot = 117417693239.180, Nqll = 547960664852.133\n",
      "L-BFGS iteration loss: Ntot = 117927232113.383, Nqll = 605153693522.463\n",
      "L-BFGS iteration loss: Ntot = 483176226291.739, Nqll = 40322076297506.695\n",
      "L-BFGS iteration loss: Ntot = 2360310138507.996, Nqll = 99442033774891.750\n",
      "L-BFGS iteration loss: Ntot = 127103464820.392, Nqll = 1420684884908.512\n",
      "L-BFGS iteration loss: Ntot = 123127918820.268, Nqll = 573944924606.690\n",
      "L-BFGS iteration loss: Ntot = 120667735406.815, Nqll = 733113530975.726\n",
      "L-BFGS iteration loss: Ntot = 117787152977.609, Nqll = 655506070889.589\n",
      "L-BFGS iteration loss: Ntot = 142612545779.117, Nqll = 2637978600243.562\n",
      "L-BFGS iteration loss: Ntot = 123927680415645.766, Nqll = 5872448721556724.000\n",
      "L-BFGS iteration loss: Ntot = 126148809919.595, Nqll = 1454491999349.364\n",
      "L-BFGS iteration loss: Ntot = 121265293154.795, Nqll = 767310706395.080\n",
      "L-BFGS iteration loss: Ntot = 117606402332.690, Nqll = 808335249905.188\n",
      "L-BFGS iteration loss: Ntot = 616571139350.487, Nqll = 51695475668257.781\n",
      "L-BFGS iteration loss: Ntot = 116626582511.034, Nqll = 544022351952.654\n",
      "L-BFGS iteration loss: Ntot = 649812084846.418, Nqll = 18333216682115.730\n",
      "L-BFGS iteration loss: Ntot = 18003708639142338.000, Nqll = 110013231181246224.000\n",
      "L-BFGS iteration loss: Ntot = 1092657766097.107, Nqll = 64499400466187.844\n",
      "L-BFGS iteration loss: Ntot = 289133346298312.688, Nqll = 81920463518416224.000\n",
      "L-BFGS iteration loss: Ntot = 230989068231.861, Nqll = 1720086251476.582\n",
      "L-BFGS iteration loss: Ntot = 528966203681.445, Nqll = 28035577638100.160\n",
      "L-BFGS iteration loss: Ntot = 108230085654.130, Nqll = 867462638403.459\n",
      "L-BFGS iteration loss: Ntot = 293435248436.739, Nqll = 21755581546061.949\n",
      "L-BFGS iteration loss: Ntot = 108064049689.718, Nqll = 561629592112.627\n",
      "L-BFGS iteration loss: Ntot = 107771339291.635, Nqll = 547960665314.425\n",
      "L-BFGS iteration loss: Ntot = 11741866853216.740, Nqll = 951990375120516.875\n",
      "L-BFGS iteration loss: Ntot = 109852256155.487, Nqll = 541347824314.081\n",
      "L-BFGS iteration loss: Ntot = 112548085741.327, Nqll = 567619104810.629\n",
      "L-BFGS iteration loss: Ntot = 106722078910.840, Nqll = 506915915791.032\n",
      "L-BFGS iteration loss: Ntot = 360253668945815040.000, Nqll = 12420328614636943360.000\n",
      "L-BFGS iteration loss: Ntot = 426219014853.492, Nqll = 9540740906011.893\n",
      "L-BFGS iteration loss: Ntot = 106902883267.627, Nqll = 530662439075.289\n",
      "L-BFGS iteration loss: Ntot = 90552207578342.391, Nqll = 10163126918099146.000\n",
      "L-BFGS iteration loss: Ntot = 107819176839.275, Nqll = 531207074311.185\n",
      "L-BFGS iteration loss: Ntot = 151256685785.850, Nqll = 5261604415840.396\n",
      "L-BFGS iteration loss: Ntot = 112557834663.464, Nqll = 696442145465.807\n",
      "L-BFGS iteration loss: Ntot = 107842473111.760, Nqll = 709214133143.031\n",
      "L-BFGS iteration loss: Ntot = 106080946476.813, Nqll = 490143538409.315\n",
      "L-BFGS iteration loss: Ntot = 162283368332.323, Nqll = 3588266188475.346\n",
      "L-BFGS iteration loss: Ntot = 136386277293.795, Nqll = 1504572234582.569\n",
      "L-BFGS iteration loss: Ntot = 291166282979.102, Nqll = 12028322191038.053\n",
      "L-BFGS iteration loss: Ntot = 16185979065467.742, Nqll = 4701114962648094.000\n",
      "L-BFGS iteration loss: Ntot = 106391578714.279, Nqll = 519408546159.619\n",
      "L-BFGS iteration loss: Ntot = 105143335886.027, Nqll = 493349850657.630\n",
      "L-BFGS iteration loss: Ntot = 105184986865.351, Nqll = 495125684916.799\n",
      "L-BFGS iteration loss: Ntot = 130909574991.929, Nqll = 4170101394459.686\n",
      "L-BFGS iteration loss: Ntot = 107848572612.850, Nqll = 1078731410043.099\n",
      "L-BFGS iteration loss: Ntot = 190608331116.589, Nqll = 11523668740309.609\n",
      "L-BFGS iteration loss: Ntot = 432350371867.945, Nqll = 196333786886135.562\n",
      "L-BFGS iteration loss: Ntot = 578375264632.411, Nqll = 2475255182463.729\n",
      "L-BFGS iteration loss: Ntot = 105198542172.616, Nqll = 538370857184.508\n",
      "L-BFGS iteration loss: Ntot = 105206292429.799, Nqll = 573925190262.999\n",
      "L-BFGS iteration loss: Ntot = 105799793613.800, Nqll = 698521394246.026\n",
      "L-BFGS iteration loss: Ntot = 579082955159.322, Nqll = 246023443240789.906\n",
      "L-BFGS iteration loss: Ntot = 348289962637828.875, Nqll = 14706321487909384.000\n",
      "L-BFGS iteration loss: Ntot = 2054791839374266.500, Nqll = 88530288251404272.000\n",
      "L-BFGS iteration loss: Ntot = 521065819176.039, Nqll = 40550671360248.109\n",
      "L-BFGS iteration loss: Ntot = 120612183752.605, Nqll = 1945820242073.321\n",
      "L-BFGS iteration loss: Ntot = 104505092656.632, Nqll = 487913779578.879\n",
      "L-BFGS iteration loss: Ntot = 104502676953.085, Nqll = 487890981491.081\n",
      "L-BFGS iteration loss: Ntot = 231915609806.779, Nqll = 130072953037565.312\n",
      "L-BFGS iteration loss: Ntot = 45274690099877.359, Nqll = 129947286638211.078\n",
      "L-BFGS iteration loss: Ntot = 122025059535.867, Nqll = 1118396684060.670\n",
      "L-BFGS iteration loss: Ntot = 104766300678.941, Nqll = 499926575865.776\n",
      "L-BFGS iteration loss: Ntot = 105958637964.809, Nqll = 514953541180.911\n",
      "L-BFGS iteration loss: Ntot = 131092350253.409, Nqll = 747858321884.091\n",
      "L-BFGS iteration loss: Ntot = 171936478061.829, Nqll = 26292326128077.602\n",
      "L-BFGS iteration loss: Ntot = 106799916695.712, Nqll = 542147275230.160\n",
      "L-BFGS iteration loss: Ntot = 106481871111.921, Nqll = 761723579800.082\n",
      "L-BFGS iteration loss: Ntot = 110460553749.138, Nqll = 1680721540158.712\n",
      "L-BFGS iteration loss: Ntot = 105427495471.620, Nqll = 572815926005.182\n",
      "L-BFGS iteration loss: Ntot = 105379386056.468, Nqll = 563469300001.759\n",
      "L-BFGS iteration loss: Ntot = 105339378279.675, Nqll = 554911788621.020\n",
      "L-BFGS iteration loss: Ntot = 105292027303.257, Nqll = 543483391320.816\n",
      "L-BFGS iteration loss: Ntot = 105272061911.649, Nqll = 538116121818.413\n",
      "L-BFGS iteration loss: Ntot = 131516443822.504, Nqll = 858192220788.584\n",
      "L-BFGS iteration loss: Ntot = 2386836490671.662, Nqll = 16605688205056.049\n",
      "L-BFGS iteration loss: Ntot = 106427148905.352, Nqll = 1073700503047.185\n",
      "L-BFGS iteration loss: Ntot = 107030707155.857, Nqll = 1343561671528.526\n",
      "L-BFGS iteration loss: Ntot = 107719611518.152, Nqll = 1676515432828.961\n",
      "L-BFGS iteration loss: Ntot = 108292815118.780, Nqll = 2009452864576.477\n",
      "L-BFGS iteration loss: Ntot = 108382887970.391, Nqll = 2209131528506.856\n",
      "L-BFGS iteration loss: Ntot = 107679918974.351, Nqll = 2120157104778.256\n",
      "L-BFGS iteration loss: Ntot = 106444040796.649, Nqll = 1710652483465.792\n",
      "L-BFGS iteration loss: Ntot = 32536746074313.770, Nqll = 103088880799089.625\n",
      "L-BFGS iteration loss: Ntot = 141098755166.870, Nqll = 14437961272648.594\n",
      "L-BFGS iteration loss: Ntot = 141835170804.884, Nqll = 11748582691496.443\n",
      "L-BFGS iteration loss: Ntot = 127769855201.114, Nqll = 8680218175216.040\n",
      "L-BFGS iteration loss: Ntot = 123976888912.025, Nqll = 7106362712680.764\n",
      "L-BFGS iteration loss: Ntot = 408071531911.125, Nqll = 17255998793770.053\n",
      "L-BFGS iteration loss: Ntot = 116975448857.787, Nqll = 4232460970099.806\n",
      "L-BFGS iteration loss: Ntot = 360014607412.287, Nqll = 4741380159784.746\n",
      "L-BFGS iteration loss: Ntot = 109603520640.830, Nqll = 2039927397027.892\n",
      "L-BFGS iteration loss: Ntot = 108214467207.839, Nqll = 1348042680291.005\n",
      "L-BFGS iteration loss: Ntot = 139656201738.947, Nqll = 2926273540989.223\n",
      "L-BFGS iteration loss: Ntot = 108885868984.251, Nqll = 638473894916.399\n",
      "L-BFGS iteration loss: Ntot = 104847532761.811, Nqll = 489577554776.391\n",
      "L-BFGS iteration loss: Ntot = 104856123605.489, Nqll = 489709022062.807\n",
      "L-BFGS iteration loss: Ntot = 104885523268.206, Nqll = 491051651897.871\n",
      "L-BFGS iteration loss: Ntot = 104932727560.491, Nqll = 500780346374.752\n",
      "L-BFGS iteration loss: Ntot = 104944995984.417, Nqll = 502396565449.920\n",
      "L-BFGS iteration loss: Ntot = 104946691266.692, Nqll = 502498133296.941\n",
      "L-BFGS iteration loss: Ntot = 104946554707.171, Nqll = 502266031770.908\n",
      "L-BFGS iteration loss: Ntot = 104947241481.244, Nqll = 502051757345.097\n",
      "L-BFGS iteration loss: Ntot = 104950183527.170, Nqll = 501316385273.838\n",
      "L-BFGS iteration loss: Ntot = 105077763807.991, Nqll = 499463060303.163\n",
      "L-BFGS iteration loss: Ntot = 160405196545.677, Nqll = 6555325268357.215\n",
      "L-BFGS iteration loss: Ntot = 546394520729.182, Nqll = 47614091822888.859\n",
      "L-BFGS iteration loss: Ntot = 106185973362.376, Nqll = 515331029680.744\n",
      "L-BFGS iteration loss: Ntot = 106172727994.878, Nqll = 516146426338.083\n",
      "L-BFGS iteration loss: Ntot = 104825198506.284, Nqll = 490994676751.834\n",
      "L-BFGS iteration loss: Ntot = 270933399767.531, Nqll = 19956183323878.309\n",
      "L-BFGS iteration loss: Ntot = 104794473350.801, Nqll = 491844226803.362\n",
      "L-BFGS iteration loss: Ntot = 258111943145315.906, Nqll = 11111391404219256.000\n",
      "L-BFGS iteration loss: Ntot = 104805187931.488, Nqll = 491720864164.002\n",
      "L-BFGS iteration loss: Ntot = 104812719676.251, Nqll = 491960135230.503\n",
      "L-BFGS iteration loss: Ntot = 105652143389.271, Nqll = 501018613455.551\n",
      "L-BFGS iteration loss: Ntot = 104875471661.469, Nqll = 493128227994.385\n",
      "L-BFGS iteration loss: Ntot = 104857259250.226, Nqll = 493684334236.293\n",
      "L-BFGS iteration loss: Ntot = 104866925917.111, Nqll = 494175128890.595\n",
      "L-BFGS iteration loss: Ntot = 104882957973.738, Nqll = 495008715602.873\n",
      "L-BFGS iteration loss: Ntot = 104913358025.265, Nqll = 496660012196.423\n",
      "L-BFGS iteration loss: Ntot = 104982494783.337, Nqll = 500715958360.994\n",
      "L-BFGS iteration loss: Ntot = 105181251533.078, Nqll = 513931058834.974\n",
      "L-BFGS iteration loss: Ntot = 105958125611.957, Nqll = 574771079181.152\n",
      "L-BFGS iteration loss: Ntot = 109194848593.456, Nqll = 865098381527.831\n",
      "L-BFGS iteration loss: Ntot = 116003610582.250, Nqll = 1517719551621.289\n",
      "L-BFGS iteration loss: Ntot = 34046439385309.859, Nqll = 1370417627203795.500\n",
      "L-BFGS iteration loss: Ntot = 113944787570.935, Nqll = 1076454228133.491\n",
      "L-BFGS iteration loss: Ntot = 111084721365.256, Nqll = 1045121497948.769\n",
      "L-BFGS iteration loss: Ntot = 111038358085.329, Nqll = 1040893057676.967\n",
      "L-BFGS iteration loss: Ntot = 110993528795.924, Nqll = 1036694472813.395\n",
      "L-BFGS iteration loss: Ntot = 110949241072.857, Nqll = 1032511653657.165\n",
      "L-BFGS iteration loss: Ntot = 110905214545.209, Nqll = 1028340847862.186\n",
      "L-BFGS iteration loss: Ntot = 110861354688.365, Nqll = 1024180975267.449\n",
      "L-BFGS iteration loss: Ntot = 110817625719.451, Nqll = 1020031788081.809\n",
      "L-BFGS iteration loss: Ntot = 110774013236.498, Nqll = 1015893330767.849\n",
      "L-BFGS iteration loss: Ntot = 110730511538.563, Nqll = 1011765759329.405\n",
      "L-BFGS iteration loss: Ntot = 110687118777.498, Nqll = 1007649272118.573\n",
      "L-BFGS iteration loss: Ntot = 110643834943.109, Nqll = 1003544083123.497\n",
      "L-BFGS iteration loss: Ntot = 110600660960.180, Nqll = 999450411416.708\n",
      "L-BFGS iteration loss: Ntot = 110557598252.888, Nqll = 995368476663.936\n",
      "L-BFGS iteration loss: Ntot = 110514648535.820, Nqll = 991298498520.156\n",
      "L-BFGS iteration loss: Ntot = 110471813705.093, Nqll = 987240696900.544\n",
      "L-BFGS iteration loss: Ntot = 110429095794.290, Nqll = 983195293907.422\n",
      "L-BFGS iteration loss: Ntot = 110386496949.801, Nqll = 979162515167.467\n",
      "L-BFGS iteration loss: Ntot = 110344019425.943, Nqll = 975142591648.106\n",
      "L-BFGS iteration loss: Ntot = 110301665584.044, Nqll = 971135761026.166\n",
      "L-BFGS iteration loss: Ntot = 110259437893.294, Nqll = 967142268732.434\n",
      "L-BFGS iteration loss: Ntot = 110217338938.070, Nqll = 963162369273.265\n",
      "L-BFGS iteration loss: Ntot = 110175371408.818, Nqll = 959196325814.583\n",
      "L-BFGS iteration loss: Ntot = 110133538090.806, Nqll = 955244409417.906\n",
      "L-BFGS iteration loss: Ntot = 110091841863.607, Nqll = 951306899194.591\n",
      "L-BFGS iteration loss: Ntot = 110050285657.143, Nqll = 947384078302.846\n",
      "L-BFGS iteration loss: Ntot = 110008872428.472, Nqll = 943476231846.218\n",
      "L-BFGS iteration loss: Ntot = 109967605136.029, Nqll = 939583644505.899\n",
      "L-BFGS iteration loss: Ntot = 109926486692.602, Nqll = 935706596142.112\n",
      "L-BFGS iteration loss: Ntot = 109885519940.476, Nqll = 931845359474.539\n",
      "L-BFGS iteration loss: Ntot = 109844707609.975, Nqll = 928000196191.672\n",
      "L-BFGS iteration loss: Ntot = 109804052289.013, Nqll = 924171354105.793\n",
      "L-BFGS iteration loss: Ntot = 109763556425.897, Nqll = 920359067421.229\n",
      "L-BFGS iteration loss: Ntot = 109723222301.160, Nqll = 916563554114.522\n",
      "L-BFGS iteration loss: Ntot = 109683052020.576, Nqll = 912785015292.483\n",
      "L-BFGS iteration loss: Ntot = 109643047541.182, Nqll = 909023637664.242\n",
      "L-BFGS iteration loss: Ntot = 109603210658.412, Nqll = 905279592355.250\n",
      "L-BFGS iteration loss: Ntot = 109563543028.729, Nqll = 901553037049.033\n",
      "L-BFGS iteration loss: Ntot = 109524046187.527, Nqll = 897844117687.435\n",
      "L-BFGS iteration loss: Ntot = 109484721564.373, Nqll = 894152969910.323\n",
      "L-BFGS iteration loss: Ntot = 109445570500.742, Nqll = 890479720725.075\n",
      "L-BFGS iteration loss: Ntot = 109406594269.368, Nqll = 886824490324.648\n",
      "L-BFGS iteration loss: Ntot = 109367794092.269, Nqll = 883187393776.782\n",
      "L-BFGS iteration loss: Ntot = 109329171156.597, Nqll = 879568542505.930\n",
      "L-BFGS iteration loss: Ntot = 109290726632.818, Nqll = 875968046000.287\n",
      "L-BFGS iteration loss: Ntot = 109252461685.915, Nqll = 872386012847.097\n",
      "L-BFGS iteration loss: Ntot = 109214377493.740, Nqll = 868822552463.927\n",
      "L-BFGS iteration loss: Ntot = 109176475254.988, Nqll = 865277775836.488\n",
      "L-BFGS iteration loss: Ntot = 109138756198.679, Nqll = 861751796421.876\n",
      "L-BFGS iteration loss: Ntot = 109101221595.338, Nqll = 858244731179.309\n",
      "L-BFGS iteration loss: Ntot = 109063872763.927, Nqll = 854756701242.685\n",
      "L-BFGS iteration loss: Ntot = 109026711065.185, Nqll = 851287831293.540\n",
      "L-BFGS iteration loss: Ntot = 108989737905.547, Nqll = 847838249929.176\n",
      "L-BFGS iteration loss: Ntot = 108952954735.592, Nqll = 844408089521.943\n",
      "L-BFGS iteration loss: Ntot = 108916363033.034, Nqll = 840997484627.998\n",
      "L-BFGS iteration loss: Ntot = 108879964298.877, Nqll = 837606571619.345\n",
      "L-BFGS iteration loss: Ntot = 108843760031.206, Nqll = 834235486240.235\n",
      "L-BFGS iteration loss: Ntot = 108807751720.653, Nqll = 830884363166.932\n",
      "L-BFGS iteration loss: Ntot = 108771940820.845, Nqll = 827553333253.111\n",
      "L-BFGS iteration loss: Ntot = 108736328735.006, Nqll = 824242522271.199\n",
      "L-BFGS iteration loss: Ntot = 108700916799.838, Nqll = 820952049411.316\n",
      "L-BFGS iteration loss: Ntot = 108665706266.166, Nqll = 817682025485.487\n",
      "L-BFGS iteration loss: Ntot = 108630698288.893, Nqll = 814432551997.100\n",
      "L-BFGS iteration loss: Ntot = 108595893925.029, Nqll = 811203720965.064\n",
      "L-BFGS iteration loss: Ntot = 108561294117.935, Nqll = 807995613488.201\n",
      "L-BFGS iteration loss: Ntot = 108526899699.696, Nqll = 804808299977.889\n",
      "L-BFGS iteration loss: Ntot = 108492711398.120, Nqll = 801641840830.276\n",
      "L-BFGS iteration loss: Ntot = 108458729837.001, Nqll = 798496286479.698\n",
      "L-BFGS iteration loss: Ntot = 108424955541.533, Nqll = 795371677916.800\n",
      "L-BFGS iteration loss: Ntot = 108391388945.317, Nqll = 792268047366.729\n",
      "L-BFGS iteration loss: Ntot = 108358030407.676, Nqll = 789185419907.829\n",
      "L-BFGS iteration loss: Ntot = 108324880212.452, Nqll = 786123813376.171\n",
      "L-BFGS iteration loss: Ntot = 108291938586.059, Nqll = 783083240056.330\n",
      "L-BFGS iteration loss: Ntot = 108259205698.486, Nqll = 780063706780.952\n",
      "L-BFGS iteration loss: Ntot = 108226681682.758, Nqll = 777065216735.328\n",
      "L-BFGS iteration loss: Ntot = 108194366632.644, Nqll = 774087769258.077\n",
      "L-BFGS iteration loss: Ntot = 108162260620.176, Nqll = 771131361459.430\n",
      "L-BFGS iteration loss: Ntot = 108130363699.544, Nqll = 768195988583.571\n",
      "L-BFGS iteration loss: Ntot = 108098675907.611, Nqll = 765281644059.191\n",
      "L-BFGS iteration loss: Ntot = 108067197281.053, Nqll = 762388321080.026\n",
      "L-BFGS iteration loss: Ntot = 108035927856.442, Nqll = 759516012612.837\n",
      "L-BFGS iteration loss: Ntot = 108004867674.885, Nqll = 756664711821.198\n",
      "L-BFGS iteration loss: Ntot = 107974016784.527, Nqll = 753834412301.041\n",
      "L-BFGS iteration loss: Ntot = 107943375246.726, Nqll = 751025108644.252\n",
      "L-BFGS iteration loss: Ntot = 107912943133.275, Nqll = 748236796181.170\n",
      "L-BFGS iteration loss: Ntot = 107882720534.315, Nqll = 745469471709.234\n",
      "L-BFGS iteration loss: Ntot = 107852707553.022, Nqll = 742723132992.349\n",
      "L-BFGS iteration loss: Ntot = 107822904305.076, Nqll = 739997778717.682\n",
      "L-BFGS iteration loss: Ntot = 107793310909.110, Nqll = 737293407618.011\n",
      "L-BFGS iteration loss: Ntot = 107763927499.493, Nqll = 734610019624.933\n",
      "L-BFGS iteration loss: Ntot = 107734754200.992, Nqll = 731947613560.614\n",
      "L-BFGS iteration loss: Ntot = 107705791140.754, Nqll = 729306188212.342\n",
      "L-BFGS iteration loss: Ntot = 107677038425.282, Nqll = 726685740243.475\n",
      "L-BFGS iteration loss: Ntot = 107648496147.730, Nqll = 724086264837.902\n",
      "L-BFGS iteration loss: Ntot = 107620164371.874, Nqll = 721507754249.392\n",
      "L-BFGS iteration loss: Ntot = 107592043129.132, Nqll = 718950197524.777\n",
      "L-BFGS iteration loss: Ntot = 107564132410.337, Nqll = 716413579759.307\n",
      "L-BFGS iteration loss: Ntot = 107536432159.036, Nqll = 713897881494.479\n",
      "L-BFGS iteration loss: Ntot = 107508942274.801, Nqll = 711403079024.025\n",
      "L-BFGS iteration loss: Ntot = 107481662599.688, Nqll = 708929143176.232\n",
      "L-BFGS iteration loss: Ntot = 107454592919.415, Nqll = 706476039439.842\n",
      "L-BFGS iteration loss: Ntot = 107427732966.694, Nqll = 704043728273.362\n",
      "L-BFGS iteration loss: Ntot = 107401082419.598, Nqll = 701632164973.910\n",
      "L-BFGS iteration loss: Ntot = 107374640892.994, Nqll = 699241298932.845\n",
      "L-BFGS iteration loss: Ntot = 107348407957.176, Nqll = 696871075321.527\n",
      "L-BFGS iteration loss: Ntot = 107322383128.085, Nqll = 694521434240.774\n",
      "L-BFGS iteration loss: Ntot = 107296565872.921, Nqll = 692192311233.505\n",
      "L-BFGS iteration loss: Ntot = 107270955622.222, Nqll = 689883638401.686\n",
      "L-BFGS iteration loss: Ntot = 107245551757.831, Nqll = 687595343330.805\n",
      "L-BFGS iteration loss: Ntot = 107220353628.712, Nqll = 685327350534.042\n",
      "L-BFGS iteration loss: Ntot = 107195360552.877, Nqll = 683079581634.636\n",
      "L-BFGS iteration loss: Ntot = 107170571819.725, Nqll = 680851955588.060\n",
      "L-BFGS iteration loss: Ntot = 107145986691.861, Nqll = 678644388864.136\n",
      "L-BFGS iteration loss: Ntot = 107121604413.746, Nqll = 676456796213.684\n",
      "L-BFGS iteration loss: Ntot = 107097424210.378, Nqll = 674289090581.484\n",
      "L-BFGS iteration loss: Ntot = 107073445290.242, Nqll = 672141183356.647\n",
      "L-BFGS iteration loss: Ntot = 107049666852.686, Nqll = 670012985046.583\n",
      "L-BFGS iteration loss: Ntot = 107026088086.562, Nqll = 667904405160.085\n",
      "L-BFGS iteration loss: Ntot = 107002708170.557, Nqll = 665815352239.056\n",
      "L-BFGS iteration loss: Ntot = 106979526280.977, Nqll = 663745734553.639\n",
      "L-BFGS iteration loss: Ntot = 106956541593.074, Nqll = 661695460222.213\n",
      "L-BFGS iteration loss: Ntot = 106933753275.648, Nqll = 659664436732.279\n",
      "L-BFGS iteration loss: Ntot = 106911160498.268, Nqll = 657652571585.459\n",
      "L-BFGS iteration loss: Ntot = 106888762432.076, Nqll = 655659772363.506\n",
      "L-BFGS iteration loss: Ntot = 106866558249.170, Nqll = 653685946678.210\n",
      "L-BFGS iteration loss: Ntot = 106844547123.841, Nqll = 651731002275.956\n",
      "L-BFGS iteration loss: Ntot = 106822728231.138, Nqll = 649794846913.237\n",
      "L-BFGS iteration loss: Ntot = 106801100749.975, Nqll = 647877388624.977\n",
      "L-BFGS iteration loss: Ntot = 106779663861.571, Nqll = 645978535587.752\n",
      "L-BFGS iteration loss: Ntot = 106758416745.921, Nqll = 644098195808.218\n",
      "L-BFGS iteration loss: Ntot = 106737358588.115, Nqll = 642236277672.492\n",
      "L-BFGS iteration loss: Ntot = 106716488571.043, Nqll = 640392689307.976\n",
      "L-BFGS iteration loss: Ntot = 106695805875.074, Nqll = 638567338549.038\n",
      "L-BFGS iteration loss: Ntot = 106675309682.443, Nqll = 636760133323.461\n",
      "L-BFGS iteration loss: Ntot = 106654999166.674, Nqll = 634970980723.620\n",
      "L-BFGS iteration loss: Ntot = 106634873501.990, Nqll = 633199787828.169\n",
      "L-BFGS iteration loss: Ntot = 106614931849.584, Nqll = 631446460503.716\n",
      "L-BFGS iteration loss: Ntot = 106595173367.587, Nqll = 629710904276.436\n",
      "L-BFGS iteration loss: Ntot = 106575597200.674, Nqll = 627993023428.864\n",
      "L-BFGS iteration loss: Ntot = 106556202484.197, Nqll = 626292721359.808\n",
      "L-BFGS iteration loss: Ntot = 106536988340.809, Nqll = 624609900298.551\n",
      "L-BFGS iteration loss: Ntot = 106517953879.285, Nqll = 622944461203.615\n",
      "L-BFGS iteration loss: Ntot = 106499098193.710, Nqll = 621296303702.772\n",
      "L-BFGS iteration loss: Ntot = 106480420363.826, Nqll = 619665326128.175\n",
      "L-BFGS iteration loss: Ntot = 106461919452.376, Nqll = 618051425296.168\n",
      "L-BFGS iteration loss: Ntot = 106443594504.088, Nqll = 616454496423.738\n",
      "L-BFGS iteration loss: Ntot = 106425444551.869, Nqll = 614874433682.361\n",
      "L-BFGS iteration loss: Ntot = 106407468606.735, Nqll = 613311129329.878\n",
      "L-BFGS iteration loss: Ntot = 106389665669.731, Nqll = 611764474754.481\n",
      "L-BFGS iteration loss: Ntot = 106372034722.196, Nqll = 610234359643.697\n",
      "L-BFGS iteration loss: Ntot = 106354574732.760, Nqll = 608720672601.028\n",
      "L-BFGS iteration loss: Ntot = 106337284655.310, Nqll = 607223300977.749\n",
      "L-BFGS iteration loss: Ntot = 106320163429.894, Nqll = 605742130962.934\n",
      "L-BFGS iteration loss: Ntot = 106303209985.232, Nqll = 604277047810.418\n",
      "L-BFGS iteration loss: Ntot = 106286423240.002, Nqll = 602827935955.850\n",
      "L-BFGS iteration loss: Ntot = 106269802100.105, Nqll = 601394678793.517\n",
      "L-BFGS iteration loss: Ntot = 106253345467.875, Nqll = 599977159472.010\n",
      "L-BFGS iteration loss: Ntot = 106237052230.637, Nqll = 598575259925.753\n",
      "L-BFGS iteration loss: Ntot = 106220921274.869, Nqll = 597188862086.970\n",
      "L-BFGS iteration loss: Ntot = 106204951478.887, Nqll = 595817847274.662\n",
      "L-BFGS iteration loss: Ntot = 106189141715.790, Nqll = 594462096446.787\n",
      "L-BFGS iteration loss: Ntot = 106173490857.228, Nqll = 593121490529.454\n",
      "L-BFGS iteration loss: Ntot = 106157997771.189, Nqll = 591795910230.058\n",
      "L-BFGS iteration loss: Ntot = 106142661321.101, Nqll = 590485235967.729\n",
      "L-BFGS iteration loss: Ntot = 106127480374.113, Nqll = 589189348580.279\n",
      "L-BFGS iteration loss: Ntot = 106112453793.465, Nqll = 587908128676.153\n",
      "L-BFGS iteration loss: Ntot = 106097580442.837, Nqll = 586641457011.851\n",
      "L-BFGS iteration loss: Ntot = 106082859190.787, Nqll = 585389214862.203\n",
      "L-BFGS iteration loss: Ntot = 106068288900.737, Nqll = 584151283180.373\n",
      "L-BFGS iteration loss: Ntot = 106053868444.640, Nqll = 582927543752.981\n",
      "L-BFGS iteration loss: Ntot = 106039596693.438, Nqll = 581717878394.765\n",
      "L-BFGS iteration loss: Ntot = 106025472520.306, Nqll = 580522169222.802\n",
      "L-BFGS iteration loss: Ntot = 106011494804.332, Nqll = 579340298965.000\n",
      "L-BFGS iteration loss: Ntot = 105997662426.552, Nqll = 578172150631.813\n",
      "L-BFGS iteration loss: Ntot = 105983974270.972, Nqll = 577017607597.054\n",
      "L-BFGS iteration loss: Ntot = 105970429226.991, Nqll = 575876553802.008\n",
      "L-BFGS iteration loss: Ntot = 105957026187.106, Nqll = 574748873565.358\n",
      "L-BFGS iteration loss: Ntot = 105943764048.437, Nqll = 573634451705.535\n",
      "L-BFGS iteration loss: Ntot = 105930641712.943, Nqll = 572533173562.878\n",
      "L-BFGS iteration loss: Ntot = 105917658085.797, Nqll = 571444924860.486\n",
      "L-BFGS iteration loss: Ntot = 105904812077.560, Nqll = 570369591885.746\n",
      "L-BFGS iteration loss: Ntot = 105892102602.705, Nqll = 569307061365.166\n",
      "L-BFGS iteration loss: Ntot = 105879528579.569, Nqll = 568257220461.224\n",
      "L-BFGS iteration loss: Ntot = 105867088931.040, Nqll = 567219956831.270\n",
      "L-BFGS iteration loss: Ntot = 105854782584.722, Nqll = 566195158632.353\n",
      "L-BFGS iteration loss: Ntot = 105842608472.154, Nqll = 565182714465.847\n",
      "L-BFGS iteration loss: Ntot = 105830565527.523, Nqll = 564182513263.969\n",
      "L-BFGS iteration loss: Ntot = 105818652691.169, Nqll = 563194444580.135\n",
      "L-BFGS iteration loss: Ntot = 105806868904.080, Nqll = 562218398138.670\n",
      "L-BFGS iteration loss: Ntot = 105795213114.725, Nqll = 561254264390.767\n",
      "L-BFGS iteration loss: Ntot = 105783684269.410, Nqll = 560301933729.237\n",
      "L-BFGS iteration loss: Ntot = 105772281323.003, Nqll = 559361297365.718\n",
      "L-BFGS iteration loss: Ntot = 105761003232.419, Nqll = 558432246793.930\n",
      "L-BFGS iteration loss: Ntot = 105749848953.448, Nqll = 557514673539.844\n",
      "L-BFGS iteration loss: Ntot = 105738817450.115, Nqll = 556608469919.568\n",
      "L-BFGS iteration loss: Ntot = 105727907685.723, Nqll = 555713528315.225\n",
      "L-BFGS iteration loss: Ntot = 105717118627.323, Nqll = 554829741537.560\n",
      "L-BFGS iteration loss: Ntot = 105706449244.679, Nqll = 553957002746.406\n",
      "L-BFGS iteration loss: Ntot = 105695898509.000, Nqll = 553095205349.245\n",
      "L-BFGS iteration loss: Ntot = 105685465395.873, Nqll = 552244243240.307\n",
      "L-BFGS iteration loss: Ntot = 105675148881.119, Nqll = 551404010468.688\n",
      "L-BFGS iteration loss: Ntot = 105664947944.165, Nqll = 550574401515.409\n",
      "L-BFGS iteration loss: Ntot = 105654861567.079, Nqll = 549755311216.875\n",
      "L-BFGS iteration loss: Ntot = 105644888733.293, Nqll = 548946634666.093\n",
      "L-BFGS iteration loss: Ntot = 105635028431.219, Nqll = 548148267505.640\n",
      "L-BFGS iteration loss: Ntot = 105625279648.561, Nqll = 547360105475.465\n",
      "L-BFGS iteration loss: Ntot = 105615641379.563, Nqll = 546582044999.366\n",
      "L-BFGS iteration loss: Ntot = 105606112618.069, Nqll = 545813982629.347\n",
      "L-BFGS iteration loss: Ntot = 105596692363.487, Nqll = 545055815529.494\n",
      "L-BFGS iteration loss: Ntot = 105587379617.424, Nqll = 544307441208.299\n",
      "L-BFGS iteration loss: Ntot = 105578173385.529, Nqll = 543568757670.851\n",
      "L-BFGS iteration loss: Ntot = 105569072675.902, Nqll = 542839663295.418\n",
      "L-BFGS iteration loss: Ntot = 105560076501.572, Nqll = 542120057031.792\n",
      "L-BFGS iteration loss: Ntot = 105551183880.147, Nqll = 541409838381.004\n",
      "L-BFGS iteration loss: Ntot = 105542393832.187, Nqll = 540708907264.423\n",
      "L-BFGS iteration loss: Ntot = 105533705383.822, Nqll = 540017164236.368\n",
      "L-BFGS iteration loss: Ntot = 105525117565.338, Nqll = 539334510376.203\n",
      "L-BFGS iteration loss: Ntot = 105516629412.559, Nqll = 538660847397.139\n",
      "L-BFGS iteration loss: Ntot = 105508239964.872, Nqll = 537996077495.361\n",
      "L-BFGS iteration loss: Ntot = 105499948269.844, Nqll = 537340103711.959\n",
      "L-BFGS iteration loss: Ntot = 105491753377.394, Nqll = 536692829480.449\n",
      "L-BFGS iteration loss: Ntot = 105483654346.839, Nqll = 536054159179.324\n",
      "L-BFGS iteration loss: Ntot = 105475650238.800, Nqll = 535423997500.089\n",
      "L-BFGS iteration loss: Ntot = 105467740124.826, Nqll = 534802250198.650\n",
      "L-BFGS iteration loss: Ntot = 105459923078.681, Nqll = 534188823419.829\n",
      "L-BFGS iteration loss: Ntot = 105452198183.262, Nqll = 533583624233.130\n",
      "L-BFGS iteration loss: Ntot = 105444564526.862, Nqll = 532986560346.142\n",
      "L-BFGS iteration loss: Ntot = 105437021204.577, Nqll = 532397540210.706\n",
      "L-BFGS iteration loss: Ntot = 105429567318.324, Nqll = 531816473025.809\n",
      "L-BFGS iteration loss: Ntot = 105422201977.361, Nqll = 531243268777.872\n",
      "L-BFGS iteration loss: Ntot = 105414924297.258, Nqll = 530677838161.167\n",
      "L-BFGS iteration loss: Ntot = 105407733400.556, Nqll = 530120092625.899\n",
      "L-BFGS iteration loss: Ntot = 105400628417.960, Nqll = 529569944472.739\n",
      "L-BFGS iteration loss: Ntot = 105393608486.357, Nqll = 529027306697.039\n",
      "L-BFGS iteration loss: Ntot = 105386672750.530, Nqll = 528492093119.533\n",
      "L-BFGS iteration loss: Ntot = 105379820362.437, Nqll = 527964218331.432\n",
      "L-BFGS iteration loss: Ntot = 105373050481.551, Nqll = 527443597717.832\n",
      "L-BFGS iteration loss: Ntot = 105366362273.710, Nqll = 526930147369.963\n",
      "L-BFGS iteration loss: Ntot = 105359754913.818, Nqll = 526423784287.675\n",
      "L-BFGS iteration loss: Ntot = 105353227582.833, Nqll = 525924426150.137\n",
      "L-BFGS iteration loss: Ntot = 105346779468.960, Nqll = 525431991405.103\n",
      "L-BFGS iteration loss: Ntot = 105340409769.277, Nqll = 524946399388.548\n",
      "L-BFGS iteration loss: Ntot = 105334117687.036, Nqll = 524467570123.451\n",
      "L-BFGS iteration loss: Ntot = 105327902433.597, Nqll = 523995424455.196\n",
      "L-BFGS iteration loss: Ntot = 105321763227.081, Nqll = 523529883958.932\n",
      "L-BFGS iteration loss: Ntot = 105315699292.741, Nqll = 523070870956.257\n",
      "L-BFGS iteration loss: Ntot = 105309709863.792, Nqll = 522618308583.370\n",
      "L-BFGS iteration loss: Ntot = 105303794180.111, Nqll = 522172120685.667\n",
      "L-BFGS iteration loss: Ntot = 105297951490.230, Nqll = 521732231968.127\n",
      "L-BFGS iteration loss: Ntot = 105292181047.402, Nqll = 521298567698.808\n",
      "L-BFGS iteration loss: Ntot = 105286482113.667, Nqll = 520871054008.804\n",
      "L-BFGS iteration loss: Ntot = 105280853958.342, Nqll = 520449617780.507\n",
      "L-BFGS iteration loss: Ntot = 105275295857.005, Nqll = 520034186566.609\n",
      "L-BFGS iteration loss: Ntot = 105269807091.813, Nqll = 519624688615.439\n",
      "L-BFGS iteration loss: Ntot = 105264386952.547, Nqll = 519221052944.233\n",
      "L-BFGS iteration loss: Ntot = 105259034736.204, Nqll = 518823209305.540\n",
      "L-BFGS iteration loss: Ntot = 105253749745.596, Nqll = 518431088085.528\n",
      "L-BFGS iteration loss: Ntot = 105248531290.619, Nqll = 518044620392.063\n",
      "L-BFGS iteration loss: Ntot = 105243378687.621, Nqll = 517663738008.956\n",
      "L-BFGS iteration loss: Ntot = 105238291260.138, Nqll = 517288373445.626\n",
      "L-BFGS iteration loss: Ntot = 105233268337.359, Nqll = 516918459824.772\n",
      "L-BFGS iteration loss: Ntot = 105228309255.444, Nqll = 516553930975.395\n",
      "L-BFGS iteration loss: Ntot = 105223413356.229, Nqll = 516194721337.271\n",
      "L-BFGS iteration loss: Ntot = 105218579989.190, Nqll = 515840766102.491\n",
      "L-BFGS iteration loss: Ntot = 105213808508.212, Nqll = 515492000975.111\n",
      "L-BFGS iteration loss: Ntot = 105209098274.759, Nqll = 515148362407.513\n",
      "L-BFGS iteration loss: Ntot = 105204448654.979, Nqll = 514809787378.192\n",
      "L-BFGS iteration loss: Ntot = 105199859022.144, Nqll = 514476213576.046\n",
      "L-BFGS iteration loss: Ntot = 105195328755.130, Nqll = 514147579282.655\n",
      "L-BFGS iteration loss: Ntot = 105190857237.890, Nqll = 513823823336.093\n",
      "L-BFGS iteration loss: Ntot = 105186443860.787, Nqll = 513504885223.533\n",
      "L-BFGS iteration loss: Ntot = 105182088019.561, Nqll = 513190705005.600\n",
      "L-BFGS iteration loss: Ntot = 105177789115.779, Nqll = 512881223347.293\n",
      "L-BFGS iteration loss: Ntot = 105173546555.740, Nqll = 512576381438.505\n",
      "L-BFGS iteration loss: Ntot = 105169359751.852, Nqll = 512276121089.951\n",
      "L-BFGS iteration loss: Ntot = 105165228121.773, Nqll = 511980384671.348\n",
      "L-BFGS iteration loss: Ntot = 105161151087.994, Nqll = 511689115079.392\n",
      "L-BFGS iteration loss: Ntot = 105157128078.242, Nqll = 511402255765.509\n",
      "L-BFGS iteration loss: Ntot = 105153158525.544, Nqll = 511119750740.035\n",
      "L-BFGS iteration loss: Ntot = 105149241868.331, Nqll = 510841544573.862\n",
      "L-BFGS iteration loss: Ntot = 105145377548.479, Nqll = 510567582266.279\n",
      "L-BFGS iteration loss: Ntot = 105141565014.442, Nqll = 510297809456.676\n",
      "L-BFGS iteration loss: Ntot = 105137803718.777, Nqll = 510032172255.052\n",
      "L-BFGS iteration loss: Ntot = 105134093117.951, Nqll = 509770617223.343\n",
      "L-BFGS iteration loss: Ntot = 105130432674.542, Nqll = 509513091530.863\n",
      "L-BFGS iteration loss: Ntot = 105126821854.730, Nqll = 509259542776.294\n",
      "L-BFGS iteration loss: Ntot = 105123260129.358, Nqll = 509009919061.240\n",
      "L-BFGS iteration loss: Ntot = 105119746973.820, Nqll = 508764168980.623\n",
      "L-BFGS iteration loss: Ntot = 105116281867.990, Nqll = 508522241618.182\n",
      "L-BFGS iteration loss: Ntot = 105112864296.222, Nqll = 508284086543.107\n",
      "L-BFGS iteration loss: Ntot = 105109493746.466, Nqll = 508049653749.604\n",
      "L-BFGS iteration loss: Ntot = 105106169711.459, Nqll = 507818893736.401\n",
      "L-BFGS iteration loss: Ntot = 105102891688.124, Nqll = 507591757466.910\n",
      "L-BFGS iteration loss: Ntot = 105099659177.141, Nqll = 507368196335.940\n",
      "L-BFGS iteration loss: Ntot = 105096471683.614, Nqll = 507148162215.828\n",
      "L-BFGS iteration loss: Ntot = 105093328716.420, Nqll = 506931607409.824\n",
      "L-BFGS iteration loss: Ntot = 105090229788.932, Nqll = 506718484702.497\n",
      "L-BFGS iteration loss: Ntot = 105087174417.646, Nqll = 506508747263.453\n",
      "L-BFGS iteration loss: Ntot = 105084162123.509, Nqll = 506302348735.162\n",
      "L-BFGS iteration loss: Ntot = 105081192431.361, Nqll = 506099243198.367\n",
      "L-BFGS iteration loss: Ntot = 105078264869.468, Nqll = 505899385135.364\n",
      "L-BFGS iteration loss: Ntot = 105075378970.376, Nqll = 505702729488.977\n",
      "L-BFGS iteration loss: Ntot = 105072534270.448, Nqll = 505509231629.204\n",
      "L-BFGS iteration loss: Ntot = 105069730309.347, Nqll = 505318847317.600\n",
      "L-BFGS iteration loss: Ntot = 105066966630.761, Nqll = 505131532754.963\n",
      "L-BFGS iteration loss: Ntot = 105064242781.976, Nqll = 504947244552.163\n",
      "L-BFGS iteration loss: Ntot = 105061558314.294, Nqll = 504765939755.606\n",
      "L-BFGS iteration loss: Ntot = 105058912782.410, Nqll = 504587575805.646\n",
      "L-BFGS iteration loss: Ntot = 105056305744.856, Nqll = 504412110564.796\n",
      "L-BFGS iteration loss: Ntot = 105053736763.812, Nqll = 504239502303.613\n",
      "L-BFGS iteration loss: Ntot = 105051205404.932, Nqll = 504069709687.080\n",
      "L-BFGS iteration loss: Ntot = 105048711238.073, Nqll = 503902691824.805\n",
      "L-BFGS iteration loss: Ntot = 105046253836.061, Nqll = 503738408181.623\n",
      "L-BFGS iteration loss: Ntot = 105043832775.881, Nqll = 503576818663.293\n",
      "L-BFGS iteration loss: Ntot = 105041447638.107, Nqll = 503417883570.331\n",
      "L-BFGS iteration loss: Ntot = 105039098006.874, Nqll = 503261563595.770\n",
      "L-BFGS iteration loss: Ntot = 105036783470.423, Nqll = 503107819863.426\n",
      "L-BFGS iteration loss: Ntot = 105034503620.026, Nqll = 502956613852.524\n",
      "L-BFGS iteration loss: Ntot = 105032258051.395, Nqll = 502807907487.844\n",
      "L-BFGS iteration loss: Ntot = 105030046363.336, Nqll = 502661663053.260\n",
      "L-BFGS iteration loss: Ntot = 105027868158.850, Nqll = 502517843261.575\n",
      "L-BFGS iteration loss: Ntot = 105025723044.365, Nqll = 502376411203.635\n",
      "L-BFGS iteration loss: Ntot = 105023610630.297, Nqll = 502237330388.394\n",
      "L-BFGS iteration loss: Ntot = 105021530530.337, Nqll = 502100564690.655\n",
      "L-BFGS iteration loss: Ntot = 105019482362.400, Nqll = 501966078419.582\n",
      "L-BFGS iteration loss: Ntot = 105017465747.818, Nqll = 501833836260.260\n",
      "L-BFGS iteration loss: Ntot = 105015480311.387, Nqll = 501703803275.242\n",
      "L-BFGS iteration loss: Ntot = 105013525682.452, Nqll = 501575944968.689\n",
      "L-BFGS iteration loss: Ntot = 105011601493.619, Nqll = 501450227195.948\n",
      "L-BFGS iteration loss: Ntot = 105009707382.000, Nqll = 501326616238.186\n",
      "L-BFGS iteration loss: Ntot = 105007842988.361, Nqll = 501205078742.845\n",
      "L-BFGS iteration loss: Ntot = 105006007957.741, Nqll = 501085581763.252\n",
      "L-BFGS iteration loss: Ntot = 105004201939.177, Nqll = 500968092743.924\n",
      "L-BFGS iteration loss: Ntot = 105002424585.600, Nqll = 500852579519.053\n",
      "L-BFGS iteration loss: Ntot = 105000675554.185, Nqll = 500739010331.288\n",
      "L-BFGS iteration loss: Ntot = 104998954505.643, Nqll = 500627353786.490\n",
      "L-BFGS iteration loss: Ntot = 104997261104.835, Nqll = 500517578887.895\n",
      "L-BFGS iteration loss: Ntot = 104995595021.086, Nqll = 500409655058.403\n",
      "L-BFGS iteration loss: Ntot = 104993955927.251, Nqll = 500303552070.274\n",
      "L-BFGS iteration loss: Ntot = 104992343500.592, Nqll = 500199240103.581\n",
      "L-BFGS iteration loss: Ntot = 104990757422.396, Nqll = 500096689719.420\n",
      "L-BFGS iteration loss: Ntot = 104989197378.084, Nqll = 499995871863.308\n",
      "L-BFGS iteration loss: Ntot = 104987663057.301, Nqll = 499896757867.659\n",
      "L-BFGS iteration loss: Ntot = 104986154154.070, Nqll = 499799319463.989\n",
      "L-BFGS iteration loss: Ntot = 104984670366.197, Nqll = 499703528737.114\n",
      "L-BFGS iteration loss: Ntot = 104983211395.948, Nqll = 499609358170.347\n",
      "L-BFGS iteration loss: Ntot = 104981776949.681, Nqll = 499516780619.706\n",
      "L-BFGS iteration loss: Ntot = 104980366738.227, Nqll = 499425769334.801\n",
      "L-BFGS iteration loss: Ntot = 104978980476.170, Nqll = 499336297911.270\n",
      "L-BFGS iteration loss: Ntot = 104977617882.958, Nqll = 499248340359.703\n",
      "L-BFGS iteration loss: Ntot = 104976278681.726, Nqll = 499161871026.489\n",
      "L-BFGS iteration loss: Ntot = 104974962600.043, Nqll = 499076864639.669\n",
      "L-BFGS iteration loss: Ntot = 104973669369.982, Nqll = 498993296311.624\n",
      "L-BFGS iteration loss: Ntot = 104972398727.626, Nqll = 498911141503.655\n",
      "L-BFGS iteration loss: Ntot = 104971150413.393, Nqll = 498830376046.609\n",
      "L-BFGS iteration loss: Ntot = 104969924172.011, Nqll = 498750976135.259\n",
      "L-BFGS iteration loss: Ntot = 104968719752.418, Nqll = 498672918323.475\n",
      "L-BFGS iteration loss: Ntot = 104967536907.734, Nqll = 498596179515.653\n",
      "L-BFGS iteration loss: Ntot = 104966375395.457, Nqll = 498520736981.039\n",
      "L-BFGS iteration loss: Ntot = 104965234977.201, Nqll = 498446568332.550\n",
      "L-BFGS iteration loss: Ntot = 104964115418.784, Nqll = 498373651531.828\n",
      "L-BFGS iteration loss: Ntot = 104963016490.192, Nqll = 498301964881.491\n",
      "L-BFGS iteration loss: Ntot = 104961937965.829, Nqll = 498231487043.252\n",
      "L-BFGS iteration loss: Ntot = 104960879624.099, Nqll = 498162197004.642\n",
      "L-BFGS iteration loss: Ntot = 104959841247.463, Nqll = 498094074080.285\n",
      "L-BFGS iteration loss: Ntot = 104958822622.921, Nqll = 498027097945.610\n",
      "L-BFGS iteration loss: Ntot = 104957823541.512, Nqll = 497961248594.082\n",
      "L-BFGS iteration loss: Ntot = 104956843798.115, Nqll = 497896506322.716\n",
      "L-BFGS iteration loss: Ntot = 104955883192.387, Nqll = 497832851794.871\n",
      "L-BFGS iteration loss: Ntot = 104954941527.826, Nqll = 497770265969.061\n",
      "L-BFGS iteration loss: Ntot = 104954018612.405, Nqll = 497708730139.037\n",
      "L-BFGS iteration loss: Ntot = 104953114258.337, Nqll = 497648225911.238\n",
      "L-BFGS iteration loss: Ntot = 104952228282.427, Nqll = 497588735224.456\n",
      "L-BFGS iteration loss: Ntot = 104951360505.921, Nqll = 497530240328.701\n",
      "L-BFGS iteration loss: Ntot = 104950510754.822, Nqll = 497472723805.504\n",
      "L-BFGS iteration loss: Ntot = 104949678860.123, Nqll = 497416168569.041\n",
      "L-BFGS iteration loss: Ntot = 104948864657.797, Nqll = 497360557860.367\n",
      "L-BFGS iteration loss: Ntot = 104948067989.291, Nqll = 497305875269.111\n",
      "L-BFGS iteration loss: Ntot = 104947288701.699, Nqll = 497252104741.452\n",
      "L-BFGS iteration loss: Ntot = 104946526647.895, Nqll = 497199230577.844\n",
      "L-BFGS iteration loss: Ntot = 104945781686.799, Nqll = 497147237450.407\n",
      "L-BFGS iteration loss: Ntot = 104945053683.589, Nqll = 497096110418.789\n",
      "L-BFGS iteration loss: Ntot = 104944342509.483, Nqll = 497045834926.765\n",
      "L-BFGS iteration loss: Ntot = 104943648041.713, Nqll = 496996396815.870\n",
      "L-BFGS iteration loss: Ntot = 104942970162.660, Nqll = 496947782299.827\n",
      "L-BFGS iteration loss: Ntot = 104942308759.484, Nqll = 496899977980.798\n",
      "L-BFGS iteration loss: Ntot = 104941663722.494, Nqll = 496852970792.081\n",
      "L-BFGS iteration loss: Ntot = 104941034943.990, Nqll = 496806747973.546\n",
      "L-BFGS iteration loss: Ntot = 104940422316.477, Nqll = 496761297006.981\n",
      "L-BFGS iteration loss: Ntot = 104939825731.359, Nqll = 496716605565.745\n",
      "L-BFGS iteration loss: Ntot = 104939245077.835, Nqll = 496672661441.021\n",
      "L-BFGS iteration loss: Ntot = 104938680243.497, Nqll = 496629452512.674\n",
      "L-BFGS iteration loss: Ntot = 104938131122.041, Nqll = 496586966849.406\n",
      "L-BFGS iteration loss: Ntot = 104937597680.373, Nqll = 496545193946.418\n",
      "L-BFGS iteration loss: Ntot = 104937080691.515, Nqll = 496504138250.393\n",
      "L-BFGS iteration loss: Ntot = 104936591720.989, Nqll = 496463999311.347\n",
      "L-BFGS iteration loss: Ntot = 104936318614.885, Nqll = 496428157815.855\n",
      "L-BFGS iteration loss: Ntot = 118712612950.200, Nqll = 1592577491605.450\n",
      "L-BFGS iteration loss: Ntot = 106259040895.061, Nqll = 581144194012.071\n",
      "L-BFGS iteration loss: Ntot = 105109587108.999, Nqll = 504096905148.078\n",
      "L-BFGS iteration loss: Ntot = 104969233701.553, Nqll = 497333273280.266\n",
      "L-BFGS iteration loss: Ntot = 104943576047.361, Nqll = 496537592428.583\n",
      "L-BFGS iteration loss: Ntot = 104937201373.093, Nqll = 496403771879.132\n",
      "L-BFGS iteration loss: Ntot = 104935501782.038, Nqll = 496377690321.549\n",
      "L-BFGS iteration loss: Ntot = 104934986030.279, Nqll = 496370447461.313\n",
      "L-BFGS iteration loss: Ntot = 104934693957.301, Nqll = 496365776971.432\n",
      "L-BFGS iteration loss: Ntot = 104934476953.738, Nqll = 496361721385.642\n",
      "L-BFGS iteration loss: Ntot = 104934295132.579, Nqll = 496357835645.234\n",
      "L-BFGS iteration loss: Ntot = 104934133004.186, Nqll = 496353972593.176\n",
      "L-BFGS iteration loss: Ntot = 104933983218.246, Nqll = 496350073761.870\n",
      "L-BFGS iteration loss: Ntot = 104933841818.415, Nqll = 496346113681.954\n",
      "L-BFGS iteration loss: Ntot = 104933706481.884, Nqll = 496342080966.843\n",
      "L-BFGS iteration loss: Ntot = 104933575756.542, Nqll = 496337970853.150\n",
      "L-BFGS iteration loss: Ntot = 104933448688.865, Nqll = 496333781848.879\n",
      "L-BFGS iteration loss: Ntot = 104933324629.426, Nqll = 496329514164.146\n",
      "L-BFGS iteration loss: Ntot = 104933203122.077, Nqll = 496325168918.484\n",
      "L-BFGS iteration loss: Ntot = 104933083838.600, Nqll = 496320747705.184\n",
      "L-BFGS iteration loss: Ntot = 104932966538.343, Nqll = 496316252376.818\n",
      "L-BFGS iteration loss: Ntot = 104932851041.820, Nqll = 496311684913.783\n",
      "L-BFGS iteration loss: Ntot = 104932737213.419, Nqll = 496307047341.075\n",
      "L-BFGS iteration loss: Ntot = 104932624949.708, Nqll = 496302341701.272\n",
      "L-BFGS iteration loss: Ntot = 104932514171.410, Nqll = 496297570042.566\n",
      "L-BFGS iteration loss: Ntot = 104932404817.194, Nqll = 496292734382.124\n",
      "L-BFGS iteration loss: Ntot = 104932296839.737, Nqll = 496287836730.222\n",
      "L-BFGS iteration loss: Ntot = 104932190202.638, Nqll = 496282879073.185\n",
      "L-BFGS iteration loss: Ntot = 104932084877.959, Nqll = 496277863372.307\n",
      "L-BFGS iteration loss: Ntot = 104931980844.703, Nqll = 496272791580.690\n",
      "L-BFGS iteration loss: Ntot = 104931878087.428, Nqll = 496267665635.675\n",
      "L-BFGS iteration loss: Ntot = 104931776595.263, Nqll = 496262487469.702\n",
      "L-BFGS iteration loss: Ntot = 104931676361.135, Nqll = 496257259005.444\n",
      "L-BFGS iteration loss: Ntot = 104931577381.158, Nqll = 496251982164.096\n",
      "L-BFGS iteration loss: Ntot = 104931479654.293, Nqll = 496246658872.614\n",
      "L-BFGS iteration loss: Ntot = 104931383181.952, Nqll = 496241291072.060\n",
      "L-BFGS iteration loss: Ntot = 104931287967.626, Nqll = 496235880698.979\n",
      "L-BFGS iteration loss: Ntot = 104931194016.888, Nqll = 496230429724.816\n",
      "L-BFGS iteration loss: Ntot = 104931101337.035, Nqll = 496224940125.311\n",
      "L-BFGS iteration loss: Ntot = 104931009937.056, Nqll = 496219413910.389\n",
      "L-BFGS iteration loss: Ntot = 104930919827.652, Nqll = 496213853111.216\n",
      "L-BFGS iteration loss: Ntot = 104930831021.050, Nqll = 496208259799.295\n",
      "L-BFGS iteration loss: Ntot = 104930743530.885, Nqll = 496202636074.325\n",
      "L-BFGS iteration loss: Ntot = 104930657372.384, Nqll = 496196984083.274\n",
      "L-BFGS iteration loss: Ntot = 104930572561.998, Nqll = 496191306010.389\n",
      "L-BFGS iteration loss: Ntot = 104930489117.754, Nqll = 496185604103.666\n",
      "L-BFGS iteration loss: Ntot = 104930407058.752, Nqll = 496179880642.825\n",
      "L-BFGS iteration loss: Ntot = 104930326405.334, Nqll = 496174137970.439\n",
      "L-BFGS iteration loss: Ntot = 104930247178.907, Nqll = 496168378487.762\n",
      "L-BFGS iteration loss: Ntot = 104930169401.653, Nqll = 496162604641.841\n",
      "L-BFGS iteration loss: Ntot = 104930093096.329, Nqll = 496156818934.496\n",
      "L-BFGS iteration loss: Ntot = 104930018286.150, Nqll = 496151023926.812\n",
      "L-BFGS iteration loss: Ntot = 104929944994.090, Nqll = 496145222212.557\n",
      "L-BFGS iteration loss: Ntot = 104929873242.659, Nqll = 496139416433.809\n",
      "L-BFGS iteration loss: Ntot = 104929803053.078, Nqll = 496133609243.131\n",
      "L-BFGS iteration loss: Ntot = 104929734445.030, Nqll = 496127803318.561\n",
      "L-BFGS iteration loss: Ntot = 104929667435.444, Nqll = 496122001322.852\n",
      "L-BFGS iteration loss: Ntot = 104929602038.079, Nqll = 496116205892.136\n",
      "L-BFGS iteration loss: Ntot = 104929538262.127, Nqll = 496110419604.418\n",
      "L-BFGS iteration loss: Ntot = 104929476111.763, Nqll = 496104644954.973\n",
      "L-BFGS iteration loss: Ntot = 104929415585.254, Nqll = 496098884325.203\n",
      "L-BFGS iteration loss: Ntot = 104929356673.589, Nqll = 496093139943.426\n",
      "L-BFGS iteration loss: Ntot = 104929299359.896, Nqll = 496087413846.044\n",
      "L-BFGS iteration loss: Ntot = 104929243619.126, Nqll = 496081707857.996\n",
      "L-BFGS iteration loss: Ntot = 104929189417.804, Nqll = 496076023544.972\n",
      "L-BFGS iteration loss: Ntot = 104929136713.656, Nqll = 496070362192.928\n",
      "L-BFGS iteration loss: Ntot = 104929085456.435, Nqll = 496064724791.445\n",
      "L-BFGS iteration loss: Ntot = 104929035588.070, Nqll = 496059112006.142\n",
      "L-BFGS iteration loss: Ntot = 104928987044.642, Nqll = 496053524185.512\n",
      "L-BFGS iteration loss: Ntot = 104928939757.536, Nqll = 496047961376.080\n",
      "L-BFGS iteration loss: Ntot = 104928893655.265, Nqll = 496042423321.725\n",
      "L-BFGS iteration loss: Ntot = 104928848665.196, Nqll = 496036909496.332\n",
      "L-BFGS iteration loss: Ntot = 104928804716.258, Nqll = 496031419140.541\n",
      "L-BFGS iteration loss: Ntot = 104928761740.756, Nqll = 496025951314.664\n",
      "L-BFGS iteration loss: Ntot = 104928719675.254, Nqll = 496020504910.261\n",
      "L-BFGS iteration loss: Ntot = 104928678463.076, Nqll = 496015078724.355\n",
      "L-BFGS iteration loss: Ntot = 104928638055.428, Nqll = 496009671498.776\n",
      "L-BFGS iteration loss: Ntot = 104928598411.444, Nqll = 496004281960.500\n",
      "L-BFGS iteration loss: Ntot = 104928559498.173, Nqll = 495998908842.280\n",
      "L-BFGS iteration loss: Ntot = 104928521291.584, Nqll = 495993550934.388\n",
      "L-BFGS iteration loss: Ntot = 104928483775.314, Nqll = 495988207089.731\n",
      "L-BFGS iteration loss: Ntot = 104928446939.417, Nqll = 495982876253.634\n",
      "L-BFGS iteration loss: Ntot = 104928410781.073, Nqll = 495977557470.112\n",
      "L-BFGS iteration loss: Ntot = 104928375302.243, Nqll = 495972249890.069\n",
      "L-BFGS iteration loss: Ntot = 104928340508.030, Nqll = 495966952754.914\n",
      "L-BFGS iteration loss: Ntot = 104928306408.227, Nqll = 495961665421.800\n",
      "L-BFGS iteration loss: Ntot = 104928273013.794, Nqll = 495956387336.417\n",
      "L-BFGS iteration loss: Ntot = 104928240337.740, Nqll = 495951118048.750\n",
      "L-BFGS iteration loss: Ntot = 104928208393.494, Nqll = 495945857178.278\n",
      "L-BFGS iteration loss: Ntot = 104928177194.544, Nqll = 495940604424.801\n",
      "L-BFGS iteration loss: Ntot = 104928146753.941, Nqll = 495935359546.611\n",
      "L-BFGS iteration loss: Ntot = 104928117085.072, Nqll = 495930122373.610\n",
      "L-BFGS iteration loss: Ntot = 104928088200.039, Nqll = 495924892786.764\n",
      "L-BFGS iteration loss: Ntot = 104928060109.702, Nqll = 495919670706.419\n",
      "L-BFGS iteration loss: Ntot = 104928032824.182, Nqll = 495914456090.119\n",
      "L-BFGS iteration loss: Ntot = 104928006352.563, Nqll = 495909248931.280\n",
      "L-BFGS iteration loss: Ntot = 104927980702.836, Nqll = 495904049254.113\n",
      "L-BFGS iteration loss: Ntot = 104927955881.457, Nqll = 495898857099.314\n",
      "L-BFGS iteration loss: Ntot = 104927931894.581, Nqll = 495893672529.214\n",
      "L-BFGS iteration loss: Ntot = 104927908747.245, Nqll = 495888495625.955\n",
      "L-BFGS iteration loss: Ntot = 104927886443.868, Nqll = 495883326489.885\n",
      "L-BFGS iteration loss: Ntot = 104927864987.676, Nqll = 495878165223.560\n",
      "L-BFGS iteration loss: Ntot = 104927844381.620, Nqll = 495873011946.346\n",
      "L-BFGS iteration loss: Ntot = 104927824627.124, Nqll = 495867866766.526\n",
      "L-BFGS iteration loss: Ntot = 104927805726.758, Nqll = 495862729833.659\n",
      "L-BFGS iteration loss: Ntot = 104927787681.743, Nqll = 495857601276.054\n",
      "L-BFGS iteration loss: Ntot = 104927770492.275, Nqll = 495852481227.219\n",
      "L-BFGS iteration loss: Ntot = 104927754159.372, Nqll = 495847369836.886\n",
      "L-BFGS iteration loss: Ntot = 104927738683.042, Nqll = 495842267249.009\n",
      "L-BFGS iteration loss: Ntot = 104927724063.348, Nqll = 495837173608.914\n",
      "L-BFGS iteration loss: Ntot = 104927710300.106, Nqll = 495832089067.579\n",
      "L-BFGS iteration loss: Ntot = 104927697392.747, Nqll = 495827013770.578\n",
      "L-BFGS iteration loss: Ntot = 104927685340.360, Nqll = 495821947867.952\n",
      "L-BFGS iteration loss: Ntot = 104927674143.961, Nqll = 495816891527.620\n",
      "L-BFGS iteration loss: Ntot = 104927663800.202, Nqll = 495811844869.221\n",
      "L-BFGS iteration loss: Ntot = 104927654309.805, Nqll = 495806808065.848\n",
      "L-BFGS iteration loss: Ntot = 104927645671.600, Nqll = 495801781257.120\n",
      "L-BFGS iteration loss: Ntot = 104927637884.471, Nqll = 495796764597.613\n",
      "L-BFGS iteration loss: Ntot = 104927630948.016, Nqll = 495791758244.060\n",
      "L-BFGS iteration loss: Ntot = 104927624859.708, Nqll = 495786762319.557\n",
      "L-BFGS iteration loss: Ntot = 104927619619.473, Nqll = 495781776987.987\n",
      "L-BFGS iteration loss: Ntot = 104927615225.933, Nqll = 495776802392.476\n",
      "L-BFGS iteration loss: Ntot = 104927611677.829, Nqll = 495771838671.235\n",
      "L-BFGS iteration loss: Ntot = 104927608974.014, Nqll = 495766885970.952\n",
      "L-BFGS iteration loss: Ntot = 104927607112.935, Nqll = 495761944423.333\n",
      "L-BFGS iteration loss: Ntot = 104927606094.341, Nqll = 495757014184.033\n",
      "L-BFGS iteration loss: Ntot = 104927605916.014, Nqll = 495752095377.295\n",
      "L-BFGS iteration loss: Ntot = 104927606577.059, Nqll = 495747188137.907\n",
      "L-BFGS iteration loss: Ntot = 104927608076.121, Nqll = 495742292602.737\n",
      "L-BFGS iteration loss: Ntot = 104927610412.475, Nqll = 495737408908.974\n",
      "L-BFGS iteration loss: Ntot = 104927613584.344, Nqll = 495732537179.295\n",
      "L-BFGS iteration loss: Ntot = 104927617590.937, Nqll = 495727677548.252\n",
      "L-BFGS iteration loss: Ntot = 104927622430.661, Nqll = 495722830137.393\n",
      "L-BFGS iteration loss: Ntot = 104927628102.076, Nqll = 495717995066.179\n",
      "L-BFGS iteration loss: Ntot = 104927634604.534, Nqll = 495713172462.414\n",
      "L-BFGS iteration loss: Ntot = 104927641936.885, Nqll = 495708362453.424\n",
      "L-BFGS iteration loss: Ntot = 104927650097.163, Nqll = 495703565142.630\n",
      "L-BFGS iteration loss: Ntot = 104927659085.043, Nqll = 495698780656.902\n",
      "L-BFGS iteration loss: Ntot = 104927668898.837, Nqll = 495694009107.170\n",
      "L-BFGS iteration loss: Ntot = 104927679537.372, Nqll = 495689250603.647\n",
      "L-BFGS iteration loss: Ntot = 104927690999.750, Nqll = 495684505260.038\n",
      "L-BFGS iteration loss: Ntot = 104927703284.777, Nqll = 495679773181.367\n",
      "L-BFGS iteration loss: Ntot = 104927716391.205, Nqll = 495675054473.846\n",
      "L-BFGS iteration loss: Ntot = 104927730318.112, Nqll = 495670349247.003\n",
      "L-BFGS iteration loss: Ntot = 104927745063.636, Nqll = 495665657587.438\n",
      "L-BFGS iteration loss: Ntot = 104927760627.591, Nqll = 495660979607.211\n",
      "L-BFGS iteration loss: Ntot = 104927777008.316, Nqll = 495656315397.962\n",
      "L-BFGS iteration loss: Ntot = 104927794205.285, Nqll = 495651665060.490\n",
      "L-BFGS iteration loss: Ntot = 104927812216.907, Nqll = 495647028683.380\n",
      "L-BFGS iteration loss: Ntot = 104927831042.780, Nqll = 495642406369.298\n",
      "L-BFGS iteration loss: Ntot = 104927850680.600, Nqll = 495637798184.923\n",
      "L-BFGS iteration loss: Ntot = 104927871130.667, Nqll = 495633204237.123\n",
      "L-BFGS iteration loss: Ntot = 104927892391.088, Nqll = 495628624599.795\n",
      "L-BFGS iteration loss: Ntot = 104927914461.556, Nqll = 495624059366.367\n",
      "L-BFGS iteration loss: Ntot = 104927937340.874, Nqll = 495619508615.448\n",
      "L-BFGS iteration loss: Ntot = 104927961027.616, Nqll = 495614972415.208\n",
      "L-BFGS iteration loss: Ntot = 104927985522.021, Nqll = 495610450868.236\n",
      "L-BFGS iteration loss: Ntot = 104928010821.154, Nqll = 495605944013.916\n",
      "L-BFGS iteration loss: Ntot = 104928036926.041, Nqll = 495601451956.741\n",
      "L-BFGS iteration loss: Ntot = 104928063834.412, Nqll = 495596974745.413\n",
      "L-BFGS iteration loss: Ntot = 104928091546.291, Nqll = 495592512467.144\n",
      "L-BFGS iteration loss: Ntot = 104928120060.076, Nqll = 495588065178.530\n",
      "L-BFGS iteration loss: Ntot = 104928149375.982, Nqll = 495583632958.981\n",
      "L-BFGS iteration loss: Ntot = 104928179491.959, Nqll = 495579215858.211\n",
      "L-BFGS iteration loss: Ntot = 104928210407.932, Nqll = 495574813946.822\n",
      "L-BFGS iteration loss: Ntot = 104928242122.892, Nqll = 495570427282.661\n",
      "L-BFGS iteration loss: Ntot = 104928274635.674, Nqll = 495566055921.446\n",
      "L-BFGS iteration loss: Ntot = 104928307945.516, Nqll = 495561699916.829\n",
      "L-BFGS iteration loss: Ntot = 104928342052.940, Nqll = 495557359343.000\n",
      "L-BFGS iteration loss: Ntot = 104928376955.725, Nqll = 495553034237.226\n",
      "L-BFGS iteration loss: Ntot = 104928412653.715, Nqll = 495548724657.803\n",
      "L-BFGS iteration loss: Ntot = 104928449145.873, Nqll = 495544430648.346\n",
      "L-BFGS iteration loss: Ntot = 104928486431.368, Nqll = 495540152254.655\n",
      "L-BFGS iteration loss: Ntot = 104928524510.651, Nqll = 495535889542.169\n",
      "L-BFGS iteration loss: Ntot = 104928563382.015, Nqll = 495531642543.064\n",
      "L-BFGS iteration loss: Ntot = 104928603045.431, Nqll = 495527411306.294\n",
      "L-BFGS iteration loss: Ntot = 104928643499.429, Nqll = 495523195867.858\n",
      "L-BFGS iteration loss: Ntot = 104928684744.330, Nqll = 495518996278.371\n",
      "L-BFGS iteration loss: Ntot = 104928726779.017, Nqll = 495514812570.107\n",
      "L-BFGS iteration loss: Ntot = 104928769602.366, Nqll = 495510644773.196\n",
      "L-BFGS iteration loss: Ntot = 104928813215.255, Nqll = 495506492944.016\n",
      "L-BFGS iteration loss: Ntot = 104928857615.482, Nqll = 495502357095.336\n",
      "L-BFGS iteration loss: Ntot = 104928902804.232, Nqll = 495498237284.096\n",
      "L-BFGS iteration loss: Ntot = 104928948779.492, Nqll = 495494133522.902\n",
      "L-BFGS iteration loss: Ntot = 104928995541.518, Nqll = 495490045850.901\n",
      "L-BFGS iteration loss: Ntot = 104929043089.887, Nqll = 495485974298.835\n",
      "L-BFGS iteration loss: Ntot = 104929091423.536, Nqll = 495481918886.437\n",
      "L-BFGS iteration loss: Ntot = 104929140542.887, Nqll = 495477879657.254\n",
      "L-BFGS iteration loss: Ntot = 104929190447.682, Nqll = 495473856635.814\n",
      "L-BFGS iteration loss: Ntot = 104929241135.337, Nqll = 495469849814.891\n",
      "L-BFGS iteration loss: Ntot = 104929292607.782, Nqll = 495465859251.495\n",
      "L-BFGS iteration loss: Ntot = 104929344863.696, Nqll = 495461884951.866\n",
      "L-BFGS iteration loss: Ntot = 104929397903.910, Nqll = 495457926958.682\n",
      "L-BFGS iteration loss: Ntot = 104929451725.946, Nqll = 495453985261.978\n",
      "L-BFGS iteration loss: Ntot = 104929506331.073, Nqll = 495450059895.418\n",
      "L-BFGS iteration loss: Ntot = 104929561718.170, Nqll = 495446150869.984\n",
      "L-BFGS iteration loss: Ntot = 104929617887.972, Nqll = 495442258217.195\n",
      "L-BFGS iteration loss: Ntot = 104929674838.877, Nqll = 495438381929.370\n",
      "L-BFGS iteration loss: Ntot = 104929732571.888, Nqll = 495434522043.099\n",
      "L-BFGS iteration loss: Ntot = 104929791085.656, Nqll = 495430678552.548\n",
      "L-BFGS iteration loss: Ntot = 104929850381.308, Nqll = 495426851490.813\n",
      "L-BFGS iteration loss: Ntot = 104929910457.438, Nqll = 495423040854.231\n",
      "L-BFGS iteration loss: Ntot = 104929971314.678, Nqll = 495419246660.762\n",
      "L-BFGS iteration loss: Ntot = 104930032951.817, Nqll = 495415468905.532\n",
      "L-BFGS iteration loss: Ntot = 104930095369.761, Nqll = 495411707609.250\n",
      "L-BFGS iteration loss: Ntot = 104930158567.960, Nqll = 495407962779.704\n",
      "L-BFGS iteration loss: Ntot = 104930222546.425, Nqll = 495404234418.742\n",
      "L-BFGS iteration loss: Ntot = 104930287304.797, Nqll = 495400522531.191\n",
      "L-BFGS iteration loss: Ntot = 104930352843.338, Nqll = 495396827126.479\n",
      "L-BFGS iteration loss: Ntot = 104930419161.594, Nqll = 495393148202.887\n",
      "L-BFGS iteration loss: Ntot = 104930486260.916, Nqll = 495389485782.806\n",
      "L-BFGS iteration loss: Ntot = 104930554139.626, Nqll = 495385839847.545\n",
      "L-BFGS iteration loss: Ntot = 104930622797.976, Nqll = 495382210400.009\n",
      "L-BFGS iteration loss: Ntot = 104930692236.747, Nqll = 495378597451.654\n",
      "L-BFGS iteration loss: Ntot = 104930762455.399, Nqll = 495375000995.300\n",
      "L-BFGS iteration loss: Ntot = 104930833453.851, Nqll = 495371421027.899\n",
      "L-BFGS iteration loss: Ntot = 104930905232.722, Nqll = 495367857552.944\n",
      "L-BFGS iteration loss: Ntot = 104930977792.038, Nqll = 495364310573.366\n",
      "L-BFGS iteration loss: Ntot = 104931051131.998, Nqll = 495360780083.619\n",
      "L-BFGS iteration loss: Ntot = 104931125251.935, Nqll = 495357266069.001\n",
      "L-BFGS iteration loss: Ntot = 104931200153.067, Nqll = 495353768544.784\n",
      "L-BFGS iteration loss: Ntot = 104931275834.802, Nqll = 495350287489.526\n",
      "L-BFGS iteration loss: Ntot = 104931352297.517, Nqll = 495346822903.017\n",
      "L-BFGS iteration loss: Ntot = 104931429542.226, Nqll = 495343374795.688\n",
      "L-BFGS iteration loss: Ntot = 104931507567.797, Nqll = 495339943135.143\n",
      "L-BFGS iteration loss: Ntot = 104931586375.122, Nqll = 495336527926.123\n",
      "L-BFGS iteration loss: Ntot = 104931665964.996, Nqll = 495333129171.825\n",
      "L-BFGS iteration loss: Ntot = 104931746336.549, Nqll = 495329746840.635\n",
      "L-BFGS iteration loss: Ntot = 104931827490.837, Nqll = 495326380941.478\n",
      "L-BFGS iteration loss: Ntot = 104931909429.210, Nqll = 495323031477.477\n",
      "L-BFGS iteration loss: Ntot = 104931992150.134, Nqll = 495319698412.737\n",
      "L-BFGS iteration loss: Ntot = 104932075653.993, Nqll = 495316381737.531\n",
      "L-BFGS iteration loss: Ntot = 104932159943.269, Nqll = 495313081469.845\n",
      "L-BFGS iteration loss: Ntot = 104932245016.364, Nqll = 495309797572.551\n",
      "L-BFGS iteration loss: Ntot = 104932330874.299, Nqll = 495306530044.308\n",
      "L-BFGS iteration loss: Ntot = 104932417517.493, Nqll = 495303278869.277\n",
      "L-BFGS iteration loss: Ntot = 104932504946.848, Nqll = 495300044041.258\n",
      "L-BFGS iteration loss: Ntot = 104932593162.939, Nqll = 495296825554.188\n",
      "L-BFGS iteration loss: Ntot = 104932682164.970, Nqll = 495293623373.903\n",
      "L-BFGS iteration loss: Ntot = 104932771954.908, Nqll = 495290437508.511\n",
      "L-BFGS iteration loss: Ntot = 104932862532.280, Nqll = 495287267927.846\n",
      "L-BFGS iteration loss: Ntot = 104932953898.857, Nqll = 495284114637.962\n",
      "L-BFGS iteration loss: Ntot = 104933046054.083, Nqll = 495280977607.888\n",
      "L-BFGS iteration loss: Ntot = 104933138998.723, Nqll = 495277856826.021\n",
      "L-BFGS iteration loss: Ntot = 104933232733.759, Nqll = 495274752280.139\n",
      "L-BFGS iteration loss: Ntot = 104933327260.101, Nqll = 495271663961.362\n",
      "L-BFGS iteration loss: Ntot = 104933422577.462, Nqll = 495268591843.269\n",
      "L-BFGS iteration loss: Ntot = 104933518687.541, Nqll = 495265535919.820\n",
      "L-BFGS iteration loss: Ntot = 104933615590.089, Nqll = 495262496161.244\n",
      "L-BFGS iteration loss: Ntot = 104933713286.625, Nqll = 495259472564.743\n",
      "L-BFGS iteration loss: Ntot = 104933811777.593, Nqll = 495256465111.610\n",
      "L-BFGS iteration loss: Ntot = 104933911064.251, Nqll = 495253473791.567\n",
      "L-BFGS iteration loss: Ntot = 104934011146.174, Nqll = 495250498569.371\n",
      "L-BFGS iteration loss: Ntot = 104934112025.225, Nqll = 495247539443.479\n",
      "L-BFGS iteration loss: Ntot = 104934213701.781, Nqll = 495244596387.420\n",
      "L-BFGS iteration loss: Ntot = 104934316176.954, Nqll = 495241669393.784\n",
      "L-BFGS iteration loss: Ntot = 104934419451.556, Nqll = 495238758441.767\n",
      "L-BFGS iteration loss: Ntot = 104934523526.539, Nqll = 495235863513.742\n",
      "L-BFGS iteration loss: Ntot = 104934628402.450, Nqll = 495232984586.299\n",
      "L-BFGS iteration loss: Ntot = 104934734080.829, Nqll = 495230121652.083\n",
      "L-BFGS iteration loss: Ntot = 104934840561.901, Nqll = 495227274681.463\n",
      "L-BFGS iteration loss: Ntot = 104934947846.971, Nqll = 495224443661.624\n",
      "L-BFGS iteration loss: Ntot = 104935055936.703, Nqll = 495221628566.595\n",
      "L-BFGS iteration loss: Ntot = 104935164833.092, Nqll = 495218829394.323\n",
      "L-BFGS iteration loss: Ntot = 104935274536.332, Nqll = 495216046114.658\n",
      "L-BFGS iteration loss: Ntot = 104935385048.103, Nqll = 495213278717.391\n",
      "L-BFGS iteration loss: Ntot = 104935496368.875, Nqll = 495210527173.403\n",
      "L-BFGS iteration loss: Ntot = 104935608500.133, Nqll = 495207791473.925\n",
      "L-BFGS iteration loss: Ntot = 104935721442.876, Nqll = 495205071594.345\n",
      "L-BFGS iteration loss: Ntot = 104935835197.458, Nqll = 495202367504.592\n",
      "L-BFGS iteration loss: Ntot = 104935949766.984, Nqll = 495199679212.992\n",
      "L-BFGS iteration loss: Ntot = 104936065150.783, Nqll = 495197006677.378\n",
      "L-BFGS iteration loss: Ntot = 104936181351.274, Nqll = 495194349893.309\n",
      "L-BFGS iteration loss: Ntot = 104936298369.019, Nqll = 495191708835.577\n",
      "L-BFGS iteration loss: Ntot = 104936416204.963, Nqll = 495189083474.383\n",
      "L-BFGS iteration loss: Ntot = 104936534861.883, Nqll = 495186473817.285\n",
      "L-BFGS iteration loss: Ntot = 104936654339.627, Nqll = 495183879823.581\n",
      "L-BFGS iteration loss: Ntot = 104936774639.768, Nqll = 495181301474.862\n",
      "L-BFGS iteration loss: Ntot = 104936895764.163, Nqll = 495178738763.070\n",
      "L-BFGS iteration loss: Ntot = 104937017713.912, Nqll = 495176191662.804\n",
      "L-BFGS iteration loss: Ntot = 104937140490.368, Nqll = 495173660157.397\n",
      "L-BFGS iteration loss: Ntot = 104937264094.918, Nqll = 495171144221.421\n",
      "L-BFGS iteration loss: Ntot = 104937388529.383, Nqll = 495168643850.174\n",
      "L-BFGS iteration loss: Ntot = 104937513794.665, Nqll = 495166159009.903\n",
      "L-BFGS iteration loss: Ntot = 104937639892.083, Nqll = 495163689681.240\n",
      "L-BFGS iteration loss: Ntot = 104937766824.798, Nqll = 495161235869.491\n",
      "L-BFGS iteration loss: Ntot = 104937894592.519, Nqll = 495158797533.783\n",
      "L-BFGS iteration loss: Ntot = 104938023196.528, Nqll = 495156374643.179\n",
      "L-BFGS iteration loss: Ntot = 104938152640.408, Nqll = 495153967211.706\n",
      "L-BFGS iteration loss: Ntot = 104938282924.576, Nqll = 495151575207.487\n",
      "L-BFGS iteration loss: Ntot = 104938414050.022, Nqll = 495149198598.816\n",
      "L-BFGS iteration loss: Ntot = 104938546019.699, Nqll = 495146837383.710\n",
      "L-BFGS iteration loss: Ntot = 104938678834.785, Nqll = 495144491541.791\n",
      "L-BFGS iteration loss: Ntot = 104938812497.027, Nqll = 495142161057.216\n",
      "L-BFGS iteration loss: Ntot = 104938947007.517, Nqll = 495139845895.370\n",
      "L-BFGS iteration loss: Ntot = 104939082368.650, Nqll = 495137546055.573\n",
      "L-BFGS iteration loss: Ntot = 104939218582.185, Nqll = 495135261513.639\n",
      "L-BFGS iteration loss: Ntot = 104939355650.371, Nqll = 495132992261.975\n",
      "L-BFGS iteration loss: Ntot = 104939493574.044, Nqll = 495130738267.471\n",
      "L-BFGS iteration loss: Ntot = 104939632355.310, Nqll = 495128499518.650\n",
      "L-BFGS iteration loss: Ntot = 104939771996.278, Nqll = 495126275998.473\n",
      "L-BFGS iteration loss: Ntot = 104939912498.754, Nqll = 495124067691.026\n",
      "L-BFGS iteration loss: Ntot = 104940053864.911, Nqll = 495121874579.279\n",
      "L-BFGS iteration loss: Ntot = 104940196097.249, Nqll = 495119696661.042\n",
      "L-BFGS iteration loss: Ntot = 104940339195.389, Nqll = 495117533877.159\n",
      "L-BFGS iteration loss: Ntot = 104940483164.264, Nqll = 495115386260.172\n",
      "L-BFGS iteration loss: Ntot = 104940628004.277, Nqll = 495113253770.224\n",
      "L-BFGS iteration loss: Ntot = 104940773717.848, Nqll = 495111136392.504\n",
      "L-BFGS iteration loss: Ntot = 104940920306.602, Nqll = 495109034106.138\n",
      "L-BFGS iteration loss: Ntot = 104941067773.351, Nqll = 495106946908.113\n",
      "L-BFGS iteration loss: Ntot = 104941216119.966, Nqll = 495104874774.278\n",
      "L-BFGS iteration loss: Ntot = 104941365349.345, Nqll = 495102817704.991\n",
      "L-BFGS iteration loss: Ntot = 104941515461.421, Nqll = 495100775649.126\n",
      "L-BFGS iteration loss: Ntot = 104941666460.606, Nqll = 495098748624.232\n",
      "L-BFGS iteration loss: Ntot = 104941818348.774, Nqll = 495096736609.670\n",
      "L-BFGS iteration loss: Ntot = 104941971127.171, Nqll = 495094739578.014\n",
      "L-BFGS iteration loss: Ntot = 104942124799.093, Nqll = 495092757526.975\n",
      "L-BFGS iteration loss: Ntot = 104942279367.044, Nqll = 495090790445.687\n",
      "L-BFGS iteration loss: Ntot = 104942434832.277, Nqll = 495088838306.317\n",
      "L-BFGS iteration loss: Ntot = 104942591198.562, Nqll = 495086901113.200\n",
      "L-BFGS iteration loss: Ntot = 104942748466.874, Nqll = 495084978835.503\n",
      "L-BFGS iteration loss: Ntot = 104942906640.178, Nqll = 495083071461.744\n",
      "L-BFGS iteration loss: Ntot = 104943065721.470, Nqll = 495081178990.018\n",
      "L-BFGS iteration loss: Ntot = 104943225712.343, Nqll = 495079301396.467\n",
      "L-BFGS iteration loss: Ntot = 104943386616.231, Nqll = 495077438676.941\n",
      "L-BFGS iteration loss: Ntot = 104943548435.542, Nqll = 495075590822.378\n",
      "L-BFGS iteration loss: Ntot = 104943711171.749, Nqll = 495073757798.757\n",
      "L-BFGS iteration loss: Ntot = 104943874828.949, Nqll = 495071939620.119\n",
      "L-BFGS iteration loss: Ntot = 104944039408.817, Nqll = 495070136260.797\n",
      "L-BFGS iteration loss: Ntot = 104944204915.058, Nqll = 495068347723.519\n",
      "L-BFGS iteration loss: Ntot = 104944371348.980, Nqll = 495066573978.784\n",
      "L-BFGS iteration loss: Ntot = 104944538714.009, Nqll = 495064815024.685\n",
      "L-BFGS iteration loss: Ntot = 104944707012.750, Nqll = 495063070846.665\n",
      "L-BFGS iteration loss: Ntot = 104944876248.235, Nqll = 495061341441.581\n",
      "L-BFGS iteration loss: Ntot = 104945046422.488, Nqll = 495059626783.014\n",
      "L-BFGS iteration loss: Ntot = 104945217539.788, Nqll = 495057926884.340\n",
      "L-BFGS iteration loss: Ntot = 104945389602.732, Nqll = 495056241738.155\n",
      "L-BFGS iteration loss: Ntot = 104945562612.503, Nqll = 495054571301.304\n",
      "L-BFGS iteration loss: Ntot = 104945736574.216, Nqll = 495052915601.944\n",
      "L-BFGS iteration loss: Ntot = 104945911489.123, Nqll = 495051274602.994\n",
      "L-BFGS iteration loss: Ntot = 104946087361.849, Nqll = 495049648321.856\n",
      "L-BFGS iteration loss: Ntot = 104946264193.552, Nqll = 495048036723.153\n",
      "L-BFGS iteration loss: Ntot = 104946441989.478, Nqll = 495046439830.821\n",
      "L-BFGS iteration loss: Ntot = 104946620751.148, Nqll = 495044857614.458\n",
      "L-BFGS iteration loss: Ntot = 104946800481.566, Nqll = 495043290067.932\n",
      "L-BFGS iteration loss: Ntot = 104946981184.571, Nqll = 495041737186.620\n",
      "L-BFGS iteration loss: Ntot = 104947162863.785, Nqll = 495040198977.331\n",
      "L-BFGS iteration loss: Ntot = 104947345521.030, Nqll = 495038675408.712\n",
      "L-BFGS iteration loss: Ntot = 104947529161.090, Nqll = 495037166501.864\n",
      "L-BFGS iteration loss: Ntot = 104947713787.115, Nqll = 495035672244.903\n",
      "L-BFGS iteration loss: Ntot = 104947899400.899, Nqll = 495034192614.285\n",
      "L-BFGS iteration loss: Ntot = 104948086007.314, Nqll = 495032727622.961\n",
      "L-BFGS iteration loss: Ntot = 104948273608.899, Nqll = 495031277257.105\n",
      "L-BFGS iteration loss: Ntot = 104948462209.608, Nqll = 495029841518.197\n",
      "L-BFGS iteration loss: Ntot = 104948651812.645, Nqll = 495028420397.908\n",
      "L-BFGS iteration loss: Ntot = 104948842421.944, Nqll = 495027013899.507\n",
      "L-BFGS iteration loss: Ntot = 104949034040.676, Nqll = 495025622016.105\n",
      "L-BFGS iteration loss: Ntot = 104949226671.995, Nqll = 495024244737.013\n",
      "L-BFGS iteration loss: Ntot = 104949420320.617, Nqll = 495022882077.857\n",
      "L-BFGS iteration loss: Ntot = 104949614988.719, Nqll = 495021534010.900\n",
      "L-BFGS iteration loss: Ntot = 104949810681.432, Nqll = 495020200558.249\n",
      "L-BFGS iteration loss: Ntot = 104950007401.104, Nqll = 495018881697.728\n",
      "L-BFGS iteration loss: Ntot = 104950205152.675, Nqll = 495017577444.362\n",
      "L-BFGS iteration loss: Ntot = 104950403939.811, Nqll = 495016287797.496\n",
      "L-BFGS iteration loss: Ntot = 104950603765.555, Nqll = 495015012747.181\n",
      "L-BFGS iteration loss: Ntot = 104950804634.071, Nqll = 495013752292.834\n",
      "L-BFGS iteration loss: Ntot = 104951006550.120, Nqll = 495012506451.137\n",
      "L-BFGS iteration loss: Ntot = 104951209515.875, Nqll = 495011275193.883\n",
      "L-BFGS iteration loss: Ntot = 104951413537.047, Nqll = 495010058549.813\n",
      "L-BFGS iteration loss: Ntot = 104951618616.131, Nqll = 495008856496.835\n",
      "L-BFGS iteration loss: Ntot = 104951824758.358, Nqll = 495007669050.127\n",
      "L-BFGS iteration loss: Ntot = 104952031968.605, Nqll = 495006496229.179\n",
      "L-BFGS iteration loss: Ntot = 104952240248.034, Nqll = 495005337992.699\n",
      "L-BFGS iteration loss: Ntot = 104952449603.931, Nqll = 495004194385.165\n",
      "L-BFGS iteration loss: Ntot = 104952660038.402, Nqll = 495003065379.576\n",
      "L-BFGS iteration loss: Ntot = 104952871557.449, Nqll = 495001951008.894\n",
      "L-BFGS iteration loss: Ntot = 104953084163.540, Nqll = 495000851246.444\n",
      "L-BFGS iteration loss: Ntot = 104953297862.417, Nqll = 494999766121.786\n",
      "L-BFGS iteration loss: Ntot = 104953512657.901, Nqll = 494998695628.748\n",
      "L-BFGS iteration loss: Ntot = 104953728553.365, Nqll = 494997639752.975\n",
      "L-BFGS iteration loss: Ntot = 104953945555.169, Nqll = 494996598530.802\n",
      "L-BFGS iteration loss: Ntot = 104954163667.057, Nqll = 494995571960.215\n",
      "L-BFGS iteration loss: Ntot = 104954382893.342, Nqll = 494994560041.510\n",
      "L-BFGS iteration loss: Ntot = 104954603239.114, Nqll = 494993562789.081\n",
      "L-BFGS iteration loss: Ntot = 104954824708.516, Nqll = 494992580206.481\n",
      "L-BFGS iteration loss: Ntot = 104955047305.697, Nqll = 494991612287.262\n",
      "L-BFGS iteration loss: Ntot = 104955271036.809, Nqll = 494990659065.585\n",
      "L-BFGS iteration loss: Ntot = 104955495904.852, Nqll = 494989720520.985\n",
      "L-BFGS iteration loss: Ntot = 104955721916.408, Nqll = 494988796690.068\n",
      "L-BFGS iteration loss: Ntot = 104955949075.016, Nqll = 494987887561.401\n",
      "L-BFGS iteration loss: Ntot = 104956177385.997, Nqll = 494986993151.279\n",
      "L-BFGS iteration loss: Ntot = 104956406854.604, Nqll = 494986113474.175\n",
      "L-BFGS iteration loss: Ntot = 104956637485.644, Nqll = 494985248540.490\n",
      "L-BFGS iteration loss: Ntot = 104956869284.062, Nqll = 494984398358.517\n",
      "L-BFGS iteration loss: Ntot = 104957102254.522, Nqll = 494983562932.043\n",
      "L-BFGS iteration loss: Ntot = 104957336402.787, Nqll = 494982742283.304\n",
      "L-BFGS iteration loss: Ntot = 104957571733.731, Nqll = 494981936419.742\n",
      "L-BFGS iteration loss: Ntot = 104957808252.991, Nqll = 494981145361.716\n",
      "L-BFGS iteration loss: Ntot = 104958045964.645, Nqll = 494980369107.026\n",
      "L-BFGS iteration loss: Ntot = 104958284875.288, Nqll = 494979607678.452\n",
      "L-BFGS iteration loss: Ntot = 104958524989.637, Nqll = 494978861089.013\n",
      "L-BFGS iteration loss: Ntot = 104958766314.314, Nqll = 494978129371.742\n",
      "L-BFGS iteration loss: Ntot = 104959008852.246, Nqll = 494977412500.497\n",
      "L-BFGS iteration loss: Ntot = 104959252611.398, Nqll = 494976710525.668\n",
      "L-BFGS iteration loss: Ntot = 104959497596.071, Nqll = 494976023448.915\n",
      "L-BFGS iteration loss: Ntot = 104959743812.049, Nqll = 494975351285.861\n",
      "L-BFGS iteration loss: Ntot = 104959991265.486, Nqll = 494974694061.950\n",
      "L-BFGS iteration loss: Ntot = 104960239961.446, Nqll = 494974051784.541\n",
      "L-BFGS iteration loss: Ntot = 104960489906.058, Nqll = 494973424475.979\n",
      "L-BFGS iteration loss: Ntot = 104960741104.894, Nqll = 494972812150.477\n",
      "L-BFGS iteration loss: Ntot = 104960993564.315, Nqll = 494972214834.765\n",
      "L-BFGS iteration loss: Ntot = 104961247290.172, Nqll = 494971632546.459\n",
      "L-BFGS iteration loss: Ntot = 104961502287.575, Nqll = 494971065296.301\n",
      "L-BFGS iteration loss: Ntot = 104961758563.370, Nqll = 494970513108.807\n",
      "L-BFGS iteration loss: Ntot = 104962016123.792, Nqll = 494969976011.531\n",
      "L-BFGS iteration loss: Ntot = 104962274974.834, Nqll = 494969454024.164\n",
      "L-BFGS iteration loss: Ntot = 104962535122.296, Nqll = 494968947161.529\n",
      "L-BFGS iteration loss: Ntot = 104962796572.080, Nqll = 494968455438.803\n",
      "L-BFGS iteration loss: Ntot = 104963059332.038, Nqll = 494967978901.921\n",
      "L-BFGS iteration loss: Ntot = 104963323407.395, Nqll = 494967517558.159\n",
      "L-BFGS iteration loss: Ntot = 104963588804.341, Nqll = 494967071428.576\n",
      "L-BFGS iteration loss: Ntot = 104963855530.171, Nqll = 494966640548.278\n",
      "L-BFGS iteration loss: Ntot = 104964123590.612, Nqll = 494966224927.623\n",
      "L-BFGS iteration loss: Ntot = 104964392993.713, Nqll = 494965824617.318\n",
      "L-BFGS iteration loss: Ntot = 104964663743.674, Nqll = 494965439603.324\n",
      "L-BFGS iteration loss: Ntot = 104964935849.554, Nqll = 494965069949.611\n",
      "L-BFGS iteration loss: Ntot = 104965209317.415, Nqll = 494964715667.613\n",
      "L-BFGS iteration loss: Ntot = 104965484153.733, Nqll = 494964376781.213\n",
      "L-BFGS iteration loss: Ntot = 104965760365.791, Nqll = 494964053326.840\n",
      "L-BFGS iteration loss: Ntot = 104966037960.724, Nqll = 494963745331.550\n",
      "L-BFGS iteration loss: Ntot = 104966316944.679, Nqll = 494963452816.489\n",
      "L-BFGS iteration loss: Ntot = 104966597325.902, Nqll = 494963175823.041\n",
      "L-BFGS iteration loss: Ntot = 104966879110.315, Nqll = 494962914363.980\n",
      "L-BFGS iteration loss: Ntot = 104967162305.933, Nqll = 494962668481.728\n",
      "L-BFGS iteration loss: Ntot = 104967446920.485, Nqll = 494962438213.596\n",
      "L-BFGS iteration loss: Ntot = 104967732960.634, Nqll = 494962223581.487\n",
      "L-BFGS iteration loss: Ntot = 104968020434.547, Nqll = 494962024631.468\n",
      "L-BFGS iteration loss: Ntot = 104968309348.010, Nqll = 494961841370.512\n",
      "L-BFGS iteration loss: Ntot = 104968599710.203, Nqll = 494961673851.921\n",
      "L-BFGS iteration loss: Ntot = 104968891528.561, Nqll = 494961522111.618\n",
      "L-BFGS iteration loss: Ntot = 104969184810.195, Nqll = 494961386174.760\n",
      "L-BFGS iteration loss: Ntot = 104969479562.908, Nqll = 494961266074.385\n",
      "L-BFGS iteration loss: Ntot = 104969775795.809, Nqll = 494961161868.113\n",
      "L-BFGS iteration loss: Ntot = 104970073514.319, Nqll = 494961073555.174\n",
      "L-BFGS iteration loss: Ntot = 104970372729.339, Nqll = 494961001213.589\n",
      "L-BFGS iteration loss: Ntot = 104970673446.702, Nqll = 494960944852.963\n",
      "L-BFGS iteration loss: Ntot = 104970975675.264, Nqll = 494960904516.975\n",
      "L-BFGS iteration loss: Ntot = 104971279423.638, Nqll = 494960880254.541\n",
      "L-BFGS iteration loss: Ntot = 104971584700.219, Nqll = 494960872106.238\n",
      "L-BFGS iteration loss: Ntot = 104971891511.843, Nqll = 494960880090.404\n",
      "L-BFGS iteration loss: Ntot = 104972199868.612, Nqll = 494960904271.948\n",
      "L-BFGS iteration loss: Ntot = 104972509778.314, Nqll = 494960944679.832\n",
      "L-BFGS iteration loss: Ntot = 104972821250.073, Nqll = 494961001369.355\n",
      "L-BFGS iteration loss: Ntot = 104973134291.160, Nqll = 494961074359.124\n",
      "L-BFGS iteration loss: Ntot = 104973448912.398, Nqll = 494961163727.495\n",
      "L-BFGS iteration loss: Ntot = 104973765120.409, Nqll = 494961269481.744\n",
      "L-BFGS iteration loss: Ntot = 104974082925.235, Nqll = 494961391684.570\n",
      "L-BFGS iteration loss: Ntot = 104974402336.231, Nqll = 494961530386.312\n",
      "L-BFGS iteration loss: Ntot = 104974723361.926, Nqll = 494961685628.037\n",
      "L-BFGS iteration loss: Ntot = 104975046011.306, Nqll = 494961857451.912\n",
      "L-BFGS iteration loss: Ntot = 104975370294.404, Nqll = 494962045921.788\n",
      "L-BFGS iteration loss: Ntot = 104975696219.117, Nqll = 494962251063.006\n",
      "L-BFGS iteration loss: Ntot = 104976023796.202, Nqll = 494962472940.732\n",
      "L-BFGS iteration loss: Ntot = 104976353034.611, Nqll = 494962711602.567\n",
      "L-BFGS iteration loss: Ntot = 104976683943.094, Nqll = 494962967082.918\n",
      "L-BFGS iteration loss: Ntot = 104977016533.176, Nqll = 494963239462.134\n",
      "L-BFGS iteration loss: Ntot = 104977350812.820, Nqll = 494963528764.668\n",
      "L-BFGS iteration loss: Ntot = 104977686793.328, Nqll = 494963835067.559\n",
      "L-BFGS iteration loss: Ntot = 104978024482.779, Nqll = 494964158395.456\n",
      "L-BFGS iteration loss: Ntot = 104978363892.667, Nqll = 494964498822.828\n",
      "L-BFGS iteration loss: Ntot = 104978705033.135, Nqll = 494964856406.834\n",
      "L-BFGS iteration loss: Ntot = 104979047913.417, Nqll = 494965231185.973\n",
      "L-BFGS iteration loss: Ntot = 104979392544.594, Nqll = 494965623229.375\n",
      "L-BFGS iteration loss: Ntot = 104979738937.142, Nqll = 494966032597.807\n",
      "L-BFGS iteration loss: Ntot = 104980087100.871, Nqll = 494966459338.773\n",
      "L-BFGS iteration loss: Ntot = 104980437046.615, Nqll = 494966903512.081\n",
      "L-BFGS iteration loss: Ntot = 104980788785.197, Nqll = 494967365185.582\n",
      "L-BFGS iteration loss: Ntot = 104981142327.446, Nqll = 494967844411.288\n",
      "L-BFGS iteration loss: Ntot = 104981497684.320, Nqll = 494968341258.052\n",
      "L-BFGS iteration loss: Ntot = 104981854865.870, Nqll = 494968855771.371\n",
      "L-BFGS iteration loss: Ntot = 104982213884.716, Nqll = 494969388038.458\n",
      "L-BFGS iteration loss: Ntot = 104982574750.253, Nqll = 494969938094.431\n",
      "L-BFGS iteration loss: Ntot = 104982937475.432, Nqll = 494970506028.375\n",
      "L-BFGS iteration loss: Ntot = 104983302070.807, Nqll = 494971091896.975\n",
      "L-BFGS iteration loss: Ntot = 104983668547.721, Nqll = 494971695755.889\n",
      "L-BFGS iteration loss: Ntot = 104984036918.586, Nqll = 494972317694.448\n",
      "L-BFGS iteration loss: Ntot = 104984407193.574, Nqll = 494972957749.606\n",
      "L-BFGS iteration loss: Ntot = 104984779386.378, Nqll = 494973616021.120\n",
      "L-BFGS iteration loss: Ntot = 104985153507.882, Nqll = 494974292562.323\n",
      "L-BFGS iteration loss: Ntot = 104985529569.961, Nqll = 494974987440.263\n",
      "L-BFGS iteration loss: Ntot = 104985907585.281, Nqll = 494975700737.390\n",
      "L-BFGS iteration loss: Ntot = 104986287565.730, Nqll = 494976432515.046\n",
      "L-BFGS iteration loss: Ntot = 104986669523.443, Nqll = 494977182844.194\n",
      "L-BFGS iteration loss: Ntot = 104987053472.497, Nqll = 494977951825.413\n",
      "L-BFGS iteration loss: Ntot = 104987439423.183, Nqll = 494978739494.683\n",
      "L-BFGS iteration loss: Ntot = 104987827389.968, Nqll = 494979545957.517\n",
      "L-BFGS iteration loss: Ntot = 104988217384.916, Nqll = 494980371276.607\n",
      "L-BFGS iteration loss: Ntot = 104988609421.146, Nqll = 494981215534.975\n",
      "L-BFGS iteration loss: Ntot = 104989003512.030, Nqll = 494982078807.761\n",
      "L-BFGS iteration loss: Ntot = 104989399670.241, Nqll = 494982961175.214\n",
      "L-BFGS iteration loss: Ntot = 104989797909.157, Nqll = 494983862715.715\n",
      "L-BFGS iteration loss: Ntot = 104990198242.991, Nqll = 494984783520.091\n",
      "L-BFGS iteration loss: Ntot = 104990600684.713, Nqll = 494985723660.678\n",
      "L-BFGS iteration loss: Ntot = 104991005247.216, Nqll = 494986683211.899\n",
      "L-BFGS iteration loss: Ntot = 104991411946.654, Nqll = 494987662294.239\n",
      "L-BFGS iteration loss: Ntot = 104991820795.068, Nqll = 494988660959.058\n",
      "L-BFGS iteration loss: Ntot = 104992231806.622, Nqll = 494989679296.123\n",
      "L-BFGS iteration loss: Ntot = 104992644996.893, Nqll = 494990717410.625\n",
      "L-BFGS iteration loss: Ntot = 104993060379.279, Nqll = 494991775383.095\n",
      "L-BFGS iteration loss: Ntot = 104993477967.954, Nqll = 494992853293.296\n",
      "L-BFGS iteration loss: Ntot = 104993897778.116, Nqll = 494993951235.858\n",
      "L-BFGS iteration loss: Ntot = 104994319824.530, Nqll = 494995069309.578\n",
      "L-BFGS iteration loss: Ntot = 104994744123.018, Nqll = 494996207617.022\n",
      "L-BFGS iteration loss: Ntot = 104995170686.367, Nqll = 494997366221.862\n",
      "L-BFGS iteration loss: Ntot = 104995599532.551, Nqll = 494998545252.918\n",
      "L-BFGS iteration loss: Ntot = 104996030674.455, Nqll = 494999744776.687\n",
      "L-BFGS iteration loss: Ntot = 104996464129.002, Nqll = 495000964907.266\n",
      "L-BFGS iteration loss: Ntot = 104996899911.508, Nqll = 495002205738.287\n",
      "L-BFGS iteration loss: Ntot = 104997338038.312, Nqll = 495003467378.523\n",
      "L-BFGS iteration loss: Ntot = 104997778524.175, Nqll = 495004749909.787\n",
      "L-BFGS iteration loss: Ntot = 104998221386.797, Nqll = 495006053457.416\n",
      "L-BFGS iteration loss: Ntot = 104998666641.108, Nqll = 495007378106.598\n",
      "L-BFGS iteration loss: Ntot = 104999114304.175, Nqll = 495008723967.797\n",
      "L-BFGS iteration loss: Ntot = 104999564392.787, Nqll = 495010091152.605\n",
      "L-BFGS iteration loss: Ntot = 105000016922.381, Nqll = 495011479749.143\n",
      "L-BFGS iteration loss: Ntot = 105000471911.849, Nqll = 495012889889.820\n",
      "L-BFGS iteration loss: Ntot = 105000929376.840, Nqll = 495014321664.467\n",
      "L-BFGS iteration loss: Ntot = 105001389335.196, Nqll = 495015775199.062\n",
      "L-BFGS iteration loss: Ntot = 105001851804.243, Nqll = 495017250594.371\n",
      "L-BFGS iteration loss: Ntot = 105002316801.712, Nqll = 495018747973.237\n",
      "L-BFGS iteration loss: Ntot = 105002784344.393, Nqll = 495020267431.367\n",
      "L-BFGS iteration loss: Ntot = 105003254451.564, Nqll = 495021809104.770\n",
      "L-BFGS iteration loss: Ntot = 105003727139.789, Nqll = 495023373088.004\n",
      "L-BFGS iteration loss: Ntot = 105004202429.517, Nqll = 495024959533.793\n",
      "L-BFGS iteration loss: Ntot = 105004680337.645, Nqll = 495026568533.784\n",
      "L-BFGS iteration loss: Ntot = 105005160882.783, Nqll = 495028200215.376\n",
      "L-BFGS iteration loss: Ntot = 105005644084.091, Nqll = 495029854700.512\n",
      "L-BFGS iteration loss: Ntot = 105006129960.785, Nqll = 495031532119.011\n",
      "L-BFGS iteration loss: Ntot = 105006618531.332, Nqll = 495033232582.269\n",
      "L-BFGS iteration loss: Ntot = 105007109817.161, Nqll = 495034956248.876\n",
      "L-BFGS iteration loss: Ntot = 105007603834.687, Nqll = 495036703203.280\n",
      "L-BFGS iteration loss: Ntot = 105008100606.605, Nqll = 495038473611.203\n",
      "L-BFGS iteration loss: Ntot = 105008600150.843, Nqll = 495040267584.012\n",
      "L-BFGS iteration loss: Ntot = 105009102487.997, Nqll = 495042085251.723\n",
      "L-BFGS iteration loss: Ntot = 105009607639.965, Nqll = 495043926772.487\n",
      "L-BFGS iteration loss: Ntot = 105010115624.952, Nqll = 495045792247.629\n",
      "L-BFGS iteration loss: Ntot = 105010626465.668, Nqll = 495047681841.862\n",
      "L-BFGS iteration loss: Ntot = 105011140182.302, Nqll = 495049595687.251\n",
      "L-BFGS iteration loss: Ntot = 105011656794.903, Nqll = 495051533902.771\n",
      "L-BFGS iteration loss: Ntot = 105012176327.690, Nqll = 495053496668.641\n",
      "L-BFGS iteration loss: Ntot = 105012698799.744, Nqll = 495055484098.228\n",
      "L-BFGS iteration loss: Ntot = 105013224233.947, Nqll = 495057496345.260\n",
      "L-BFGS iteration loss: Ntot = 105013752652.100, Nqll = 495059533557.518\n",
      "L-BFGS iteration loss: Ntot = 105014284076.752, Nqll = 495061595884.947\n",
      "L-BFGS iteration loss: Ntot = 105014818529.734, Nqll = 495063683467.004\n",
      "L-BFGS iteration loss: Ntot = 105015356035.165, Nqll = 495065796477.634\n",
      "L-BFGS iteration loss: Ntot = 105015896613.816, Nqll = 495067935039.057\n",
      "L-BFGS iteration loss: Ntot = 105016440290.743, Nqll = 495070099326.782\n",
      "L-BFGS iteration loss: Ntot = 105016987088.488, Nqll = 495072289492.536\n",
      "L-BFGS iteration loss: Ntot = 105017537031.558, Nqll = 495074505703.816\n",
      "L-BFGS iteration loss: Ntot = 105018090142.279, Nqll = 495076748096.994\n",
      "L-BFGS iteration loss: Ntot = 105018646447.024, Nqll = 495079016869.050\n",
      "L-BFGS iteration loss: Ntot = 105019205968.074, Nqll = 495081312150.666\n",
      "L-BFGS iteration loss: Ntot = 105019768730.631, Nqll = 495083634118.589\n",
      "L-BFGS iteration loss: Ntot = 105020334761.303, Nqll = 495085982962.709\n",
      "L-BFGS iteration loss: Ntot = 105020904082.584, Nqll = 495088358816.514\n",
      "L-BFGS iteration loss: Ntot = 105021476721.128, Nqll = 495090761866.449\n",
      "L-BFGS iteration loss: Ntot = 105022052702.957, Nqll = 495093192291.617\n",
      "L-BFGS iteration loss: Ntot = 105022632053.312, Nqll = 495095650260.851\n",
      "L-BFGS iteration loss: Ntot = 105023214798.686, Nqll = 495098135952.268\n",
      "L-BFGS iteration loss: Ntot = 105023800965.825, Nqll = 495100649549.856\n",
      "L-BFGS iteration loss: Ntot = 105024390580.949, Nqll = 495103191227.050\n",
      "L-BFGS iteration loss: Ntot = 105024983670.851, Nqll = 495105761168.277\n",
      "L-BFGS iteration loss: Ntot = 105025580263.457, Nqll = 495108359557.424\n",
      "L-BFGS iteration loss: Ntot = 105026180386.372, Nqll = 495110986591.402\n",
      "L-BFGS iteration loss: Ntot = 105026784067.287, Nqll = 495113642455.349\n",
      "L-BFGS iteration loss: Ntot = 105027391333.723, Nqll = 495116327328.184\n",
      "L-BFGS iteration loss: Ntot = 105028002215.244, Nqll = 495119041424.252\n",
      "L-BFGS iteration loss: Ntot = 105028616739.465, Nqll = 495121784921.161\n",
      "L-BFGS iteration loss: Ntot = 105029234936.408, Nqll = 495124558029.279\n",
      "L-BFGS iteration loss: Ntot = 105029856833.843, Nqll = 495127360930.023\n",
      "L-BFGS iteration loss: Ntot = 105030482463.388, Nqll = 495130193852.348\n",
      "L-BFGS iteration loss: Ntot = 105031111854.060, Nqll = 495133056983.186\n",
      "L-BFGS iteration loss: Ntot = 105031745036.503, Nqll = 495135950541.613\n",
      "L-BFGS iteration loss: Ntot = 105032382040.874, Nqll = 495138874727.599\n",
      "L-BFGS iteration loss: Ntot = 105033022897.924, Nqll = 495141829751.247\n",
      "L-BFGS iteration loss: Ntot = 105033667639.122, Nqll = 495144815830.987\n",
      "L-BFGS iteration loss: Ntot = 105034316296.323, Nqll = 495147833181.971\n",
      "L-BFGS iteration loss: Ntot = 105034968901.158, Nqll = 495150882027.697\n",
      "L-BFGS iteration loss: Ntot = 105035625485.543, Nqll = 495153962578.238\n",
      "L-BFGS iteration loss: Ntot = 105036286082.518, Nqll = 495157075066.961\n",
      "L-BFGS iteration loss: Ntot = 105036950724.945, Nqll = 495160219713.070\n",
      "L-BFGS iteration loss: Ntot = 105037619446.508, Nqll = 495163396762.279\n",
      "L-BFGS iteration loss: Ntot = 105038292279.928, Nqll = 495166606424.542\n",
      "L-BFGS iteration loss: Ntot = 105038969259.164, Nqll = 495169848937.526\n",
      "L-BFGS iteration loss: Ntot = 105039650419.447, Nqll = 495173124546.859\n",
      "L-BFGS iteration loss: Ntot = 105040335795.132, Nqll = 495176433487.705\n",
      "L-BFGS iteration loss: Ntot = 105041025420.973, Nqll = 495179775999.389\n",
      "L-BFGS iteration loss: Ntot = 105041719332.911, Nqll = 495183152333.119\n",
      "L-BFGS iteration loss: Ntot = 105042417566.194, Nqll = 495186562723.522\n",
      "L-BFGS iteration loss: Ntot = 105043120157.745, Nqll = 495190007435.098\n",
      "L-BFGS iteration loss: Ntot = 105043827144.354, Nqll = 495193486722.506\n",
      "L-BFGS iteration loss: Ntot = 105044538561.636, Nqll = 495197000821.893\n",
      "L-BFGS iteration loss: Ntot = 105045254448.187, Nqll = 495200550005.119\n",
      "L-BFGS iteration loss: Ntot = 105045974841.741, Nqll = 495204134534.921\n",
      "L-BFGS iteration loss: Ntot = 105046699780.027, Nqll = 495207754671.002\n",
      "L-BFGS iteration loss: Ntot = 105047429302.681, Nqll = 495211410693.297\n",
      "L-BFGS iteration loss: Ntot = 105048163447.782, Nqll = 495215102858.421\n",
      "L-BFGS iteration loss: Ntot = 105048902255.089, Nqll = 495218831441.952\n",
      "L-BFGS iteration loss: Ntot = 105049645764.529, Nqll = 495222596726.536\n",
      "L-BFGS iteration loss: Ntot = 105050394015.812, Nqll = 495226398974.892\n",
      "L-BFGS iteration loss: Ntot = 105051147051.267, Nqll = 495230238498.793\n",
      "L-BFGS iteration loss: Ntot = 105051904910.287, Nqll = 495234115552.029\n",
      "L-BFGS iteration loss: Ntot = 105052667636.751, Nqll = 495238030459.029\n",
      "L-BFGS iteration loss: Ntot = 105053435270.967, Nqll = 495241983486.481\n",
      "L-BFGS iteration loss: Ntot = 105054207856.588, Nqll = 495245974946.232\n",
      "L-BFGS iteration loss: Ntot = 105054985436.139, Nqll = 495250005127.784\n",
      "L-BFGS iteration loss: Ntot = 105055768053.160, Nqll = 495254074333.252\n",
      "L-BFGS iteration loss: Ntot = 105056555751.299, Nqll = 495258182866.969\n",
      "L-BFGS iteration loss: Ntot = 105057348576.908, Nqll = 495262331059.128\n",
      "L-BFGS iteration loss: Ntot = 105058146572.527, Nqll = 495266519194.745\n",
      "L-BFGS iteration loss: Ntot = 105058949785.151, Nqll = 495270747606.510\n",
      "L-BFGS iteration loss: Ntot = 105059758260.793, Nqll = 495275016615.956\n",
      "L-BFGS iteration loss: Ntot = 105060572044.869, Nqll = 495279326529.805\n",
      "L-BFGS iteration loss: Ntot = 105061391186.134, Nqll = 495283677704.170\n",
      "L-BFGS iteration loss: Ntot = 105062215730.569, Nqll = 495288070445.633\n",
      "L-BFGS iteration loss: Ntot = 105063045727.606, Nqll = 495292505106.254\n",
      "L-BFGS iteration loss: Ntot = 105063881224.433, Nqll = 495296982008.256\n",
      "L-BFGS iteration loss: Ntot = 105064722272.079, Nqll = 495301501521.076\n",
      "L-BFGS iteration loss: Ntot = 105065568918.583, Nqll = 495306063964.187\n",
      "L-BFGS iteration loss: Ntot = 105066421215.388, Nqll = 495310669707.712\n",
      "L-BFGS iteration loss: Ntot = 105067279212.501, Nqll = 495315319096.583\n",
      "L-BFGS iteration loss: Ntot = 105068142961.717, Nqll = 495320012491.578\n",
      "L-BFGS iteration loss: Ntot = 105069012514.733, Nqll = 495324750250.118\n",
      "L-BFGS iteration loss: Ntot = 105069887924.571, Nqll = 495329532755.916\n",
      "L-BFGS iteration loss: Ntot = 105070769243.587, Nqll = 495334360352.216\n",
      "L-BFGS iteration loss: Ntot = 105071656527.125, Nqll = 495339233444.837\n",
      "L-BFGS iteration loss: Ntot = 105072549829.241, Nqll = 495344152413.528\n",
      "L-BFGS iteration loss: Ntot = 105073449203.812, Nqll = 495349117621.593\n",
      "L-BFGS iteration loss: Ntot = 105074354706.826, Nqll = 495354129465.493\n",
      "L-BFGS iteration loss: Ntot = 105075266394.843, Nqll = 495359188344.052\n",
      "L-BFGS iteration loss: Ntot = 105076184324.999, Nqll = 495364294649.699\n",
      "L-BFGS iteration loss: Ntot = 105077108553.879, Nqll = 495369448783.594\n",
      "L-BFGS iteration loss: Ntot = 105078039141.269, Nqll = 495374651164.543\n",
      "L-BFGS iteration loss: Ntot = 105078976144.424, Nqll = 495379902191.079\n",
      "L-BFGS iteration loss: Ntot = 105079919624.335, Nqll = 495385202293.530\n",
      "L-BFGS iteration loss: Ntot = 105080869640.249, Nqll = 495390551879.744\n",
      "L-BFGS iteration loss: Ntot = 105081826253.445, Nqll = 495395951384.120\n",
      "L-BFGS iteration loss: Ntot = 105082789524.948, Nqll = 495401401231.840\n",
      "L-BFGS iteration loss: Ntot = 105083759518.545, Nqll = 495406901869.288\n",
      "L-BFGS iteration loss: Ntot = 105084736295.740, Nqll = 495412453726.028\n",
      "L-BFGS iteration loss: Ntot = 105085719920.974, Nqll = 495418057257.616\n",
      "L-BFGS iteration loss: Ntot = 105086710459.346, Nqll = 495423712918.526\n",
      "L-BFGS iteration loss: Ntot = 105087707974.869, Nqll = 495429421154.354\n",
      "L-BFGS iteration loss: Ntot = 105088712534.169, Nqll = 495435182428.374\n",
      "L-BFGS iteration loss: Ntot = 105089724204.307, Nqll = 495440997220.625\n",
      "L-BFGS iteration loss: Ntot = 105090743052.541, Nqll = 495446865995.886\n",
      "L-BFGS iteration loss: Ntot = 105091769147.438, Nqll = 495452789237.188\n",
      "L-BFGS iteration loss: Ntot = 105092802557.617, Nqll = 495458767423.810\n",
      "L-BFGS iteration loss: Ntot = 105093843353.335, Nqll = 495464801043.445\n",
      "L-BFGS iteration loss: Ntot = 105094891606.287, Nqll = 495470890607.039\n",
      "L-BFGS iteration loss: Ntot = 105095947386.154, Nqll = 495477036599.830\n",
      "L-BFGS iteration loss: Ntot = 105097010766.399, Nqll = 495483239530.045\n",
      "L-BFGS iteration loss: Ntot = 105098081819.749, Nqll = 495489499913.762\n",
      "L-BFGS iteration loss: Ntot = 105099160621.617, Nqll = 495495818284.572\n",
      "L-BFGS iteration loss: Ntot = 105100247245.349, Nqll = 495502195139.288\n",
      "L-BFGS iteration loss: Ntot = 105101341768.804, Nqll = 495508631052.382\n",
      "L-BFGS iteration loss: Ntot = 105102444265.904, Nqll = 495515126507.422\n",
      "L-BFGS iteration loss: Ntot = 105103554817.180, Nqll = 495521682091.444\n",
      "L-BFGS iteration loss: Ntot = 105104673499.766, Nqll = 495528298338.388\n",
      "L-BFGS iteration loss: Ntot = 105105800393.453, Nqll = 495534975811.565\n",
      "L-BFGS iteration loss: Ntot = 105106935578.061, Nqll = 495541715062.942\n",
      "L-BFGS iteration loss: Ntot = 105108079135.998, Nqll = 495548516677.678\n",
      "L-BFGS iteration loss: Ntot = 105109231149.316, Nqll = 495555381225.976\n",
      "L-BFGS iteration loss: Ntot = 105110391701.480, Nqll = 495562309296.939\n",
      "L-BFGS iteration loss: Ntot = 105111560875.442, Nqll = 495569301464.576\n",
      "L-BFGS iteration loss: Ntot = 105112738758.164, Nqll = 495576358345.682\n",
      "L-BFGS iteration loss: Ntot = 105113925435.118, Nqll = 495583480531.213\n",
      "L-BFGS iteration loss: Ntot = 105115120994.183, Nqll = 495590668644.040\n",
      "L-BFGS iteration loss: Ntot = 105116325524.046, Nqll = 495597923310.585\n",
      "L-BFGS iteration loss: Ntot = 105117539113.180, Nqll = 495605245136.622\n",
      "L-BFGS iteration loss: Ntot = 105118761852.435, Nqll = 495612634766.537\n",
      "L-BFGS iteration loss: Ntot = 105119993833.990, Nqll = 495620092840.454\n",
      "L-BFGS iteration loss: Ntot = 105121235150.310, Nqll = 495627620020.316\n",
      "L-BFGS iteration loss: Ntot = 105122485895.260, Nqll = 495635216953.897\n",
      "L-BFGS iteration loss: Ntot = 105123746163.033, Nqll = 495642884297.961\n",
      "L-BFGS iteration loss: Ntot = 105125016050.420, Nqll = 495650622731.344\n",
      "L-BFGS iteration loss: Ntot = 105126295654.119, Nqll = 495658432936.285\n",
      "L-BFGS iteration loss: Ntot = 105127585073.306, Nqll = 495666315605.746\n",
      "L-BFGS iteration loss: Ntot = 105128884406.817, Nqll = 495674271430.959\n",
      "L-BFGS iteration loss: Ntot = 105130193756.822, Nqll = 495682301129.722\n",
      "L-BFGS iteration loss: Ntot = 105131513222.018, Nqll = 495690405376.783\n",
      "L-BFGS iteration loss: Ntot = 105132842910.460, Nqll = 495698584959.354\n",
      "L-BFGS iteration loss: Ntot = 105134182922.327, Nqll = 495706840550.931\n",
      "L-BFGS iteration loss: Ntot = 105135533365.134, Nqll = 495715172917.180\n",
      "L-BFGS iteration loss: Ntot = 105136894346.436, Nqll = 495723582809.145\n",
      "L-BFGS iteration loss: Ntot = 105138265972.887, Nqll = 495732070962.691\n",
      "L-BFGS iteration loss: Ntot = 105139648357.005, Nqll = 495740638185.632\n",
      "L-BFGS iteration loss: Ntot = 105141041606.632, Nqll = 495749285213.753\n",
      "L-BFGS iteration loss: Ntot = 105142445835.674, Nqll = 495758012857.106\n",
      "L-BFGS iteration loss: Ntot = 105143861157.271, Nqll = 495766821896.785\n",
      "L-BFGS iteration loss: Ntot = 105145287687.208, Nqll = 495775713145.394\n",
      "L-BFGS iteration loss: Ntot = 105146725541.500, Nqll = 495784687419.090\n",
      "L-BFGS iteration loss: Ntot = 105148174836.443, Nqll = 495793745517.938\n",
      "L-BFGS iteration loss: Ntot = 105149635693.452, Nqll = 495802888298.842\n",
      "L-BFGS iteration loss: Ntot = 105151108233.859, Nqll = 495812116615.811\n",
      "L-BFGS iteration loss: Ntot = 105152592577.958, Nqll = 495821431299.538\n",
      "L-BFGS iteration loss: Ntot = 105154088850.968, Nqll = 495830833231.105\n",
      "L-BFGS iteration loss: Ntot = 105155597176.557, Nqll = 495840323271.260\n",
      "L-BFGS iteration loss: Ntot = 105157117683.284, Nqll = 495849902317.866\n",
      "L-BFGS iteration loss: Ntot = 105158650497.736, Nqll = 495859571252.859\n",
      "L-BFGS iteration loss: Ntot = 105160195751.568, Nqll = 495869331000.669\n",
      "L-BFGS iteration loss: Ntot = 105161753575.320, Nqll = 495879182469.200\n",
      "L-BFGS iteration loss: Ntot = 105163324102.149, Nqll = 495889126584.295\n",
      "L-BFGS iteration loss: Ntot = 105164907467.181, Nqll = 495899164294.915\n",
      "L-BFGS iteration loss: Ntot = 105166503806.336, Nqll = 495909296548.014\n",
      "L-BFGS iteration loss: Ntot = 105168113258.041, Nqll = 495919524306.914\n",
      "L-BFGS iteration loss: Ntot = 105169735962.859, Nqll = 495929848552.232\n",
      "L-BFGS iteration loss: Ntot = 105171372060.574, Nqll = 495940270255.769\n",
      "L-BFGS iteration loss: Ntot = 105173021696.645, Nqll = 495950790439.859\n",
      "L-BFGS iteration loss: Ntot = 105174685014.328, Nqll = 495961410095.395\n",
      "L-BFGS iteration loss: Ntot = 105176362160.772, Nqll = 495972130247.479\n",
      "L-BFGS iteration loss: Ntot = 105178053285.993, Nqll = 495982951941.765\n",
      "L-BFGS iteration loss: Ntot = 105179758538.842, Nqll = 495993876215.741\n",
      "L-BFGS iteration loss: Ntot = 105181478073.364, Nqll = 496004904147.957\n",
      "L-BFGS iteration loss: Ntot = 105183212042.726, Nqll = 496016036798.065\n",
      "L-BFGS iteration loss: Ntot = 105184960602.982, Nqll = 496027275250.063\n",
      "L-BFGS iteration loss: Ntot = 105186723913.308, Nqll = 496038620618.959\n",
      "L-BFGS iteration loss: Ntot = 105188502132.254, Nqll = 496050073991.484\n",
      "L-BFGS iteration loss: Ntot = 105190295423.832, Nqll = 496061636532.031\n",
      "L-BFGS iteration loss: Ntot = 105192103951.492, Nqll = 496073309367.103\n",
      "L-BFGS iteration loss: Ntot = 105193927879.698, Nqll = 496085093624.668\n",
      "L-BFGS iteration loss: Ntot = 105195767379.928, Nqll = 496096990526.007\n",
      "L-BFGS iteration loss: Ntot = 105197622619.474, Nqll = 496109001208.618\n",
      "L-BFGS iteration loss: Ntot = 105199493771.272, Nqll = 496121126871.898\n",
      "L-BFGS iteration loss: Ntot = 105201381013.372, Nqll = 496133368779.877\n",
      "L-BFGS iteration loss: Ntot = 105203284517.287, Nqll = 496145728093.587\n",
      "L-BFGS iteration loss: Ntot = 105205204466.709, Nqll = 496158206106.667\n",
      "L-BFGS iteration loss: Ntot = 105207141040.482, Nqll = 496170804049.721\n",
      "L-BFGS iteration loss: Ntot = 105209094423.668, Nqll = 496183523216.304\n",
      "L-BFGS iteration loss: Ntot = 105211064799.414, Nqll = 496196364868.438\n",
      "L-BFGS iteration loss: Ntot = 105213052357.569, Nqll = 496209330315.577\n",
      "L-BFGS iteration loss: Ntot = 105215057290.631, Nqll = 496222420908.379\n",
      "L-BFGS iteration loss: Ntot = 105217079788.393, Nqll = 496235637954.350\n",
      "L-BFGS iteration loss: Ntot = 105219120047.579, Nqll = 496248982811.227\n",
      "L-BFGS iteration loss: Ntot = 105221178267.761, Nqll = 496262456874.166\n",
      "L-BFGS iteration loss: Ntot = 105223254645.804, Nqll = 496276061490.951\n",
      "L-BFGS iteration loss: Ntot = 105225349387.049, Nqll = 496289798091.967\n",
      "L-BFGS iteration loss: Ntot = 105227462695.900, Nqll = 496303668087.995\n",
      "L-BFGS iteration loss: Ntot = 105229594780.337, Nqll = 496317672915.381\n",
      "L-BFGS iteration loss: Ntot = 105231745853.111, Nqll = 496331814049.435\n",
      "L-BFGS iteration loss: Ntot = 105233916124.711, Nqll = 496346092943.723\n",
      "L-BFGS iteration loss: Ntot = 105236105813.654, Nqll = 496360511112.926\n",
      "L-BFGS iteration loss: Ntot = 105238315136.818, Nqll = 496375070051.607\n",
      "L-BFGS iteration loss: Ntot = 105240544316.806, Nqll = 496389771289.968\n",
      "L-BFGS iteration loss: Ntot = 105242793577.222, Nqll = 496404616382.585\n",
      "L-BFGS iteration loss: Ntot = 105245063146.324, Nqll = 496419606896.938\n",
      "L-BFGS iteration loss: Ntot = 105247353253.388, Nqll = 496434744418.540\n",
      "L-BFGS iteration loss: Ntot = 105249664132.190, Nqll = 496450030563.313\n",
      "L-BFGS iteration loss: Ntot = 105251996018.847, Nqll = 496465466951.256\n",
      "L-BFGS iteration loss: Ntot = 105254349151.322, Nqll = 496481055223.780\n",
      "L-BFGS iteration loss: Ntot = 105256723773.906, Nqll = 496496797072.705\n",
      "L-BFGS iteration loss: Ntot = 105259120129.460, Nqll = 496512694159.011\n",
      "L-BFGS iteration loss: Ntot = 105261538468.875, Nqll = 496528748224.977\n",
      "L-BFGS iteration loss: Ntot = 105263979040.896, Nqll = 496544960968.808\n",
      "L-BFGS iteration loss: Ntot = 105266442101.968, Nqll = 496561334162.949\n",
      "L-BFGS iteration loss: Ntot = 105268927908.255, Nqll = 496577869552.453\n",
      "L-BFGS iteration loss: Ntot = 105271436726.516, Nqll = 496594569011.496\n",
      "L-BFGS iteration loss: Ntot = 105273968815.366, Nqll = 496611434279.343\n",
      "L-BFGS iteration loss: Ntot = 105276524445.293, Nqll = 496628467225.080\n",
      "L-BFGS iteration loss: Ntot = 105279103888.353, Nqll = 496645669724.003\n",
      "L-BFGS iteration loss: Ntot = 105281707420.168, Nqll = 496663043657.995\n",
      "L-BFGS iteration loss: Ntot = 105284335318.763, Nqll = 496680590952.814\n",
      "L-BFGS iteration loss: Ntot = 105286987866.273, Nqll = 496698313531.304\n",
      "L-BFGS iteration loss: Ntot = 105289665347.505, Nqll = 496716213339.388\n",
      "L-BFGS iteration loss: Ntot = 105292368055.759, Nqll = 496734292408.011\n",
      "L-BFGS iteration loss: Ntot = 105295096281.157, Nqll = 496752552705.898\n",
      "L-BFGS iteration loss: Ntot = 105297850323.111, Nqll = 496770996300.945\n",
      "L-BFGS iteration loss: Ntot = 105300630481.251, Nqll = 496789625241.502\n",
      "L-BFGS iteration loss: Ntot = 105303437063.258, Nqll = 496808441630.615\n",
      "L-BFGS iteration loss: Ntot = 105306270375.377, Nqll = 496827447565.081\n",
      "L-BFGS iteration loss: Ntot = 105309130732.085, Nqll = 496846645194.141\n",
      "L-BFGS iteration loss: Ntot = 105312018450.036, Nqll = 496866036674.212\n",
      "L-BFGS iteration loss: Ntot = 105314933853.356, Nqll = 496885624245.068\n",
      "L-BFGS iteration loss: Ntot = 105317877265.618, Nqll = 496905410106.939\n",
      "L-BFGS iteration loss: Ntot = 105320849017.862, Nqll = 496925396522.876\n",
      "L-BFGS iteration loss: Ntot = 105323849442.982, Nqll = 496945585757.594\n",
      "L-BFGS iteration loss: Ntot = 105326878880.968, Nqll = 496965980136.878\n",
      "L-BFGS iteration loss: Ntot = 105329937674.186, Nqll = 496986581993.730\n",
      "L-BFGS iteration loss: Ntot = 105333026173.556, Nqll = 497007393729.797\n",
      "L-BFGS iteration loss: Ntot = 105336144730.286, Nqll = 497028417741.617\n",
      "L-BFGS iteration loss: Ntot = 105339293699.952, Nqll = 497049656441.513\n",
      "L-BFGS iteration loss: Ntot = 105342473446.980, Nqll = 497071112316.045\n",
      "L-BFGS iteration loss: Ntot = 105345684336.712, Nqll = 497092787852.973\n",
      "L-BFGS iteration loss: Ntot = 105348926743.878, Nqll = 497114685617.480\n",
      "L-BFGS iteration loss: Ntot = 105352201042.096, Nqll = 497136808123.832\n",
      "L-BFGS iteration loss: Ntot = 105355507616.177, Nqll = 497159158015.532\n",
      "L-BFGS iteration loss: Ntot = 105358846852.010, Nqll = 497181737898.872\n",
      "L-BFGS iteration loss: Ntot = 105362219143.853, Nqll = 497204550468.458\n",
      "L-BFGS iteration loss: Ntot = 105365624887.803, Nqll = 497227598406.592\n",
      "L-BFGS iteration loss: Ntot = 105369064488.755, Nqll = 497250884464.135\n",
      "L-BFGS iteration loss: Ntot = 105372538355.979, Nqll = 497274411425.156\n",
      "L-BFGS iteration loss: Ntot = 105376046902.624, Nqll = 497298182091.661\n",
      "L-BFGS iteration loss: Ntot = 105379590551.262, Nqll = 497322199334.078\n",
      "L-BFGS iteration loss: Ntot = 105383169724.917, Nqll = 497346466004.509\n",
      "L-BFGS iteration loss: Ntot = 105386784857.882, Nqll = 497370985064.282\n",
      "L-BFGS iteration loss: Ntot = 105390436389.881, Nqll = 497395759493.271\n",
      "L-BFGS iteration loss: Ntot = 105394124762.227, Nqll = 497420792261.600\n",
      "L-BFGS iteration loss: Ntot = 105397850428.489, Nqll = 497446086467.257\n",
      "L-BFGS iteration loss: Ntot = 105401613843.733, Nqll = 497471645173.403\n",
      "L-BFGS iteration loss: Ntot = 105405415471.774, Nqll = 497497471526.608\n",
      "L-BFGS iteration loss: Ntot = 105409255783.002, Nqll = 497523568699.368\n",
      "L-BFGS iteration loss: Ntot = 105413135254.745, Nqll = 497549939926.457\n",
      "L-BFGS iteration loss: Ntot = 105417054370.213, Nqll = 497576588472.036\n",
      "L-BFGS iteration loss: Ntot = 105421013619.383, Nqll = 497603517650.402\n",
      "L-BFGS iteration loss: Ntot = 105425013498.586, Nqll = 497630730796.374\n",
      "L-BFGS iteration loss: Ntot = 105429054517.690, Nqll = 497658231379.116\n",
      "L-BFGS iteration loss: Ntot = 105433137185.294, Nqll = 497686022815.916\n",
      "L-BFGS iteration loss: Ntot = 105437262020.896, Nqll = 497714108594.076\n",
      "L-BFGS iteration loss: Ntot = 105441429554.380, Nqll = 497742492322.938\n",
      "L-BFGS iteration loss: Ntot = 105445640317.846, Nqll = 497771177554.111\n",
      "L-BFGS iteration loss: Ntot = 105449894859.088, Nqll = 497800168016.648\n",
      "L-BFGS iteration loss: Ntot = 105454193725.562, Nqll = 497829467366.242\n",
      "L-BFGS iteration loss: Ntot = 105458537478.220, Nqll = 497859079400.931\n",
      "L-BFGS iteration loss: Ntot = 105462926683.758, Nqll = 497889007916.561\n",
      "L-BFGS iteration loss: Ntot = 105467361920.628, Nqll = 497919256819.276\n",
      "L-BFGS iteration loss: Ntot = 105471843773.833, Nqll = 497949830039.081\n",
      "L-BFGS iteration loss: Ntot = 105476372836.739, Nqll = 497980731553.840\n",
      "L-BFGS iteration loss: Ntot = 105480949716.073, Nqll = 498011965482.596\n",
      "L-BFGS iteration loss: Ntot = 105485575019.974, Nqll = 498043535871.334\n",
      "L-BFGS iteration loss: Ntot = 105490249372.923, Nqll = 498075446924.599\n",
      "L-BFGS iteration loss: Ntot = 105494973408.772, Nqll = 498107702906.674\n",
      "L-BFGS iteration loss: Ntot = 105499747766.355, Nqll = 498140308093.407\n",
      "L-BFGS iteration loss: Ntot = 105504573102.225, Nqll = 498173266916.742\n",
      "L-BFGS iteration loss: Ntot = 105509450074.449, Nqll = 498206583760.367\n",
      "L-BFGS iteration loss: Ntot = 105514379356.312, Nqll = 498240263152.815\n",
      "L-BFGS iteration loss: Ntot = 105519361636.807, Nqll = 498274309717.293\n",
      "L-BFGS iteration loss: Ntot = 105524397607.021, Nqll = 498308728084.161\n",
      "L-BFGS iteration loss: Ntot = 105529487972.445, Nqll = 498343522967.823\n",
      "L-BFGS iteration loss: Ntot = 105534633452.332, Nqll = 498378699191.960\n",
      "L-BFGS iteration loss: Ntot = 105539834780.946, Nqll = 498414261706.940\n",
      "L-BFGS iteration loss: Ntot = 105545092691.323, Nqll = 498450215359.990\n",
      "L-BFGS iteration loss: Ntot = 105550407942.227, Nqll = 498486565258.906\n",
      "L-BFGS iteration loss: Ntot = 105555781302.126, Nqll = 498523316554.394\n",
      "L-BFGS iteration loss: Ntot = 105561213548.614, Nqll = 498560474435.321\n",
      "L-BFGS iteration loss: Ntot = 105566705474.729, Nqll = 498598044205.895\n",
      "L-BFGS iteration loss: Ntot = 105572257885.720, Nqll = 498636031241.055\n",
      "L-BFGS iteration loss: Ntot = 105577871604.518, Nqll = 498674441045.227\n",
      "L-BFGS iteration loss: Ntot = 105583547465.595, Nqll = 498713279205.095\n",
      "L-BFGS iteration loss: Ntot = 105589286315.313, Nqll = 498752551361.974\n",
      "L-BFGS iteration loss: Ntot = 105595089018.836, Nqll = 498792263284.557\n",
      "L-BFGS iteration loss: Ntot = 105600956454.797, Nqll = 498832420851.916\n",
      "L-BFGS iteration loss: Ntot = 105606889518.397, Nqll = 498873030034.673\n",
      "L-BFGS iteration loss: Ntot = 105612889118.948, Nqll = 498914096888.805\n",
      "L-BFGS iteration loss: Ntot = 105618956185.550, Nqll = 498955627625.202\n",
      "L-BFGS iteration loss: Ntot = 105625091658.299, Nqll = 498997628508.474\n",
      "L-BFGS iteration loss: Ntot = 105631296501.973, Nqll = 499040105962.485\n",
      "L-BFGS iteration loss: Ntot = 105637571693.409, Nqll = 499083066530.354\n",
      "L-BFGS iteration loss: Ntot = 105643918224.201, Nqll = 499126516782.699\n",
      "L-BFGS iteration loss: Ntot = 105650337111.628, Nqll = 499170463510.448\n",
      "L-BFGS iteration loss: Ntot = 105656829383.686, Nqll = 499214913542.368\n",
      "L-BFGS iteration loss: Ntot = 105663396103.570, Nqll = 499259873992.986\n",
      "L-BFGS iteration loss: Ntot = 105670038338.355, Nqll = 499305351956.616\n",
      "L-BFGS iteration loss: Ntot = 105676757174.293, Nqll = 499351354638.403\n",
      "L-BFGS iteration loss: Ntot = 105683553730.061, Nqll = 499397889512.582\n",
      "L-BFGS iteration loss: Ntot = 105690429137.247, Nqll = 499444964092.688\n",
      "L-BFGS iteration loss: Ntot = 105697384553.300, Nqll = 499492586082.456\n",
      "L-BFGS iteration loss: Ntot = 105704421156.109, Nqll = 499540763338.151\n",
      "L-BFGS iteration loss: Ntot = 105711540138.986, Nqll = 499589503763.238\n",
      "L-BFGS iteration loss: Ntot = 105718742729.042, Nqll = 499638815504.044\n",
      "L-BFGS iteration loss: Ntot = 105726030178.083, Nqll = 499688706919.630\n",
      "L-BFGS iteration loss: Ntot = 105733403753.932, Nqll = 499739186425.873\n",
      "L-BFGS iteration loss: Ntot = 105740864751.716, Nqll = 499790262619.141\n",
      "L-BFGS iteration loss: Ntot = 105748414490.895, Nqll = 499841944253.749\n",
      "L-BFGS iteration loss: Ntot = 105756054323.338, Nqll = 499894240338.740\n",
      "L-BFGS iteration loss: Ntot = 105763785619.687, Nqll = 499947159946.274\n",
      "L-BFGS iteration loss: Ntot = 105771609784.712, Nqll = 500000712432.647\n",
      "L-BFGS iteration loss: Ntot = 105779528241.156, Nqll = 500054907203.991\n",
      "L-BFGS iteration loss: Ntot = 105787542455.415, Nqll = 500109754044.867\n",
      "L-BFGS iteration loss: Ntot = 105795653903.328, Nqll = 500165262704.068\n",
      "L-BFGS iteration loss: Ntot = 105803864106.770, Nqll = 500221443295.210\n",
      "L-BFGS iteration loss: Ntot = 105812174608.459, Nqll = 500278306053.811\n",
      "L-BFGS iteration loss: Ntot = 105820586989.074, Nqll = 500335861469.514\n",
      "L-BFGS iteration loss: Ntot = 105829102849.530, Nqll = 500394120134.169\n",
      "L-BFGS iteration loss: Ntot = 105837723839.837, Nqll = 500453093029.696\n",
      "L-BFGS iteration loss: Ntot = 105846451622.838, Nqll = 500512791137.292\n",
      "L-BFGS iteration loss: Ntot = 105855287907.051, Nqll = 500573225797.030\n",
      "L-BFGS iteration loss: Ntot = 105864234432.454, Nqll = 500634408545.512\n",
      "L-BFGS iteration loss: Ntot = 105873292975.184, Nqll = 500696351132.222\n",
      "L-BFGS iteration loss: Ntot = 105882465341.513, Nqll = 500759065530.739\n",
      "L-BFGS iteration loss: Ntot = 105891753383.741, Nqll = 500822564046.007\n",
      "L-BFGS iteration loss: Ntot = 105901158969.396, Nqll = 500886858964.706\n",
      "L-BFGS iteration loss: Ntot = 105910684027.858, Nqll = 500951963142.703\n",
      "L-BFGS iteration loss: Ntot = 105920330505.013, Nqll = 501017889393.789\n",
      "L-BFGS iteration loss: Ntot = 105930100401.968, Nqll = 501084651003.705\n",
      "L-BFGS iteration loss: Ntot = 105939995746.686, Nqll = 501152261373.174\n",
      "L-BFGS iteration loss: Ntot = 105950018607.175, Nqll = 501220734176.343\n",
      "L-BFGS iteration loss: Ntot = 105960171098.752, Nqll = 501290083421.577\n",
      "L-BFGS iteration loss: Ntot = 105970455367.199, Nqll = 501360323289.387\n",
      "L-BFGS iteration loss: Ntot = 105980873601.413, Nqll = 501431468234.993\n",
      "L-BFGS iteration loss: Ntot = 105991428033.760, Nqll = 501503533025.715\n",
      "L-BFGS iteration loss: Ntot = 106002120938.005, Nqll = 501576532687.219\n",
      "L-BFGS iteration loss: Ntot = 106012954626.395, Nqll = 501650482504.019\n",
      "L-BFGS iteration loss: Ntot = 106023931445.251, Nqll = 501725397945.444\n",
      "L-BFGS iteration loss: Ntot = 106035053803.987, Nqll = 501801294938.704\n",
      "L-BFGS iteration loss: Ntot = 106046324131.585, Nqll = 501878189526.130\n",
      "L-BFGS iteration loss: Ntot = 106057744909.262, Nqll = 501956098063.412\n",
      "L-BFGS iteration loss: Ntot = 106069318663.784, Nqll = 502035037213.548\n",
      "L-BFGS iteration loss: Ntot = 106081047964.138, Nqll = 502115023940.999\n",
      "L-BFGS iteration loss: Ntot = 106092935411.201, Nqll = 502196075381.426\n",
      "L-BFGS iteration loss: Ntot = 106104983663.894, Nqll = 502278209087.038\n",
      "L-BFGS iteration loss: Ntot = 106117195403.052, Nqll = 502361442659.615\n",
      "L-BFGS iteration loss: Ntot = 106129573385.048, Nqll = 502445794354.433\n",
      "L-BFGS iteration loss: Ntot = 106142120363.634, Nqll = 502531282193.535\n",
      "L-BFGS iteration loss: Ntot = 106154839173.126, Nqll = 502617924905.970\n",
      "L-BFGS iteration loss: Ntot = 106167732675.431, Nqll = 502705741318.999\n",
      "L-BFGS iteration loss: Ntot = 106180803764.417, Nqll = 502794750449.722\n",
      "L-BFGS iteration loss: Ntot = 106194055386.459, Nqll = 502884971669.838\n",
      "L-BFGS iteration loss: Ntot = 106207490525.360, Nqll = 502976424575.207\n",
      "L-BFGS iteration loss: Ntot = 106221112202.890, Nqll = 503069129031.664\n",
      "L-BFGS iteration loss: Ntot = 106234923491.667, Nqll = 503163105249.415\n",
      "L-BFGS iteration loss: Ntot = 106248927475.694, Nqll = 503258373412.589\n",
      "L-BFGS iteration loss: Ntot = 106263127308.315, Nqll = 503354954257.760\n",
      "L-BFGS iteration loss: Ntot = 106277526151.131, Nqll = 503452868474.252\n",
      "L-BFGS iteration loss: Ntot = 106292127221.087, Nqll = 503552137160.830\n",
      "L-BFGS iteration loss: Ntot = 106306933773.968, Nqll = 503652781648.370\n",
      "L-BFGS iteration loss: Ntot = 106321949077.532, Nqll = 503754823316.014\n",
      "L-BFGS iteration loss: Ntot = 106337176461.365, Nqll = 503858283975.692\n",
      "L-BFGS iteration loss: Ntot = 106352619259.582, Nqll = 503963185407.569\n",
      "L-BFGS iteration loss: Ntot = 106368280855.857, Nqll = 504069549701.142\n",
      "L-BFGS iteration loss: Ntot = 106384164664.276, Nqll = 504177399167.612\n",
      "L-BFGS iteration loss: Ntot = 106400274127.004, Nqll = 504286756305.388\n",
      "L-BFGS iteration loss: Ntot = 106416612701.836, Nqll = 504397643616.115\n",
      "L-BFGS iteration loss: Ntot = 106433183895.784, Nqll = 504510083972.175\n",
      "L-BFGS iteration loss: Ntot = 106449991230.098, Nqll = 504624100319.212\n",
      "L-BFGS iteration loss: Ntot = 106467038247.095, Nqll = 504739715680.952\n",
      "L-BFGS iteration loss: Ntot = 106484328521.401, Nqll = 504856953305.089\n",
      "L-BFGS iteration loss: Ntot = 106501865645.959, Nqll = 504975836532.315\n",
      "L-BFGS iteration loss: Ntot = 106519653251.687, Nqll = 505096388931.219\n",
      "L-BFGS iteration loss: Ntot = 106537694968.985, Nqll = 505218634052.494\n",
      "L-BFGS iteration loss: Ntot = 106555994462.548, Nqll = 505342595599.302\n",
      "L-BFGS iteration loss: Ntot = 106574555417.875, Nqll = 505468297490.230\n",
      "L-BFGS iteration loss: Ntot = 106593381528.373, Nqll = 505595763546.860\n",
      "L-BFGS iteration loss: Ntot = 106612476524.349, Nqll = 505725017904.199\n",
      "L-BFGS iteration loss: Ntot = 106631844134.854, Nqll = 505856084586.204\n",
      "L-BFGS iteration loss: Ntot = 106651488127.265, Nqll = 505988987942.945\n",
      "L-BFGS iteration loss: Ntot = 106671412257.048, Nqll = 506123752053.484\n",
      "L-BFGS iteration loss: Ntot = 106691620339.181, Nqll = 506260401572.188\n",
      "L-BFGS iteration loss: Ntot = 106712116154.340, Nqll = 506398960667.187\n",
      "L-BFGS iteration loss: Ntot = 106732903544.106, Nqll = 506539454090.130\n",
      "L-BFGS iteration loss: Ntot = 106753986344.059, Nqll = 506681906388.904\n",
      "L-BFGS iteration loss: Ntot = 106775368394.289, Nqll = 506826342040.753\n",
      "L-BFGS iteration loss: Ntot = 106797053597.264, Nqll = 506972786215.953\n",
      "L-BFGS iteration loss: Ntot = 106819045808.467, Nqll = 507121263300.647\n",
      "L-BFGS iteration loss: Ntot = 106841348949.666, Nqll = 507271798433.420\n",
      "L-BFGS iteration loss: Ntot = 106863966936.965, Nqll = 507424416510.676\n",
      "L-BFGS iteration loss: Ntot = 106886903711.570, Nqll = 507579142617.961\n",
      "L-BFGS iteration loss: Ntot = 106910163225.363, Nqll = 507736001794.136\n",
      "L-BFGS iteration loss: Ntot = 106933749461.433, Nqll = 507895019368.704\n",
      "L-BFGS iteration loss: Ntot = 106957666408.760, Nqll = 508056220535.517\n",
      "L-BFGS iteration loss: Ntot = 106981918090.977, Nqll = 508219630834.940\n",
      "L-BFGS iteration loss: Ntot = 107006508540.050, Nqll = 508385275703.066\n",
      "L-BFGS iteration loss: Ntot = 107031441795.539, Nqll = 508553180560.014\n",
      "L-BFGS iteration loss: Ntot = 107056721953.454, Nqll = 508723371268.026\n",
      "L-BFGS iteration loss: Ntot = 107082353124.726, Nqll = 508895873697.533\n",
      "L-BFGS iteration loss: Ntot = 107108339427.932, Nqll = 509070713699.763\n",
      "L-BFGS iteration loss: Ntot = 107134685017.386, Nqll = 509247917388.470\n",
      "L-BFGS iteration loss: Ntot = 107161394069.743, Nqll = 509427510882.309\n",
      "L-BFGS iteration loss: Ntot = 107188470816.069, Nqll = 509609520741.312\n",
      "L-BFGS iteration loss: Ntot = 107215919473.197, Nqll = 509793973278.250\n",
      "L-BFGS iteration loss: Ntot = 107243744328.698, Nqll = 509980895302.206\n",
      "L-BFGS iteration loss: Ntot = 107271949690.954, Nqll = 510170313755.427\n",
      "L-BFGS iteration loss: Ntot = 107300539879.253, Nqll = 510362255481.132\n",
      "L-BFGS iteration loss: Ntot = 107329519288.717, Nqll = 510556747944.871\n",
      "L-BFGS iteration loss: Ntot = 107358892320.299, Nqll = 510753818475.666\n",
      "L-BFGS iteration loss: Ntot = 107388663433.708, Nqll = 510953494876.117\n",
      "L-BFGS iteration loss: Ntot = 107418837112.342, Nqll = 511155804963.303\n",
      "L-BFGS iteration loss: Ntot = 107449417898.723, Nqll = 511360777033.053\n",
      "L-BFGS iteration loss: Ntot = 107480410375.007, Nqll = 511568439543.224\n",
      "L-BFGS iteration loss: Ntot = 107511819156.969, Nqll = 511778821024.817\n",
      "L-BFGS iteration loss: Ntot = 107543648939.886, Nqll = 511991950817.384\n",
      "L-BFGS iteration loss: Ntot = 107575904445.485, Nqll = 512207858185.405\n",
      "L-BFGS iteration loss: Ntot = 107608590437.967, Nqll = 512426572715.578\n",
      "L-BFGS iteration loss: Ntot = 107641711753.893, Nqll = 512648124405.866\n",
      "L-BFGS iteration loss: Ntot = 107675273271.558, Nqll = 512872543485.217\n",
      "L-BFGS iteration loss: Ntot = 107709279998.154, Nqll = 513099861250.055\n",
      "L-BFGS iteration loss: Ntot = 107743736918.116, Nqll = 513330108715.978\n",
      "L-BFGS iteration loss: Ntot = 107778649098.734, Nqll = 513563317285.737\n",
      "L-BFGS iteration loss: Ntot = 107814021705.456, Nqll = 513799519214.438\n",
      "L-BFGS iteration loss: Ntot = 107849859966.866, Nqll = 514038747138.874\n",
      "L-BFGS iteration loss: Ntot = 107886169190.705, Nqll = 514281034215.773\n",
      "L-BFGS iteration loss: Ntot = 107922954742.552, Nqll = 514526413947.700\n",
      "L-BFGS iteration loss: Ntot = 107960222096.624, Nqll = 514774920662.719\n",
      "L-BFGS iteration loss: Ntot = 107997976814.929, Nqll = 515026589258.312\n",
      "L-BFGS iteration loss: Ntot = 108036224541.839, Nqll = 515281455148.942\n",
      "L-BFGS iteration loss: Ntot = 108074971039.573, Nqll = 515539554762.173\n",
      "L-BFGS iteration loss: Ntot = 108114222137.223, Nqll = 515800924725.543\n",
      "L-BFGS iteration loss: Ntot = 108153983821.485, Nqll = 516065602967.582\n",
      "L-BFGS iteration loss: Ntot = 108194262156.665, Nqll = 516333627869.928\n",
      "L-BFGS iteration loss: Ntot = 108235063369.761, Nqll = 516605039058.364\n",
      "L-BFGS iteration loss: Ntot = 108276393773.068, Nqll = 516879876630.578\n",
      "L-BFGS iteration loss: Ntot = 108318259864.077, Nqll = 517158182063.307\n",
      "L-BFGS iteration loss: Ntot = 108360668278.564, Nqll = 517439997934.076\n",
      "L-BFGS iteration loss: Ntot = 108403625756.141, Nqll = 517725367262.939\n",
      "L-BFGS iteration loss: Ntot = 108447139281.941, Nqll = 518014335128.049\n",
      "L-BFGS iteration loss: Ntot = 108491215950.331, Nqll = 518306947127.323\n",
      "L-BFGS iteration loss: Ntot = 108535863082.819, Nqll = 518603250642.433\n",
      "L-BFGS iteration loss: Ntot = 108581088181.492, Nqll = 518903294204.993\n",
      "L-BFGS iteration loss: Ntot = 108626898936.267, Nqll = 519207127637.416\n",
      "L-BFGS iteration loss: Ntot = 108673303333.683, Nqll = 519514803163.112\n",
      "L-BFGS iteration loss: Ntot = 108720309455.299, Nqll = 519826373132.693\n",
      "L-BFGS iteration loss: Ntot = 108767925767.679, Nqll = 520141893059.634\n",
      "L-BFGS iteration loss: Ntot = 108816160905.380, Nqll = 520461419450.214\n",
      "L-BFGS iteration loss: Ntot = 108865023761.545, Nqll = 520785010517.817\n",
      "L-BFGS iteration loss: Ntot = 108914523542.567, Nqll = 521112726691.021\n",
      "L-BFGS iteration loss: Ntot = 108964669748.518, Nqll = 521444630585.480\n",
      "L-BFGS iteration loss: Ntot = 109015472152.479, Nqll = 521780786588.659\n",
      "L-BFGS iteration loss: Ntot = 109066940758.666, Nqll = 522121260568.098\n",
      "L-BFGS iteration loss: Ntot = 109119085974.255, Nqll = 522466121100.149\n",
      "L-BFGS iteration loss: Ntot = 109171918513.218, Nqll = 522815439103.215\n",
      "L-BFGS iteration loss: Ntot = 109225449371.831, Nqll = 523169287306.313\n",
      "L-BFGS iteration loss: Ntot = 109279689857.517, Nqll = 523527740545.453\n",
      "L-BFGS iteration loss: Ntot = 109334651532.943, Nqll = 523890875050.427\n",
      "L-BFGS iteration loss: Ntot = 109390346380.775, Nqll = 524258770315.350\n",
      "L-BFGS iteration loss: Ntot = 109446786604.751, Nqll = 524631507210.509\n",
      "L-BFGS iteration loss: Ntot = 109503984665.692, Nqll = 525009168005.090\n",
      "L-BFGS iteration loss: Ntot = 109561953287.154, Nqll = 525391836917.611\n",
      "L-BFGS iteration loss: Ntot = 109620705472.996, Nqll = 525779600020.306\n",
      "L-BFGS iteration loss: Ntot = 109680254380.786, Nqll = 526172544170.129\n",
      "L-BFGS iteration loss: Ntot = 109740613346.443, Nqll = 526570757357.039\n",
      "L-BFGS iteration loss: Ntot = 109801795906.447, Nqll = 526974328941.971\n",
      "L-BFGS iteration loss: Ntot = 109863815638.482, Nqll = 527383348293.483\n",
      "L-BFGS iteration loss: Ntot = 109926686228.814, Nqll = 527797905406.152\n",
      "L-BFGS iteration loss: Ntot = 109990421343.850, Nqll = 528218089910.686\n",
      "L-BFGS iteration loss: Ntot = 110055034704.451, Nqll = 528643991829.306\n",
      "L-BFGS iteration loss: Ntot = 110120539861.440, Nqll = 529075699395.504\n",
      "L-BFGS iteration loss: Ntot = 110186950378.000, Nqll = 529513301042.912\n",
      "L-BFGS iteration loss: Ntot = 110254279603.156, Nqll = 529956883310.658\n",
      "L-BFGS iteration loss: Ntot = 110322540773.706, Nqll = 530406531769.307\n",
      "L-BFGS iteration loss: Ntot = 110391746844.725, Nqll = 530862329757.470\n",
      "L-BFGS iteration loss: Ntot = 110461910547.416, Nqll = 531324358560.260\n",
      "L-BFGS iteration loss: Ntot = 110533044378.358, Nqll = 531792697683.157\n",
      "L-BFGS iteration loss: Ntot = 110605160530.074, Nqll = 532267424093.385\n",
      "L-BFGS iteration loss: Ntot = 110678270869.755, Nqll = 532748611983.018\n",
      "L-BFGS iteration loss: Ntot = 110752387033.588, Nqll = 533236333743.418\n",
      "L-BFGS iteration loss: Ntot = 110827520253.506, Nqll = 533730658066.014\n",
      "L-BFGS iteration loss: Ntot = 110903681582.405, Nqll = 534231652450.938\n",
      "L-BFGS iteration loss: Ntot = 110980881663.621, Nqll = 534739380573.647\n",
      "L-BFGS iteration loss: Ntot = 111059130930.964, Nqll = 535253904080.091\n",
      "L-BFGS iteration loss: Ntot = 111138439626.448, Nqll = 535775283406.502\n",
      "L-BFGS iteration loss: Ntot = 111218817604.890, Nqll = 536303574682.461\n",
      "L-BFGS iteration loss: Ntot = 111300274652.278, Nqll = 536838833671.696\n",
      "L-BFGS iteration loss: Ntot = 111382820315.599, Nqll = 537381113678.420\n",
      "L-BFGS iteration loss: Ntot = 111466464025.951, Nqll = 537930466454.396\n",
      "L-BFGS iteration loss: Ntot = 111551215172.911, Nqll = 538486943319.747\n",
      "L-BFGS iteration loss: Ntot = 111637082903.375, Nqll = 539050592729.469\n",
      "L-BFGS iteration loss: Ntot = 111724076458.445, Nqll = 539621463733.479\n",
      "L-BFGS iteration loss: Ntot = 111812205076.777, Nqll = 540199604845.944\n",
      "L-BFGS iteration loss: Ntot = 111901477907.396, Nqll = 540785063361.194\n",
      "L-BFGS iteration loss: Ntot = 111991904255.697, Nqll = 541377887316.149\n",
      "L-BFGS iteration loss: Ntot = 112083493510.366, Nqll = 541978125437.942\n",
      "L-BFGS iteration loss: Ntot = 112176255074.264, Nqll = 542585825775.793\n",
      "L-BFGS iteration loss: Ntot = 112270198630.191, Nqll = 543201038589.138\n",
      "L-BFGS iteration loss: Ntot = 112365334016.172, Nqll = 543823815279.984\n",
      "L-BFGS iteration loss: Ntot = 112461671222.919, Nqll = 544454208111.981\n",
      "L-BFGS iteration loss: Ntot = 112559220585.522, Nqll = 545092272283.970\n",
      "L-BFGS iteration loss: Ntot = 112657992689.381, Nqll = 545738065167.212\n",
      "L-BFGS iteration loss: Ntot = 112757998422.200, Nqll = 546391646492.769\n",
      "L-BFGS iteration loss: Ntot = 112859249030.207, Nqll = 547053079090.184\n",
      "L-BFGS iteration loss: Ntot = 112961756212.457, Nqll = 547722429817.007\n",
      "L-BFGS iteration loss: Ntot = 113065532134.187, Nqll = 548399769785.979\n",
      "L-BFGS iteration loss: Ntot = 113170589380.838, Nqll = 549085173444.848\n",
      "L-BFGS iteration loss: Ntot = 113276941212.438, Nqll = 549778721677.522\n",
      "L-BFGS iteration loss: Ntot = 113384601516.643, Nqll = 550480500847.020\n",
      "L-BFGS iteration loss: Ntot = 113493584675.415, Nqll = 551190601367.278\n",
      "L-BFGS iteration loss: Ntot = 113603906101.960, Nqll = 551909122891.624\n",
      "L-BFGS iteration loss: Ntot = 113715581906.312, Nqll = 552636170861.761\n",
      "L-BFGS iteration loss: Ntot = 113828629176.688, Nqll = 553371859337.250\n",
      "L-BFGS iteration loss: Ntot = 113943065963.469, Nqll = 554116310029.710\n",
      "L-BFGS iteration loss: Ntot = 114058911521.738, Nqll = 554869655024.357\n",
      "L-BFGS iteration loss: Ntot = 114176186087.314, Nqll = 555632033707.414\n",
      "L-BFGS iteration loss: Ntot = 114294911430.429, Nqll = 556403598546.458\n",
      "L-BFGS iteration loss: Ntot = 114415110435.818, Nqll = 557184510039.873\n",
      "L-BFGS iteration loss: Ntot = 114536807511.250, Nqll = 557974940442.054\n",
      "L-BFGS iteration loss: Ntot = 114660028647.822, Nqll = 558775074696.086\n",
      "L-BFGS iteration loss: Ntot = 114784801079.578, Nqll = 559585106035.722\n",
      "L-BFGS iteration loss: Ntot = 114911153794.682, Nqll = 560405241931.711\n",
      "L-BFGS iteration loss: Ntot = 115039116907.799, Nqll = 561235696548.404\n",
      "L-BFGS iteration loss: Ntot = 115168722098.693, Nqll = 562076695969.415\n",
      "L-BFGS iteration loss: Ntot = 115300002199.755, Nqll = 562928473971.577\n",
      "L-BFGS iteration loss: Ntot = 115432991112.437, Nqll = 563791272067.941\n",
      "L-BFGS iteration loss: Ntot = 115567723255.478, Nqll = 564665333856.797\n",
      "L-BFGS iteration loss: Ntot = 115704233709.554, Nqll = 565550908045.149\n",
      "L-BFGS iteration loss: Ntot = 115842557354.032, Nqll = 566448240138.763\n",
      "L-BFGS iteration loss: Ntot = 115982728774.585, Nqll = 567357572753.744\n",
      "L-BFGS iteration loss: Ntot = 116124781716.932, Nqll = 568279141601.957\n",
      "L-BFGS iteration loss: Ntot = 116268748486.180, Nqll = 569213170298.709\n",
      "L-BFGS iteration loss: Ntot = 116414659655.215, Nqll = 570159868499.954\n",
      "L-BFGS iteration loss: Ntot = 116562543678.627, Nqll = 571119429202.010\n",
      "L-BFGS iteration loss: Ntot = 116712426352.039, Nqll = 572092024459.697\n",
      "L-BFGS iteration loss: Ntot = 116864330540.425, Nqll = 573077802076.225\n",
      "L-BFGS iteration loss: Ntot = 117018276440.226, Nqll = 574076889388.776\n",
      "L-BFGS iteration loss: Ntot = 117174280810.134, Nqll = 575089384871.802\n",
      "L-BFGS iteration loss: Ntot = 117332357650.273, Nqll = 576115364675.720\n",
      "L-BFGS iteration loss: Ntot = 117492517877.134, Nqll = 577154877948.692\n",
      "L-BFGS iteration loss: Ntot = 117654770030.494, Nqll = 578207953682.573\n",
      "L-BFGS iteration loss: Ntot = 117819120211.987, Nqll = 579274598717.283\n",
      "L-BFGS iteration loss: Ntot = 117985572533.283, Nqll = 580354800352.423\n",
      "L-BFGS iteration loss: Ntot = 118154129834.245, Nqll = 581448533498.791\n",
      "L-BFGS iteration loss: Ntot = 118324793575.767, Nqll = 582555757357.726\n",
      "L-BFGS iteration loss: Ntot = 118497564789.821, Nqll = 583676425309.330\n",
      "L-BFGS iteration loss: Ntot = 118672444070.508, Nqll = 584810483426.186\n",
      "L-BFGS iteration loss: Ntot = 118849432081.726, Nqll = 585957874819.662\n",
      "L-BFGS iteration loss: Ntot = 119028530132.960, Nqll = 587118546864.243\n",
      "L-BFGS iteration loss: Ntot = 119209739974.884, Nqll = 588292447257.012\n",
      "L-BFGS iteration loss: Ntot = 119393064626.739, Nqll = 589479534451.773\n",
      "L-BFGS iteration loss: Ntot = 119578508140.413, Nqll = 590679773866.686\n",
      "L-BFGS iteration loss: Ntot = 119766076314.126, Nqll = 591893148133.179\n",
      "L-BFGS iteration loss: Ntot = 119955776514.838, Nqll = 593119653229.247\n",
      "L-BFGS iteration loss: Ntot = 120147618080.153, Nqll = 594359304580.454\n",
      "L-BFGS iteration loss: Ntot = 120341612802.341, Nqll = 595612141913.404\n",
      "L-BFGS iteration loss: Ntot = 120537774731.346, Nqll = 596878227529.104\n",
      "L-BFGS iteration loss: Ntot = 120736121050.951, Nqll = 598157655254.094\n",
      "L-BFGS iteration loss: Ntot = 120936671860.092, Nqll = 599450547934.247\n",
      "L-BFGS iteration loss: Ntot = 121139450795.434, Nqll = 600757063219.463\n",
      "L-BFGS iteration loss: Ntot = 121344485509.913, Nqll = 602077396700.272\n",
      "L-BFGS iteration loss: Ntot = 121551807981.666, Nqll = 603411784235.188\n",
      "L-BFGS iteration loss: Ntot = 121761455175.286, Nqll = 604760507533.061\n",
      "L-BFGS iteration loss: Ntot = 121973468854.663, Nqll = 606123889435.140\n",
      "L-BFGS iteration loss: Ntot = 122187896795.644, Nqll = 607502304183.565\n",
      "L-BFGS iteration loss: Ntot = 122404792509.019, Nqll = 608896173274.125\n",
      "L-BFGS iteration loss: Ntot = 122624215415.850, Nqll = 610305964321.655\n",
      "L-BFGS iteration loss: Ntot = 122846231134.041, Nqll = 611732194305.804\n",
      "L-BFGS iteration loss: Ntot = 123070910558.575, Nqll = 613175417967.335\n",
      "L-BFGS iteration loss: Ntot = 123298329458.612, Nqll = 614636225841.145\n",
      "L-BFGS iteration loss: Ntot = 123528567292.082, Nqll = 616115232999.500\n",
      "L-BFGS iteration loss: Ntot = 123761705294.925, Nqll = 617613064102.600\n",
      "L-BFGS iteration loss: Ntot = 123997824798.645, Nqll = 619130341480.006\n",
      "L-BFGS iteration loss: Ntot = 124237004086.218, Nqll = 620667658403.334\n",
      "L-BFGS iteration loss: Ntot = 124479316294.890, Nqll = 622225566007.462\n",
      "L-BFGS iteration loss: Ntot = 124724826316.718, Nqll = 623804548121.503\n",
      "L-BFGS iteration loss: Ntot = 124973588449.015, Nqll = 625405003647.566\n",
      "L-BFGS iteration loss: Ntot = 125225643969.701, Nqll = 627027228215.577\n",
      "L-BFGS iteration loss: Ntot = 125481019849.830, Nqll = 628671400707.355\n",
      "L-BFGS iteration loss: Ntot = 125739728671.758, Nqll = 630337583189.557\n",
      "L-BFGS iteration loss: Ntot = 126001768288.906, Nqll = 632025713991.346\n",
      "L-BFGS iteration loss: Ntot = 126267123942.021, Nqll = 633735622750.363\n",
      "L-BFGS iteration loss: Ntot = 126535769135.608, Nqll = 635467032223.411\n",
      "L-BFGS iteration loss: Ntot = 126807669182.939, Nqll = 637219585085.413\n",
      "L-BFGS iteration loss: Ntot = 127082783369.983, Nqll = 638992860584.627\n",
      "L-BFGS iteration loss: Ntot = 127361067485.027, Nqll = 640786391991.923\n",
      "L-BFGS iteration loss: Ntot = 127642476361.528, Nqll = 642599688133.416\n",
      "L-BFGS iteration loss: Ntot = 127926967082.339, Nqll = 644432264735.772\n",
      "L-BFGS iteration loss: Ntot = 128214499311.625, Nqll = 646283648200.182\n",
      "L-BFGS iteration loss: Ntot = 128505037833.961, Nqll = 648153401175.571\n",
      "L-BFGS iteration loss: Ntot = 128798553970.796, Nqll = 650041142825.333\n",
      "L-BFGS iteration loss: Ntot = 129095025896.858, Nqll = 651946554419.600\n",
      "L-BFGS iteration loss: Ntot = 129394440354.047, Nqll = 653869401712.526\n",
      "L-BFGS iteration loss: Ntot = 129696792817.487, Nqll = 655809539872.886\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LBFGS:    \n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# lbfgs_iter_counter = 0\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# lbfgs_print_freq = 1\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mlbfgs_optim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mMODEL_NAME\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Create folder to store model in if necessary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\jonescode\\PINN-capstone\\venv\\lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\jonescode\\PINN-capstone\\venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\jonescode\\PINN-capstone\\venv\\lib\\site-packages\\torch\\optim\\lbfgs.py:407\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    405\u001b[0m     d \u001b[38;5;241m=\u001b[39m r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(q, H_diag)\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_old):\n\u001b[1;32m--> 407\u001b[0m         be_i \u001b[38;5;241m=\u001b[39m \u001b[43mold_dirs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mro\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    408\u001b[0m         r\u001b[38;5;241m.\u001b[39madd_(old_stps[i], alpha\u001b[38;5;241m=\u001b[39mal[i] \u001b[38;5;241m-\u001b[39m be_i)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prev_flat_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if LBFGS:    \n",
    "    # lbfgs_iter_counter = 0\n",
    "    # lbfgs_print_freq = 1\n",
    "\n",
    "    lbfgs_optim.step(closure)\n",
    "\n",
    "    \n",
    "    save_path = './models/'+MODEL_NAME\n",
    "\n",
    "    # Create folder to store model in if necessary\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Save model (not including initial condition wrapper)\n",
    "    # torch.save(model.state_dict(), save_path+'/post_LBFGS_params.pth')\n",
    "    # TODO - update (load) so that it can load LBFGS results\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-30.0000,   0.0000],\n",
      "        [-29.8119,   0.0000],\n",
      "        [-29.6238,   0.0000],\n",
      "        [-29.4357,   0.0000],\n",
      "        [-29.2476,   0.0000],\n",
      "        [-29.0596,   0.0000],\n",
      "        [-28.8715,   0.0000],\n",
      "        [-28.6834,   0.0000],\n",
      "        [-28.4953,   0.0000],\n",
      "        [-28.3072,   0.0000],\n",
      "        [-28.1191,   0.0000],\n",
      "        [-27.9310,   0.0000],\n",
      "        [-27.7429,   0.0000],\n",
      "        [-27.5549,   0.0000],\n",
      "        [-27.3668,   0.0000],\n",
      "        [-27.1787,   0.0000],\n",
      "        [-26.9906,   0.0000],\n",
      "        [-26.8025,   0.0000],\n",
      "        [-26.6144,   0.0000],\n",
      "        [-26.4263,   0.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(training_set[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train some more if needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip.train_IcePINN(\n",
    "#     model=model, \n",
    "#     optimizer=optimizer, \n",
    "#     training_set=training_set, \n",
    "#     epochs=100_000, \n",
    "#     name=MODEL_NAME, \n",
    "#     print_every=1_000, \n",
    "#     diffusion=diffusion,\n",
    "#     LR_scheduler=None,\n",
    "#     enforce_IC=True,\n",
    "#     adjustment_period=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
